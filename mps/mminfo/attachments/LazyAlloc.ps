%!PS-Adobe-3.0
%%Title: (NNLazyAlloc.text)
%%Creator: (Microsoft Word: LaserWriter 8 8.2)
%%CreationDate: (7:05 PM Tuesday, December 6, 1994)
%%For: (Henry Baker)
%%Pages: 10
%%DocumentFonts: Times-Italic Times-Bold Times-Roman Times-BoldItalic Courier Symbol Courier-Bold
%%DocumentNeededFonts: Times-Italic Times-Bold Times-Roman Times-BoldItalic Courier Symbol Courier-Bold
%%DocumentSuppliedFonts:
%%DocumentData: Clean7Bit
%%PageOrder: Ascend
%%Orientation: Portrait
%%DocumentMedia: Default 612 792 0 () ()
%ADO_ImageableArea: 31 31 583 761
%%EndComments
userdict begin/dscInfo 5 dict dup begin
/Title(NNLazyAlloc.text)def
/Creator(Microsoft Word: LaserWriter 8 8.2)def
/CreationDate(7:05 PM Tuesday, December 6, 1994)def
/For(Henry Baker)def
/Pages 1 def
end def end

save 
/version23-manualfeedpatch where { pop false } { true }ifelse
 % we don't do an explicit 'get' since product and version MAY
 % be in systemdict or statusdict - this technique gets the lookup
 % without failure
statusdict begin
  product (LaserWriter) eq        % true if LaserWriter
  version cvr 23.0 eq             % true if version 23
end

and  % only install this patch if both are true
and  % true only if patch is not installed and is for this printer
     % save object and boolean on stack
dup { exch restore }if
% either true OR saveobject false
dup
{
  /version23-manualfeedpatch true def
  /oldversion23-showpage /showpage load def
  /showpage       % this showpage will wait extra time if manualfeed is true
  {%
     statusdict /manualfeed known
     {% manualfeed known in statusdict
        statusdict /manualfeed get
        {% if true then we loop for 5 seconds
           usertime 5000 add       % target usertime
           { % loop
             dup usertime sub 0 lt
             { exit }if
           }loop
           pop             % pop the usertime off the stac
        }if
     }if
     oldversion23-showpage
  }bind def
}if
not{ restore }if

/md 189 dict def md begin/currentpacking where {pop /sc_oldpacking currentpacking def true setpacking}if
%%BeginFile: adobe_psp_basic
%%Copyright: Copyright 1990-1993 Adobe Systems Incorporated. All Rights Reserved.
/bd{bind def}bind def
/xdf{exch def}bd
/xs{exch store}bd
/ld{load def}bd
/Z{0 def}bd
/T/true
/F/false
/:L/lineto
/lw/setlinewidth
/:M/moveto
/rl/rlineto
/rm/rmoveto
/:C/curveto
/:T/translate
/:K/closepath
/:mf/makefont
/gS/gsave
/gR/grestore
/np/newpath
14{ld}repeat
/$m matrix def
/av 81 def
/por true def
/normland false def
/psb-nosave{}bd
/pse-nosave{}bd
/us Z
/psb{/us save store}bd
/pse{us restore}bd
/level2
/languagelevel where
{
pop languagelevel 2 ge
}{
false
}ifelse
def
/featurecleanup
{
stopped
cleartomark
countdictstack exch sub dup 0 gt
{
{end}repeat
}{
pop
}ifelse
}bd
/noload Z
/startnoload
{
{/noload save store}if
}bd
/endnoload
{
{noload restore}if
}bd
level2 startnoload
/setjob
{
statusdict/jobname 3 -1 roll put
}bd
/setcopies
{
userdict/#copies 3 -1 roll put
}bd
level2 endnoload level2 not startnoload
/setjob
{
1 dict begin/JobName xdf currentdict end setuserparams
}bd
/setcopies
{
1 dict begin/NumCopies xdf currentdict end setpagedevice
}bd
level2 not endnoload
/pm Z
/mT Z
/sD Z
/realshowpage Z
/initializepage
{
/pm save store mT concat
}bd
/endp
{
pm restore showpage
}def
/$c/DeviceRGB def
/rectclip where
{
pop/rC/rectclip ld
}{
/rC
{
np 4 2 roll
:M
1 index 0 rl
0 exch rl
neg 0 rl
:K
clip np
}bd
}ifelse
/rectfill where
{
pop/rF/rectfill ld
}{
/rF
{
gS
np
4 2 roll
:M
1 index 0 rl
0 exch rl
neg 0 rl
fill
gR
}bd
}ifelse
/rectstroke where
{
pop/rS/rectstroke ld
}{
/rS
{
gS
np
4 2 roll
:M
1 index 0 rl
0 exch rl
neg 0 rl
:K
stroke
gR
}bd
}ifelse
%%EndFile
%%BeginFile: adobe_psp_colorspace_level1
%%Copyright: Copyright 1991-1993 Adobe Systems Incorporated. All Rights Reserved.
/G/setgray ld
/:F/setrgbcolor ld
%%EndFile
%%BeginFile: adobe_psp_uniform_graphics
%%Copyright: Copyright 1990-1993 Adobe Systems Incorporated. All Rights Reserved.
/@a
{
np :M 0 rl :L 0 exch rl 0 rl :L fill
}bd
/@b
{
np :M 0 rl 0 exch rl :L 0 rl 0 exch rl fill
}bd
/arct where
{
pop
}{
/arct
{
arcto pop pop pop pop
}bd
}ifelse
/x1 Z
/x2 Z
/y1 Z
/y2 Z
/rad Z
/@q
{
/rad xs
/y2 xs
/x2 xs
/y1 xs
/x1 xs
np
x2 x1 add 2 div y1 :M
x2 y1 x2 y2 rad arct
x2 y2 x1 y2 rad arct
x1 y2 x1 y1 rad arct
x1 y1 x2 y1 rad arct
fill
}bd
/@s
{
/rad xs
/y2 xs
/x2 xs
/y1 xs
/x1 xs
np
x2 x1 add 2 div y1 :M
x2 y1 x2 y2 rad arct
x2 y2 x1 y2 rad arct
x1 y2 x1 y1 rad arct
x1 y1 x2 y1 rad arct
:K
stroke
}bd
/@i
{
np 0 360 arc fill
}bd
/@j
{
gS
np
:T
scale
0 0 .5 0 360 arc
fill
gR
}bd
/@e
{
np
0 360 arc
:K
stroke
}bd
/@f
{
np
$m currentmatrix
pop
:T
scale
0 0 .5 0 360 arc
:K
$m setmatrix
stroke
}bd
/@k
{
gS
np
:T
0 0 :M
0 0 5 2 roll
arc fill
gR
}bd
/@l
{
gS
np
:T
0 0 :M
scale
0 0 .5 5 -2 roll arc
fill
gR
}bd
/@m
{
np
arc
stroke
}bd
/@n
{
np
$m currentmatrix
pop
:T
scale
0 0 .5 5 -2 roll arc
$m setmatrix
stroke
}bd
%%EndFile
%%BeginFile: adobe_psp_basic_text
%%Copyright: Copyright 1990-1993 Adobe Systems Incorporated. All Rights Reserved.
/S/show ld
/A{
0.0 exch ashow
}bd
/R{
0.0 exch 32 exch widthshow
}bd
/W{
0.0 3 1 roll widthshow
}bd
/J{
0.0 32 4 2 roll 0.0 exch awidthshow
}bd
/V{
0.0 4 1 roll 0.0 exch awidthshow
}bd
/fcflg true def
/fc{
fcflg{
vmstatus exch sub 50000 lt{
(%%[ Warning: Running out of memory ]%%\r)print flush/fcflg false store
}if pop
}if
}bd
/$f[1 0 0 -1 0 0]def
/:ff{$f :mf}bd
/MacEncoding StandardEncoding 256 array copy def
MacEncoding 39/quotesingle put
MacEncoding 96/grave put
/Adieresis/Aring/Ccedilla/Eacute/Ntilde/Odieresis/Udieresis/aacute
/agrave/acircumflex/adieresis/atilde/aring/ccedilla/eacute/egrave
/ecircumflex/edieresis/iacute/igrave/icircumflex/idieresis/ntilde/oacute
/ograve/ocircumflex/odieresis/otilde/uacute/ugrave/ucircumflex/udieresis
/dagger/degree/cent/sterling/section/bullet/paragraph/germandbls
/registered/copyright/trademark/acute/dieresis/notequal/AE/Oslash
/infinity/plusminus/lessequal/greaterequal/yen/mu/partialdiff/summation
/product/pi/integral/ordfeminine/ordmasculine/Omega/ae/oslash
/questiondown/exclamdown/logicalnot/radical/florin/approxequal/Delta/guillemotleft
/guillemotright/ellipsis/space/Agrave/Atilde/Otilde/OE/oe
/endash/emdash/quotedblleft/quotedblright/quoteleft/quoteright/divide/lozenge
/ydieresis/Ydieresis/fraction/currency/guilsinglleft/guilsinglright/fi/fl
/daggerdbl/periodcentered/quotesinglbase/quotedblbase/perthousand
/Acircumflex/Ecircumflex/Aacute/Edieresis/Egrave/Iacute/Icircumflex/Idieresis/Igrave
/Oacute/Ocircumflex/apple/Ograve/Uacute/Ucircumflex/Ugrave/dotlessi/circumflex/tilde
/macron/breve/dotaccent/ring/cedilla/hungarumlaut/ogonek/caron
MacEncoding 128 128 getinterval astore pop
level2 startnoload
/copyfontdict
{
findfont dup length dict
begin
{
1 index/FID ne{def}{pop pop}ifelse
}forall
}bd
level2 endnoload level2 not startnoload
/copyfontdict
{
findfont dup length dict
copy
begin
}bd
level2 not endnoload
md/fontname known not{
/fontname/customfont def
}if
/Encoding Z
/:mre
{
copyfontdict
/Encoding MacEncoding def
fontname currentdict
end
definefont :ff def
}bd
/:bsr
{
copyfontdict
/Encoding Encoding 256 array copy def
Encoding dup
}bd
/pd{put dup}bd
/:esr
{
pop pop
fontname currentdict
end
definefont :ff def
}bd
/scf
{
scalefont def
}bd
/scf-non
{
$m scale :mf setfont
}bd
/ps Z
/fz{/ps xs}bd
/sf/setfont ld
/cF/currentfont ld
/mbf
{
/makeblendedfont where
{
pop
makeblendedfont
/ABlend exch definefont
}{
pop
}ifelse
def
}def
%%EndFile
%%BeginFile: adobe_psp_derived_styles
%%Copyright: Copyright 1990-1993 Adobe Systems Incorporated. All Rights Reserved.
/wi
version(23.0)eq
{
{
gS 0 0 0 0 rC stringwidth gR
}bind
}{
/stringwidth load
}ifelse
def
/$o 1. def
/gl{$o G}bd
/ms{:M S}bd
/condensedmtx[.82 0 0 1 0 0]def
/:mc
{
condensedmtx :mf def
}bd
/extendedmtx[1.18 0 0 1 0 0]def
/:me
{
extendedmtx :mf def
}bd
/basefont Z
/basefonto Z
/dxa Z
/dxb Z
/dxc Z
/dxd Z
/dsdx2 Z
/bfproc Z
/:fbase
{
dup/FontType get 0 eq{
dup length dict begin
dup{1 index/FID ne 2 index/UniqueID ne and{def}{pop pop}ifelse}forall
/FDepVector exch/FDepVector get[exch/:fbase load forall]def
}/bfproc load ifelse
/customfont currentdict end definefont
}bd
/:mo
{
/bfproc{
dup dup length 2 add dict
begin
{
1 index/FID ne 2 index/UniqueID ne and{def}{pop pop}ifelse
}forall
/PaintType 2 def
/StrokeWidth .012 0 FontMatrix idtransform pop def
/customfont currentdict
end
definefont
8 dict begin
/basefonto xdf
/basefont xdf
/FontType 3 def
/FontMatrix[1 0 0 1 0 0]def
/FontBBox[0 0 1 1]def
/Encoding StandardEncoding def
/BuildChar
{
exch begin
basefont setfont
( )dup 0 4 -1 roll put
dup wi
setcharwidth
0 0 :M
gS
gl
dup show
gR
basefonto setfont
show
end
}def
}store :fbase
}bd
/:mso
{
/bfproc{
7 dict begin
/basefont xdf
/FontType 3 def
/FontMatrix[1 0 0 1 0 0]def
/FontBBox[0 0 1 1]def
/Encoding StandardEncoding def
/BuildChar
{
exch begin
sD begin
/dxa 1 ps div def
basefont setfont
( )dup 0 4 -1 roll put
dup wi
1 index 0 ne
{
exch dxa add exch
}if
setcharwidth
dup 0 0 ms
dup dxa 0 ms
dup dxa dxa ms
dup 0 dxa ms
gl
dxa 2. div dup ms
end
end
}def
}store :fbase
}bd
/:ms
{
/bfproc{
dup dup length 2 add dict
begin
{
1 index/FID ne 2 index/UniqueID ne and{def}{pop pop}ifelse
}forall
/PaintType 2 def
/StrokeWidth .012 0 FontMatrix idtransform pop def
/customfont currentdict
end
definefont
8 dict begin
/basefonto xdf
/basefont xdf
/FontType 3 def
/FontMatrix[1 0 0 1 0 0]def
/FontBBox[0 0 1 1]def
/Encoding StandardEncoding def
/BuildChar
{
exch begin
sD begin
/dxb .05 def
basefont setfont
( )dup 0 4 -1 roll put
dup wi
exch dup 0 ne
{
dxb add
}if
exch setcharwidth
dup dxb .01 add 0 ms
0 dxb :T
gS
gl
dup 0 0 ms
gR
basefonto setfont
0 0 ms
end
end
}def
}store :fbase
}bd
/:mss
{
/bfproc{
7 dict begin
/basefont xdf
/FontType 3 def
/FontMatrix[1 0 0 1 0 0]def
/FontBBox[0 0 1 1]def
/Encoding StandardEncoding def
/BuildChar
{
exch begin
sD begin
/dxc 1 ps div def
/dsdx2 .05 dxc 2 div add def
basefont setfont
( )dup 0 4 -1 roll put
dup wi
exch dup 0 ne
{
dsdx2 add
}if
exch setcharwidth
dup dsdx2 .01 add 0 ms
0 .05 dxc 2 div sub :T
dup 0 0 ms
dup dxc 0 ms
dup dxc dxc ms
dup 0 dxc ms
gl
dxc 2 div dup ms
end
end
}def
}store :fbase
}bd
/:msb
{
/bfproc{
7 dict begin
/basefont xdf
/FontType 3 def
/FontMatrix[1 0 0 1 0 0]def
/FontBBox[0 0 1 1]def
/Encoding StandardEncoding def
/BuildChar
{
exch begin
sD begin
/dxd .03 def
basefont setfont
( )dup 0 4 -1 roll put
dup wi
1 index 0 ne
{
exch dxd add exch
}if
setcharwidth
dup 0 0 ms
dup dxd 0 ms
dup dxd dxd ms
0 dxd ms
end
end
}def
}store :fbase
}bd
/italicmtx[1 0 -.212557 1 0 0]def
/:mi
{
italicmtx :mf def
}bd
/:v
{
[exch dup/FontMatrix get exch
dup/FontInfo known
{
/FontInfo get
dup/UnderlinePosition known
{
dup/UnderlinePosition get
2 index 0
3 1 roll
transform
exch pop
}{
.1
}ifelse
3 1 roll
dup/UnderlineThickness known
{
/UnderlineThickness get
exch 0 3 1 roll
transform
exch pop
abs
}{
pop pop .067
}ifelse
}{
pop pop .1 .067
}ifelse
]
}bd
/$t Z
/$p Z
/$s Z
/:p
{
aload pop
2 index mul/$t xs
1 index mul/$p xs
.012 mul/$s xs
}bd
/:m
{gS
0 $p rm
$t lw
0 rl stroke
gR
}bd
/:n
{
gS
0 $p rm
$t lw
0 rl
gS
gl
stroke
gR
strokepath
$s lw
/setstrokeadjust where{pop
currentstrokeadjust true setstrokeadjust stroke setstrokeadjust
}{
stroke
}ifelse
gR
}bd
/:o
{gS
0 $p rm
$t 2 div dup rm
$t lw
dup 0 rl
stroke
gR
:n
}bd
%%EndFile
/currentpacking where {pop sc_oldpacking setpacking}if end
%%EndProlog
%%BeginSetup
md begin
countdictstack[{
%%BeginFeature: *ManualFeed False
statusdict /manualfeed false put
%%EndFeature
}featurecleanup
countdictstack[{
%%BeginFeature: *InputSlot Cassette

%%EndFeature
}featurecleanup
countdictstack[{
%%BeginFeature: *PageRegion LetterSmall
lettersmall
%%EndFeature
}featurecleanup
(Henry Baker)setjob
/mT[1 0 0 -1 31 761]def
/sD 16 dict def
300 level2{1 dict dup/WaitTimeout 4 -1 roll put setuserparams}{statusdict/waittimeout 3 -1 roll put}ifelse
%%IncludeFont: Times-Italic
%%IncludeFont: Times-Bold
%%IncludeFont: Times-Roman
%%IncludeFont: Times-BoldItalic
%%IncludeFont: Courier
%%IncludeFont: Symbol
%%IncludeFont: Courier-Bold
/f0_1/Times-Italic
:mre
/f0_12 f0_1 12 scf
/f0_9 f0_1 9 scf
/f0_8 f0_1 8 scf
/f0_7 f0_1 7 scf
/f1_1/Times-Bold
:mre
/f1_12 f1_1 12 scf
/f1_8 f1_1 8 scf
/f2_1/Times-Roman
:mre
/f2_15 f2_1 15 scf
/f2_12 f2_1 12 scf
/f2_9 f2_1 9 scf
/f2_8 f2_1 8 scf
/f2_7 f2_1 7 scf
/f3_1 f2_1
:v def
/f4_1/Times-BoldItalic
:mre
/f4_8 f4_1 8 scf
/f5_1/Courier
:mre
/f5_8 f5_1 8 scf
/f5_7 f5_1 7 scf
/f6_1/Symbol
:bsr
240/apple pd
:esr
/f6_7 f6_1 7 scf
/f7_1/Courier-Bold
:mre
/f7_8 f7_1 8 scf
/Courier findfont[10 0 0 -10 0 0]:mf setfont
%%EndSetup
%%Page: 1 1
%%BeginPageSetup
initializepage
(Henry Baker; page: 1 of 10)setjob
%%EndPageSetup
gS 0 0 552 730 rC
41 14 :M
f0_12 sf
.286 .029(ACM Sigplan Notices  )J
f1_12 sf
.095(27)A
f2_12 sf
.435 .044(,3 \(March 1992\),24-34.)J
41 720 :M
-.033(Copyright \251 1988,1990,1991 Nimble Computer Corporation)A
467 720 :M
(1)S
41 52 :M
f2_15 sf
.354 .035(CONS Should not CONS its Arguments, or, a Lazy Alloc is a Smart Alloc)J
41 75 :M
f2_12 sf
.214 .021(Henry G. Baker)J
41 88 :M
f0_9 sf
1.304 .13(Nimble Computer Corporation, 16231 Meadow Ridge Way, Encino, CA  91436, \(818\) 501-4956\312\312\312\(818\) 986-1360 \(FAX\))J
41 98 :M
f2_8 sf
.407 .041(November, 1988; revised April and December, 1990, November, 1991.)J
41 110 :M
f2_9 sf
.55 .055(This work was supported in part by the U.S. Department of Energy Contract No. DE-AC03-88ER80663)J
41 125 :M
f1_8 sf
.177(Abstract)A
41 134 :M
f0_8 sf
.413 .041(Lazy allocation)J
f2_8 sf
.237 .024( is a model for allocating objects on the execution stack)J
41 142 :M
1.033 .103(of a high-level language which does not create dangling references.)J
41 150 :M
.799 .08(Our model provides safe transportation into the heap for objects that)J
41 158 :M
.875 .088(may survive the deallocation of the surrounding stack frame.  Space)J
41 166 :M
.212 .021(for objects that do not survive the deallocation of the surrounding stack)J
41 174 :M
.466 .047(frame is reclaimed without additional effort when the stack is popped.)J
41 182 :M
.901 .09(Lazy allocation thus performs a first-level garbage collection, and if)J
41 190 :M
.684 .068(the language supports garbage collection of the heap, then our model)J
41 198 :M
.497 .05(can reduce the amortized cost of allocation in such a heap by filtering)J
41 206 :M
1.183 .118(out the short-lived objects that can be more efficiently managed in)J
41 214 :M
.665 .066(LIFO order.  A run-time mechanism called )J
f0_8 sf
1.078 .108(result expectation)J
f2_8 sf
.739 .074( further)J
41 222 :M
.327 .033(filters out unneeded results from functions called only for their effects.)J
41 230 :M
2.449 .245(In a shared-memory multi-processor environment, this filtering)J
41 238 :M
1.992 .199(reduces contention for the allocation and management of global)J
41 246 :M
.057(memory.)A
41 256 :M
.625 .062(Our model performs simple local operations, and is therefore suitable)J
41 264 :M
1.199 .12(for an interpreter or a hardware implementation.  Its overheads for)J
41 272 :M
1.252 .125(functional data are associated only with )J
f0_8 sf
.349(assignments)A
f2_8 sf
1.329 .133(, making lazy)J
41 280 :M
.592 .059(allocation attractive for )J
f0_8 sf
.887 .089(mostly functional)J
f2_8 sf
.602 .06( programming styles.  Many)J
41 288 :M
.472 .047(existing stack allocation optimizations can be seen as instances of this)J
41 296 :M
.822 .082(generic model, in which some portion of these local operations have)J
41 304 :M
.288 .029(been optimized away through static analysis techniques.)J
41 314 :M
.519 .052(Important applications of our model include the efficient allocation of)J
41 322 :M
.675 .068(temporary data structures that are passed as arguments to anonymous)J
41 330 :M
.454 .045(procedures which may or may not use these data structures in a stack-)J
41 338 :M
1.671 .167(like fashion.  The most important of these objects are functional)J
41 346 :M
2.535 .253(arguments \()J
f0_8 sf
.489(funargs)A
f2_8 sf
1.919 .192(\), which require some run-time allocation to)J
41 354 :M
.522 .052(preserve the local environment.  Since a funarg is sometimes returned)J
41 362 :M
.503 .05(as a first-class value, its lifetime can survive the stack frame in which)J
41 370 :M
1.496 .15(it was created.  Arguments which are evaluated in a lazy fashion)J
41 378 :M
1.383 .138(\(Scheme )J
f0_8 sf
.283(delays)A
f2_8 sf
1.124 .112( or "suspensions"\) are similarly handled.  Variable-)J
41 386 :M
1.145 .115(length argument "lists" themselves can be allocated in this fashion,)J
41 394 :M
.411 .041(allowing these objects to become "first-class".  Finally, lazy allocation)J
41 402 :M
.968 .097(correctly handles the allocation of a Scheme control stack, allowing)J
41 410 :M
.298 .03(Scheme continuations to become first-class values.)J
41 422 :M
f1_8 sf
-.034(1.\312\312Introduction.)A
41 431 :M
f2_8 sf
.783 .078(Stack allocation of objects in higher level programming languages is)J
41 439 :M
1.838 .184(desired because it is elegant, efficient, and can handle the great)J
41 447 :M
1.391 .139(majority of short-lived object allocations.  Traditional higher-level)J
41 455 :M
1.023 .102(languages such as Algol, Pascal and Ada have preferred to perform)J
41 463 :M
.453 .045(all )J
f0_8 sf
.226(automatic)A
f2_8 sf
.847 .085( storage management by using a stack, while non-stack)J
41 471 :M
.299 .03(allocation remains the responsibility of the programmer.  However, the)J
41 479 :M
1.042 .104(limitations of stack allocation are semantically confining, because a)J
41 487 :M
.299 .03(strict last-in, first-out, \(LIFO\) allocation/deallocation ordering does not)J
41 495 :M
1.843 .184(allow for important classes of program behavior such as that of)J
41 503 :M
3.034 .303(returning a functional argument as a result.  Therefore, the)J
41 511 :M
1.031 .103(programmer is forced to use complex and error-prone techniques to)J
41 519 :M
.534 .053(simulate this behavior himself, even though the abstract programming)J
41 527 :M
.973 .097(language may be capable of expressing the behavior more elegantly)J
41 535 :M
1.873 .187(and directly using, for example, functional arguments as results.)J
41 543 :M
.231 .023(Modern higher level languages such as Lisp, Smalltalk, Mesa, Modula-)J
41 551 :M
.991 .099(3, ML, and Eiffel, seek to escape these LIFO restrictions to gain in)J
41 559 :M
2.009 .201(expressive power while retaining elegance and simplicity in the)J
41 567 :M
2.616 .262(language.  Insofar as they succeed, they can greatly improve)J
41 575 :M
.333 .033(engineering productivity and software quality.)J
41 585 :M
.949 .095(A cost must be paid for this flexibility through the increased use of)J
41 593 :M
.769 .077(heap allocation for objects in the language.  Yet the vast majority of)J
41 601 :M
1.597 .16(objects obey a straight-forward last-in, first-out \(LIFO\) allocation)J
41 609 :M
1.038 .104(semantics, and could profitably utilize stack allocation.  One would)J
41 617 :M
1.687 .169(therefore like to provide stack allocation for these objects, while)J
41 625 :M
1.188 .119(reserving the more expensive heap allocation for those objects that)J
41 633 :M
.875 .088(require it.  In other words, one would like an implementation which)J
41 641 :M
2.301 .23(retains the efficiency of stack allocation for most objects, and)J
41 649 :M
2.311 .231(therefore does not saddle every program with the cost for the)J
41 657 :M
.228 .023(increased flexibility\321whether the program uses that flexibility or not.)J
41 667 :M
.97 .097(The problem in providing such an implementation is in determining)J
41 675 :M
1.593 .159(which objects obey LIFO allocation semantics and which do not.)J
41 683 :M
.488 .049(Much research has been done on determining these objects at compile)J
281 123 :M
.715 .072(time using various static methods which are specific to the particular)J
281 131 :M
1.158 .116(type of object whose allocation is being optimized.  Unfortunately,)J
281 139 :M
.975 .098(these techniques are limited, complex and expensive.  We present a)J
281 147 :M
1.026 .103(technique which acts more like a )J
f0_8 sf
.332(cache)A
f2_8 sf
.401 .04( or a )J
f0_8 sf
1.823 .182(virtual memory)J
f2_8 sf
.726 .073(, in the)J
281 155 :M
.381 .038(sense that no attempt is made to predict usage at compile time, but the)J
281 163 :M
1.08 .108(usage is determined at run time.  In other words, the system learns)J
281 171 :M
.271 .027(about the usage of objects "on-the-fly".)J
281 181 :M
1.203 .12(The major contribution of this paper is the recognition that a wide)J
281 189 :M
.687 .069(variety of stack-allocation optimizations are all instances of the same)J
281 197 :M
1.771 .177(underlying mechanism\321)J
f0_8 sf
1.282 .128(lazy allocation)J
f2_8 sf
.684 .068(.  Using this insight, we can)J
281 205 :M
1.991 .199(simplify hardware architecture and language implementations by)J
281 213 :M
3.349 .335(factoring the problem into two abstraction layers\321language)J
281 221 :M
4.431 .443(implementation using generic storage allocation, and the)J
281 229 :M
1.378 .138(implementation of generic storage allocation using lazy allocation.)J
281 237 :M
1.083 .108(Safety is also enhanced by the elimination of "dangling references")J
281 245 :M
.437 .044(due to objects escaping a stack-allocated scope.  While lazy allocation)J
281 253 :M
.683 .068(already provides for stack-allocation of arguments and temporaries, a)J
281 261 :M
2.908 .291(programmer can extract even better performance by utilizing)J
281 269 :M
.176 .018("continuation-passing style" to stack-allocate function results.)J
281 281 :M
f1_8 sf
1.136 .114(2.\312\312Stack Allocation is an Implementation Issue, not a Language)J
281 289 :M
-.083(Issue)A
281 298 :M
f2_8 sf
.325 .033(The stack allocation of variables and contexts in higher-level compiled)J
281 306 :M
1.121 .112(languages such as C, Pascal and Ada has been a fact of life for so)J
281 314 :M
.702 .07(many years since its introduction in Algol-60 that most programmers)J
281 322 :M
1.681 .168(today assume that stack allocation is a )J
f0_8 sf
.554(language)A
f2_8 sf
1.588 .159(, rather than an)J
281 330 :M
f0_8 sf
.257(implementation)A
f2_8 sf
.841 .084(, issue.  Stack allocation cannot be a language issue,)J
281 338 :M
.627 .063(however, since the most direct mapping of the nested lexical variable)J
281 346 :M
2.003 .2(scopes in these languages is a )J
f0_8 sf
.585(tree)A
f2_8 sf
1.838 .184(, not a stack.  Rather, stack)J
281 354 :M
1.468 .147(allocation was a conscious decision on the part of these language)J
281 362 :M
1.402 .14(designers to provide the )J
f0_8 sf
2.728 .273(implementation efficiency)J
f2_8 sf
.835 .084( of a stack as a)J
281 370 :M
1.24 .124(storage allocation mechanism even though this choice substantially)J
281 378 :M
1.352 .135(compromised language elegance.  We have also since learned that)J
281 386 :M
2.811 .281(stack allocation of variables and contexts severely limits the)J
281 394 :M
1.58 .158(expressiveness of a programming language.  Indeed, many of the)J
281 402 :M
3.609 .361(advances in programming languages after Algol-60 can be)J
281 410 :M
2.168 .217(characterized as attempts to ameliorate the restrictions of stack)J
281 418 :M
.451 .045(allocation.  For example, most of the functionality of Simula-67 could)J
281 426 :M
1.341 .134(have been achieved in Algol-60 through the dropping of the stack)J
281 434 :M
2.581 .258(allocation requirement along with the syntactic restrictions on)J
281 442 :M
.641 .064(procedure arguments and returned values.)J
281 452 :M
1.787 .179(The stack allocation of Algol-60 provided a major advance over)J
281 460 :M
.785 .078(Fortran's static allocation.  Functions could be arbitrarily nested, and)J
281 468 :M
2.24 .224(recursion became possible.  So long as the basic values being)J
281 476 :M
.656 .066(manipulated were numbers and individual characters, stack allocation)J
281 484 :M
.498 .05(proved remarkably expressive.  With the advent of dynamic strings of)J
281 492 :M
.65 .065(characters and larger dynamic objects such as arrays, stack allocation)J
281 500 :M
4.078 .408(started to break down.  PL/I used pointers and explicit)J
281 508 :M
2.745 .274(allocation/deallocation to avoid the limits of stack allocation.)J
281 516 :M
1.628 .163(Substantial arguments in the 1970's raged about the allocation of)J
281 524 :M
3.753 .375(function-calling and variable-allocation contexts\321"retention")J
281 532 :M
1.867 .187(\(non-stack allocation\) versus "deletion" \(normal stack allocation\))J
281 540 :M
1.797 .18([Berry71] [Fischer72].  Non-stack-allocation has become steadily)J
281 548 :M
.387 .039(more important as the sophistication and complexity of programs have)J
281 556 :M
1.237 .124(increased.  For example, in modern "object-oriented" programming)J
281 564 :M
.506 .051(style, most objects are heap-allocated rather than stack-allocated.)J
281 574 :M
.317 .032(Unfortunately, heap-allocation is substantially less efficient than stack-)J
281 582 :M
.82 .082(allocation.  As a result, programmers constantly seek to utilize stack)J
281 590 :M
1.866 .187(allocation whenever possible.  This change requires much work,)J
281 598 :M
.676 .068(because the source code changes required to change from one sort of)J
281 606 :M
1.807 .181(allocation to another are substantial, even when the logic of the)J
281 614 :M
1.797 .18(program has not changed.  Most importantly, the programmer is)J
281 622 :M
1.602 .16(required to use heap-allocation for entire classes of objects, even)J
281 630 :M
.677 .068(when the vast majority of these objects can be safely stack-allocated.)J
281 638 :M
.089 .009(This results from the difficulty in determining at design or compile time)J
281 646 :M
f0_8 sf
.174(which)A
f2_8 sf
.563 .056( of the objects can be safely stack-allocated, because it depends)J
281 654 :M
.578 .058(on a particular pattern of function calls, which in turn depends on the)J
281 662 :M
.115 .012(input data.)J
281 672 :M
1.291 .129(The use of different constructs and mechanisms for heap allocated)J
281 680 :M
.487 .049(objects than for stack-allocated objects is therefore less productive for)J
endp
%%Page: 2 2
%%BeginPageSetup
initializepage
(Henry Baker; page: 2 of 10)setjob
%%EndPageSetup
-31 -31 :T
gS 31 31 552 730 rC
72 45 :M
f0_12 sf
.286 .029(ACM Sigplan Notices  )J
f1_12 sf
.095(27)A
f2_12 sf
.435 .044(,3 \(March 1992\),24-34.)J
72 751 :M
-.033(Copyright \251 1988,1990,1991 Nimble Computer Corporation)A
498 751 :M
(2)S
72 78 :M
f2_8 sf
.179 .018(the programmer and less efficient at run-time.  It is also an invitation to)J
72 86 :M
1.201 .12(disaster, because using stack allocation inappropriately can cause a)J
72 94 :M
.433 .043(program to fail in a spectacular manner.)J
72 104 :M
1.414 .141(We believe that the intertwining of an implementation mechanism)J
72 112 :M
2.856 .286(\(storage allocation\) with a programming language mechanism)J
72 120 :M
1.023 .102(\(variable and function scoping\) is confusing to the programmer and)J
72 128 :M
.375 .038(inefficient for the hardware.  It is a violation of the design principle of)J
72 136 :M
2.974 .297(providing "levels of abstraction", wherein each level can be)J
72 144 :M
.626 .063(understood in its own terms, and not require a detailed understanding)J
72 152 :M
1.613 .161(of every lower level.  We therefore describe a mechanism called)J
72 160 :M
.65 .065("lazy allocation" which can be used to provide a uniform interface to)J
72 168 :M
.88 .088(the programmer, while taking advantage of stack-allocation as much)J
72 176 :M
.057 .006(as possible.)J
72 186 :M
.184 .018(The simplification in language design and implementation permitted by)J
72 194 :M
1.672 .167(lazy allocation through improved abstraction is important even if)J
72 202 :M
.578 .058(additional run-time efficiency on current hardware is not immediately)J
72 210 :M
1.44 .144(forthcoming.  The problem factorization by lazy allocation should)J
72 218 :M
1.105 .111(allow for more efficient hardware architectures as well as language)J
72 226 :M
2.41 .241(implementations, which will eventually translate into improved)J
72 234 :M
1.061 .106(price/performance ratios.)J
72 246 :M
f1_8 sf
-.008(3.\312\312The\312Model.)A
72 255 :M
f2_8 sf
1.551 .155(The standard model of a run-time system in a modern high level)J
72 263 :M
.552 .055(language consists of a traditional execution )J
f0_8 sf
.136(stack)A
f2_8 sf
.545 .054( formatted into stack)J
72 271 :M
f0_8 sf
.315(frames)A
f2_8 sf
1.035 .104(, each of which represents the execution state of a particular)J
72 279 :M
.683 .068(invocation of a particular procedure.  The model may also includes a)J
72 287 :M
f0_8 sf
.173(heap)A
f2_8 sf
.596 .06(, which contains objects that cannot be allocated and deallocated)J
72 295 :M
1.202 .12(in a last-in, first-out \(LIFO\) manner.  Typical languages using this)J
72 303 :M
.25 .025(model are Pascal, C and Ada \(without tasks\).)J
72 313 :M
.516 .052(C and PL/I make most storage allocation and pointer management the)J
72 321 :M
.387 .039(responsibility of the programmer.  In these languages, he is allowed to)J
72 329 :M
.36 .036(take the address of an object on the stack and store this pointer into an)J
72 337 :M
.573 .057(arbitrary variable.  A common instance of creating references to local)J
72 345 :M
.884 .088(variables is when local variables are passed as arguments to another)J
72 353 :M
.846 .085(procedure )J
f0_8 sf
.9 .09(by reference)J
f2_8 sf
.577 .058(.  Passing large objects by reference is usually)J
72 361 :M
2.086 .209(cheaper than passing them by value, but by-reference argument)J
72 369 :M
.806 .081(passing can lead to a dangling reference if a reference into the stack)J
72 377 :M
.831 .083(is then stored into a variable having a larger scope, such as a global)J
72 385 :M
1.062 .106(variable.  A dangling reference can cause bugs if it is dereferenced)J
72 393 :M
1.282 .128(outside of the stack object's lifetime.  Thus, the power to take the)J
72 401 :M
1.2 .12(address of an object on the stack can lead to efficient programs in)J
72 409 :M
2.355 .236(which temporaries are stack-allocated, but this power can also)J
72 417 :M
.294 .029(produce bugs which are difficult to find.)J
72 427 :M
.593 .059(Our model detects these objects whose references are about to escape)J
72 435 :M
.972 .097(from the lifetime of their enclosing stack frame, and relocates these)J
72 443 :M
.795 .079(objects into the permanent heap.  This graduation from temporary to)J
72 451 :M
1.775 .178(permanent status we call )J
f0_8 sf
.452(eviction)A
f2_8 sf
1.369 .137(.  Due to the constant threat of)J
72 459 :M
1.469 .147(sudden eviction, any access to such an object must be capable of)J
72 467 :M
.663 .066(detecting this movement so it can find the relocated object at its new)J
72 475 :M
1.438 .144(address by following a forwarding pointer.1  The mechanisms for)J
72 483 :M
1.828 .183(dealing with objects which can be unexpectedly moved are well)J
72 491 :M
1.336 .134(known in the context of "on-the-fly", or "incremental" compacting)J
72 499 :M
1.016 .102(garbage collectors [Baker78][Lieberman83].)J
72 509 :M
.756 .076(Once we have installed the machinery necessary to deal with objects)J
72 517 :M
1.682 .168(which can suddenly move, we can contemplate the possibility of)J
72 525 :M
2.299 .23(allocating )J
f0_8 sf
.486(everything)A
f2_8 sf
1.466 .147( initially on the stack.  If we implement an)J
72 533 :M
1.742 .174("escape alarm system" to detect escaping references, we can use)J
72 541 :M
.434 .043(these alarms to trap to an eviction routine which will transport evicted)J
72 549 :M
.554 .055(objects into the heap.  We call the policy of stack allocation followed)J
72 557 :M
.831 .083(by eviction traps "lazy allocation", because the system is too lazy to)J
72 565 :M
.488 .049(perform the work involved in heap allocation until this work is forced)J
72 573 :M
.18 .018(by the object's usage.)J
72 583 :M
.452 .045(In the lazy allocation model, we have a global heap, a stack formatted)J
72 591 :M
.478 .048(into stack frames, and a small number of machine registers.  We posit)J
72 599 :M
2.038 .204(the existence of an ordering relation on object addresses which)J
72 607 :M
.161 .016(adheres to the following axioms:)J
72 615 :M
1.321 .132(1.  The location address of an object in the global heap compares)J
72 623 :M
.273 .027(lower than the location address of an object in the stack.)J
72 631 :M
1.137 .114(2.  The location address of an object in a frame near the stack top)J
72 639 :M
1.238 .124(compares greater than the location address of an object in a frame)J
72 647 :M
.444 .044(near the base of the stack.)J
72 657 :M
.328 .033(Lazy allocation will enforce the following rule:)J
72 665 :M
f0_8 sf
.531 .053(Temporary Restraining Order)J
f2_8 sf
.284 .028( \321 No temporary object in the stack can)J
72 673 :M
1.089 .109(be pointed to by an object whose location address compares lower;)J
-4096 -4095 -1 1 -4094 -4095 1 -4096 -4096 @a
72 687.24 -.24 .24 215.24 687 .24 72 687 @a
72 698 :M
f2_9 sf
.39(1)A
f2_8 sf
0 3 rm
1.341 .134(Forwarding pointers are only required for side-effectable objects;)J
0 -3 rm
72 709 :M
1.882 .188(functional \(read-only\) objects are copied, but do not require the)J
72 717 :M
.393 .039(detection or following of forwarding pointers [Baker93].)J
312 78 :M
.372 .037(i.e., no object in the heap can point into the stack, and no object in the)J
312 86 :M
.108 .011(stack can point "up" the stack, only "down" the stack.)J
312 96 :M
1.499 .15(The Temporary Restraining Order \(TRO\) is enforced by checking)J
312 104 :M
.948 .095(every primitive operation which could possibly violate it.  The only)J
312 112 :M
1.205 .121(operation which can violate TRO is the storage of a pointer into a)J
312 120 :M
1.774 .177(stack frame \(or the heap\) which compares lower than the object)J
312 128 :M
.585 .059(pointed at.  In other words, when performing an assignment, we need)J
312 136 :M
.358 .036(only check that the ordering is preserved:)J
316 145 :M
f5_7 sf
-.196(component\(p\) := q;       /* p,q pointers; assert\(p)A
cF
f6_7 sf
-.196<B3>A
sf
-.196(q\). */)A
312 155 :M
f2_8 sf
1.017 .102(Statistically, most component assignments in higher level languages)J
312 163 :M
.374 .037(will respect the TRO rule, because component assignments are usually)J
312 171 :M
1.275 .127(used to initialize components of newer data structures to reference)J
312 183 :M
.632 .063(older ones.)J
f2_9 sf
0 -3 rm
.17(2)A
0 3 rm
f2_8 sf
.443 .044(  The main exceptions to this observation are assigning to)J
312 191 :M
.225 .023(\(more\) global variables and returning values.  By assigning a pointer to)J
312 199 :M
.632 .063(a global variable, we are very likely to violate TRO because our lazy)J
312 207 :M
.252 .025(allocation will allocate everything on the stack.)J
312 217 :M
.649 .065(Since most function returns result in binding a variable in the caller's)J
312 225 :M
2.098 .21(frame, they can have the same effect on returned values as an)J
312 233 :M
.292 .029(assignment to a global variable\321eviction.  In some cases, this eviction)J
312 241 :M
.45 .045(can be avoided by having the caller allocate the space for the returned)J
312 249 :M
.998 .1(result in his own frame, and passing a reference to this space as an)J
312 257 :M
1.501 .15(additional argument.  This technique, which we call "caller result)J
312 265 :M
.511 .051(allocation" has been used since the early 1960's in Fortran, Cobol and)J
312 273 :M
.637 .064(PL/I compilers.  There are two problems with caller result allocation.)J
312 281 :M
.488 .049(First, when the called routine attempts to initialize any components of)J
312 289 :M
3.274 .327(this structure, these assignments may cause eviction of the)J
312 297 :M
1.289 .129(components.  Second, caller result allocation only works when the)J
312 305 :M
2.256 .226(caller knows the size of the object being returned in advance.)J
312 313 :M
1.436 .144(Nevertheless, it can be used to reduce the number of evictions of)J
312 325 :M
.854 .085(returned values.)J
f2_9 sf
0 -3 rm
(3)S
0 3 rm
312 335 :M
f2_8 sf
.881 .088(When a TRO violation is about to take place, the system executes a)J
312 343 :M
1.534 .153("transporter trap" [Moon84], which evicts the target object of the)J
312 351 :M
.938 .094(pointer from the stack into the heap.  The process of relocating this)J
312 359 :M
.915 .092(object can cause recursive transporter traps, however, when pointers)J
312 367 :M
.618 .062(which are components of the object being relocated are discovered to)J
312 375 :M
1.15 .115(also point into the heap.  If relocation of the object, installation of)J
312 383 :M
2.399 .24(forwarding addresses, and updating pointer components are all)J
312 391 :M
.991 .099(performed in the correct order, this recursion will terminate.  When)J
312 399 :M
.618 .062(the recursion terminates, not only has the object causing the first trap)J
312 407 :M
2.141 .214(been relocated out of the stack, but so have all of the objects)J
312 415 :M
.464 .046(accessible from it.  When the original trap has completed, the updated)J
312 423 :M
1.656 .166(address is then used to complete the assignment operation which)J
312 431 :M
.501 .05(caused that trap.)J
312 441 :M
1.225 .123(Since forwarding addresses are left for every non-functional object)J
312 449 :M
1.268 .127(which is evicted in this manner, references from machine registers)J
312 457 :M
1.438 .144(and from objects still in the stack to the evictee can follow these)J
312 465 :M
.983 .098(forwarding addresses to find the moved object.  A functional \(read-)J
312 473 :M
1.49 .149(only\) object still in the stack does not need a forwarding address)J
312 485 :M
1.982 .198(because the stack original is equivalent to the heap copy,)J
f2_9 sf
0 -3 rm
.726(4)A
0 3 rm
f2_8 sf
1.682 .168( and)J
312 493 :M
.346 .035(continues to function correctly until the frame is exited, at which point)J
312 501 :M
1.614 .161(it is abandoned because no live references to it exist.  Thus, the)J
312 509 :M
.426 .043(transporter traps caused by attempted violations of the TRO rule serve)J
312 517 :M
.786 .079(to relocate the objects so that the TRO rule is preserved, and so that)J
312 525 :M
.385 .038(the semantics of the objects themselves are also preserved.)J
-4096 -4095 -1 1 -4094 -4095 1 -4096 -4096 @a
312 581.24 -.24 .24 455.24 581 .24 312 581 @a
312 592 :M
f2_9 sf
.223(2)A
f2_8 sf
0 3 rm
.885 .089(On architectures without special TRO-checking hardware, common)J
0 -3 rm
312 603 :M
.33 .033(cases like initialization can be easily recognized and optimized.)J
312 613 :M
f2_9 sf
.088(3)A
f2_8 sf
0 3 rm
.293 .029(Functions in expression-oriented languages like Lisp will often return)J
0 -3 rm
312 624 :M
.809 .081(values which are never used when the function is called for its side-)J
312 632 :M
2.579 .258(effects rather than for its returned values\321e.g., )J
f5_8 sf
.969(print)A
f2_8 sf
1.328 .133(.  An)J
312 640 :M
.292 .029(important optimization when using lazy allocation is to inform a called)J
312 648 :M
.87 .087(function when results are not expected, so that eviction of unneeded)J
312 656 :M
1.821 .182(results is not performed; this )J
f0_8 sf
3.216 .322(result expectation)J
f2_8 sf
2.243 .224( optimization is)J
312 664 :M
.25 .025(discussed in a later section.)J
312 674 :M
f2_9 sf
.372(4)A
f2_8 sf
0 3 rm
1.197 .12(If the language offers an address-comparison operator \(e.g. Lisp's)J
0 -3 rm
312 685 :M
f5_8 sf
.204(EQ\))A
f2_8 sf
.568 .057( for functional objects, then forwarding pointers will be required.)J
312 693 :M
.535 .053([Baker93] argues for a more comprehensive and portable treatment of)J
312 701 :M
1.085 .108(such an )J
f0_8 sf
2.11 .211(object identity)J
f2_8 sf
1.396 .14( predicate so that functional objects can be)J
312 709 :M
1.519 .152(relocated without requiring the checking or leaving of forwarding)J
312 717 :M
.029(pointers.)A
endp
%%Page: 3 3
%%BeginPageSetup
initializepage
(Henry Baker; page: 3 of 10)setjob
%%EndPageSetup
-31 -31 :T
gS 31 31 552 730 rC
72 45 :M
f0_12 sf
.286 .029(ACM Sigplan Notices  )J
f1_12 sf
.095(27)A
f2_12 sf
.435 .044(,3 \(March 1992\),24-34.)J
72 751 :M
-.033(Copyright \251 1988,1990,1991 Nimble Computer Corporation)A
498 751 :M
(3)S
72 78 :M
f2_8 sf
1.18 .118(Let us call a stack which does not violate TRO )J
f0_8 sf
.394(well-ordered)A
f2_8 sf
.732 .073(.  By)J
72 86 :M
.979 .098(preserving the Temporary Restraining Order, we have the following)J
72 94 :M
.081(theorem:)A
72 104 :M
8 f3_1 :p
31.747 :m
.411(Theorem)A
1.024 .102(.  If a frame from a well-ordered stack is popped, and the)J
72 113 :M
.627 .063(registers contain no references to the popped frame, then no dangling)J
72 121 :M
.786 .079(references are created by the pop.)J
72 131 :M
64.391 :m
1.158 .116(Proof by induction)J
.909 .091(.  The only dangling references could come from)J
72 140 :M
.212 .021(the registers, further down in the stack, or the heap.  By hypothesis, the)J
72 148 :M
1.044 .104(registers have no pointers to the popped frame.  There is no higher)J
72 156 :M
1.813 .181(stack frame, hence no references from the stack above.  Due to)J
72 164 :M
.529 .053(transporter traps, there are no references from down the stack or from)J
72 172 :M
1.425 .142(the heap.  Therefore, the only references to the popped frame are)J
72 180 :M
1.918 .192(from the popped frame itself, in which case the entire frame is)J
72 188 :M
.681 .068(garbage.  QED.)J
72 198 :M
.153 .015(Since the stack in our model is restricted to )J
f0_8 sf
.047(transient)A
f2_8 sf
.126 .013( objects, it is like a)J
72 206 :M
.571 .057("flophouse" hotel.  Since such an address is not respectable, one does)J
72 214 :M
.259 .026(not give it out.  In order to put down "roots", one must move to a more)J
72 222 :M
.57 .057(respectable address in the permanent heap.)J
72 234 :M
f1_8 sf
.035(4.\312\312Complexity)A
72 243 :M
f2_8 sf
.724 .072(Stack allocation has recently come under attack as being slower than)J
72 251 :M
3.021 .302(garbage-collected heap allocation under certain circumstances)J
72 259 :M
.699 .07([Appel87a].  Since many of the benefits of lazy allocation are lost in)J
72 267 :M
.377 .038(this instance, we must first demonstrate that stack allocation retains its)J
72 275 :M
.242 .024(advantage under most conditions.)J
72 285 :M
2.748 .275(As [Baker78a] and [Appel87a] demonstrate, the cost of heap)J
72 293 :M
2.467 .247(allocation can be reduced to approximately the same as stack)J
72 301 :M
.492 .049(allocation.  This reduction is achieved by increasing real memory size)J
72 309 :M
1.184 .118(\(relative to the program\) so that the number of garbage collections)J
72 317 :M
.624 .062(\(which are really heap copies\) is reduced.  With enough memory, the)J
72 325 :M
.658 .066(amortized cost of garbage collection \(heap copying\) approaches zero,)J
72 333 :M
1.237 .124(so that the cost of allocation \(incrementing a pointer\) becomes the)J
72 341 :M
.723 .072(dominant cost.  Since the cost of stack allocation/deallocation is also)J
72 349 :M
.681 .068(the incrementation/decrementation of a pointer, the costs of heap and)J
72 357 :M
.316 .032(stack allocation become similar.)J
72 367 :M
.48 .048(This reduction in execution time is only achieved, however, through a)J
72 375 :M
.733 .073(tremendous increase in the size of real memory.  Using the model in)J
72 383 :M
2.729 .273(either [Baker78a] or [Appel87a], the allocation time becomes)J
72 391 :M
.573 .057(independent of the memory size only when the fraction of space used)J
72 399 :M
.6 .06(is negligible\321i.e., at least an order of magnitude smaller!  Even with)J
72 407 :M
1.257 .126(the exponential reduction in memory prices over the last 30 years,)J
72 415 :M
1.289 .129(CPU prices have fallen even faster, resulting in an ever-increasing)J
72 423 :M
.39 .039(fraction of system costs tied up in memory.  These trends indicate that)J
72 431 :M
.47 .047(the use of garbage collection to simulate stack allocation is a waste of)J
72 439 :M
.425 .042(resources.  Stack allocation, on the other hand, operates with the same)J
72 447 :M
.682 .068(efficiency \(for those objects having LIFO behavior\) whether memory)J
72 455 :M
.37 .037(is nearly empty or nearly full.  Therefore, the "space-time product" for)J
72 463 :M
.448 .045(stack allocation is better than that for garbage collection whenever the)J
72 471 :M
.237 .024(utilization of memory is greater than a small fraction.)J
72 481 :M
3.296 .33(The growing popularity of "generational garbage collectors")J
72 489 :M
.578 .058([Lieberman83] [Unger84] [Appel89] is an indication that the efficient)J
72 497 :M
.501 .05(use of real memory is relatively important in most applications.  Lazy)J
72 505 :M
1.922 .192(allocation can be viewed as a variation on generational garbage)J
72 513 :M
.532 .053(collection in which individual objects are generations, and tenuring to)J
72 521 :M
.201 .02(the heap is immediate.)J
72 531 :M
.694 .069(Because lazy allocation copies objects, it is an interesting exercise to)J
72 539 :M
.782 .078(compare the complexity of our model with that of a straight-forward)J
72 547 :M
1.227 .123(copying garbage collector such as Cheney's [Cheney70].  We have)J
72 555 :M
.566 .057(shown in [Baker78a] that the amortized cost of allocation in a system)J
72 563 :M
.344 .034(with a copying garbage collector is linearly proportional to the amount)J
72 571 :M
1.344 .134(of space being allocated; the constant of proportionality is a more)J
72 579 :M
.618 .062(complex expression depending upon the occupancy factor of the total)J
72 587 :M
.203 .02(amount of storage under management.  Since we must usually initialize)J
72 595 :M
1.411 .141(an object being allocated, and this initialization process is usually)J
72 603 :M
.42 .042(linearly proportional to the size of the object being allocated, the most)J
72 611 :M
1.254 .125(we can hope for from our lazy stack model is a better constant of)J
72 619 :M
.185 .019(proportionality than in the uniform heap-allocation model.)J
72 629 :M
1.465 .146(Allocating an object on the stack is virtually the same process as)J
72 637 :M
1.422 .142(allocating an object in a compact heap because it involves only a)J
72 645 :M
.609 .061(movement of the free space pointer.  Deallocation of a stack frame is)J
72 653 :M
1.231 .123(essentially free, since the stack frame need not be scanned.  Well-)J
72 661 :M
.774 .077(ordering violations can occur, however, resulting in the relocation of)J
72 669 :M
.379 .038(objects from the stack.  The total size of the relocated objects during a)J
72 677 :M
1.475 .147(recursive transportation trap cannot exceed the current size of the)J
312 78 :M
1.611 .161(stack, and once an object is relocated to the heap, it will not be)J
312 90 :M
1.012 .101(relocated again.)J
f2_9 sf
0 -3 rm
(5)S
0 3 rm
312 100 :M
f2_8 sf
.693 .069(Thus, in the worst case, every object is allocated on the stack, and is)J
312 108 :M
.936 .094(then relocated to the heap.  This is a worst case in storage, because)J
312 116 :M
.618 .062(since every object was allocated once on the stack and then relocated)J
312 124 :M
.808 .081(to the heap, the storage on the stack is no longer occupied \(until the)J
312 132 :M
.77 .077(frame is popped\).  It is a worst case in time, because every object is)J
312 140 :M
1.205 .121(allocated first on the stack and then relocated to the heap, when it)J
312 148 :M
.328 .033(could have been allocated directly on the heap in the first place.  If the)J
312 156 :M
.346 .035(cost of moving an object exceeds the cost of building it directly on the)J
312 164 :M
.733 .073(heap, then our model will result in poorer performance than the pure)J
312 172 :M
.37 .037(compact heap model.  \(This analysis does not count the added costs of)J
312 180 :M
.741 .074(constantly checking for objects which may have moved, so that their)J
312 188 :M
.431 .043(forwarding pointers may be followed.\))J
312 198 :M
1.753 .175(The literature indicates, however, that while the worst case )J
f0_8 sf
.927(may)A
312 206 :M
f2_8 sf
.572 .057(occur, the most common cases are LIFO allocation of objects.  If this)J
312 214 :M
.589 .059(is the case, then most objects will get allocated on the stack, and will)J
312 226 :M
.88 .088(become inaccessible before the stack frame is popped.)J
f2_9 sf
0 -3 rm
.28(6)A
0 3 rm
f2_8 sf
.473 .047(  As a result,)J
312 234 :M
1.297 .13(most of these objects will never be evicted from the heap.  Those)J
312 242 :M
1.164 .116(objects which are evicted will require somewhat more effort to get)J
312 250 :M
.543 .054(them relocated to the heap, but in these cases we do not begrudge the)J
312 258 :M
.987 .099(additional effort because 1\) these objects are still accessible, and 2\))J
312 266 :M
.968 .097(we have saved so much time as a result of stack allocating the vast)J
312 274 :M
.849 .085(majority of objects, that we can afford to be more generous in these)J
312 282 :M
.735 .074(few instances.)J
312 292 :M
1.102 .11(The programmer himself usually has a very good idea about which)J
312 300 :M
1.698 .17(allocated objects are likely to have stack-like extents, and which)J
312 308 :M
.243 .024(objects are not.  If he knows that a particular object is almost certain to)J
312 316 :M
1.446 .145(cause a well-ordering trap, he can allocate it directly on the heap)J
312 324 :M
.462 .046(himself, and save the system the time and expense of figuring this out)J
312 332 :M
.598 .06(for itself.  The programmer can indicate this information either in the)J
312 340 :M
.536 .054(form of a declarative "hint", or by calling an allocation routine with a)J
312 348 :M
1.024 .102(different name.  In either case, the percentage of objects which can)J
312 356 :M
.41 .041(be successfully reclaimed by lazy allocation will be greatly increased.)J
312 366 :M
4.001 .4(By using "continuation-passing style"\321discussed later\321the)J
312 374 :M
1.057 .106(programmer can extend the lifetime on the stack of values returned)J
312 382 :M
2.181 .218(from functions, and thereby gain efficiency not easily obtained)J
312 390 :M
2.118 .212(through more traditional optimizations.  We conjecture that the)J
312 398 :M
.782 .078(majority of objects reclaimed early by "ephemeral" or "generational")J
312 406 :M
1.211 .121(garbage collectors are extremely temporary objects which could be)J
312 414 :M
.944 .094(more efficiently stack-allocated using continuation-passing style and)J
312 422 :M
.453 .045(lazy allocation.)J
312 432 :M
1.802 .18(Lazy allocation utilizes forwarding pointers to correctly preserve)J
312 440 :M
.233 .023("object identity".  Since we have assumed that the heap already utilizes)J
312 448 :M
.339 .034(forwarding pointers in its management, lazy stack allocation will exact)J
312 456 :M
.394 .039(no additional penalty.  Brooks's forwarding scheme [Brooks84] can be)J
312 464 :M
1.619 .162(used to advantage, since its overhead on a cached architecture is)J
312 472 :M
1.875 .188(rather small.  As we discuss later, functional objects require no)J
312 480 :M
.969 .097(forwarding pointers, in which case all overhead is concentrated into)J
312 488 :M
.222 .022(assignment operations.)J
312 498 :M
.654 .065(In real architectures, there may be additional savings from our model)J
312 506 :M
.5 .05(that will not show up in raw instruction counts.  Modern architectures)J
312 514 :M
.392 .039(have smaller, faster memory banks which )J
f0_8 sf
.108(cache)A
f2_8 sf
.34 .034( the most heavily used)J
312 522 :M
1.143 .114(memory locations.  Between the effects of caching and paging, the)J
312 530 :M
.67 .067(amortized cost of cached memory references can be up to )J
f0_8 sf
.216(two)A
f2_8 sf
.772 .077( orders)J
312 538 :M
1.061 .106(of magnitude faster than the cost of non-cached memory references)J
312 546 :M
.453 .045([Jouppi90].  Since our model attempts to keep everything on the stack)J
312 554 :M
1.199 .12(as long as possible, it is likely to have more local behavior than a)J
312 566 :M
.683 .068(model which allocates objects directly on the heap.)J
f2_9 sf
0 -3 rm
.227(7)A
0 3 rm
f2_8 sf
.477 .048(  If the hardware)J
312 574 :M
.279 .028(memory system knows that this is a stack, additional optimizations can)J
312 582 :M
.444 .044(be made, such as not writing back popped stack frames to the backing)J
312 590 :M
.091(store.)A
312 600 :M
1.073 .107(Another optimization possible with our model is the inlining of the)J
312 608 :M
1.063 .106(allocation routine itself.  In this case, the initializing information is)J
312 616 :M
.237 .024(copied directly into the appropriate locations.  For example, a Lisp-like)J
312 624 :M
2.417 .242(z:=CONS\(x,y\) is just "t1:=x;t2:=y;z:=addr\(t1\)", where t1,t2 are)J
-4096 -4095 -1 1 -4094 -4095 1 -4096 -4096 @a
312 629.24 -.24 .24 455.24 629 .24 312 629 @a
312 640 :M
f2_9 sf
.246(5)A
f2_8 sf
0 3 rm
.666 .067(We here assume that there is no sharing of functional objects, since)J
0 -3 rm
312 651 :M
.858 .086(eviction unshares them due to the lack of forwarding pointers.  This)J
312 659 :M
.544 .054(assumption is generally true, but if functional objects are to be highly)J
312 667 :M
.527 .053(shared, then forwarding pointers should be checked and left as if they)J
312 675 :M
.576 .058(were non-functional objects.)J
312 685 :M
f2_9 sf
.563(6)A
f2_8 sf
0 3 rm
1.573 .157(These statistics can be improved through the )J
0 -3 rm
f0_8 sf
0 3 rm
2.645 .264(result expectation)J
0 -3 rm
312 696 :M
f2_8 sf
.142 .014(optimization, discussed later.)J
312 706 :M
f2_9 sf
.569(7)A
f2_8 sf
0 3 rm
1.931 .193([Stanley87] reports a phenomenally large reference locality for)J
0 -3 rm
312 717 :M
.596 .06(stack caches, as opposed to other data references.)J
endp
%%Page: 4 4
%%BeginPageSetup
initializepage
(Henry Baker; page: 4 of 10)setjob
%%EndPageSetup
-31 -31 :T
gS 31 31 552 730 rC
72 45 :M
f0_12 sf
.286 .029(ACM Sigplan Notices  )J
f1_12 sf
.095(27)A
f2_12 sf
.435 .044(,3 \(March 1992\),24-34.)J
72 751 :M
-.033(Copyright \251 1988,1990,1991 Nimble Computer Corporation)A
498 751 :M
(4)S
72 78 :M
f2_8 sf
2.293 .229(adjacent locations )J
f0_8 sf
2.1 .21(known to the compiler)J
f2_8 sf
1.745 .174(, and the compiler can)J
72 86 :M
.46 .046(therefore optimize out the incrementation of the allocation pointer.  In)J
72 94 :M
.599 .06(a system without a lazy allocation routine, one would need additional)J
72 102 :M
1.534 .153(register shuffling, followed by storage to an unknown location of)J
72 110 :M
.72 .072(memory, even when the allocation routine itself was inlined.  Such a)J
72 118 :M
.594 .059(routine would be slower than our lazy allocation\321perhaps as slow as)J
72 126 :M
.743 .074(an out-of-line procedure.)J
72 136 :M
1.574 .157(A new generation of shared-memory "symmetric multiprocessing")J
72 144 :M
.819 .082(\(SMP\) machines is starting to be utilized for tasks requiring flexibly)J
72 152 :M
1.777 .178(allocated storage.  On such machines a global storage allocation)J
72 160 :M
.143 .014(routine must be protected by a lock to avoid inconsistency and this lock)J
72 168 :M
.538 .054(can become a performance bottleneck.  If the allocation responsibility)J
72 176 :M
.112 .011(is split up so that each processor has its own allocator, this bottleneck is)J
72 184 :M
1.311 .131(removed.  Lazy allocation elegantly achieves such a split, because)J
72 192 :M
1.375 .137(each processor already has its own stack, and lazy allocation may)J
72 200 :M
1.179 .118(reduce the allocation demand enough so that permanent allocations)J
72 208 :M
.267 .027(can be made using a global, shared allocator without undue contention.)J
72 220 :M
f1_8 sf
-.074(5.\312\312Applications)A
72 231 :M
.104(A.\312\312Malloc/New)A
72 241 :M
f2_8 sf
.343 .034(The most straight-forward application of lazy allocation is a version of)J
72 249 :M
.174 .017(C's )J
f5_8 sf
.098(malloc)A
f2_8 sf
.232 .023( or Pascal/Ada's )J
f5_8 sf
.098(new)A
f2_8 sf
.251 .025( which allocates the object within the)J
72 257 :M
.963 .096(current stack frame\321expanding it if necessary.  In other words, C's)J
72 265 :M
f5_8 sf
.927(malloc)A
f2_8 sf
2.113 .211( becomes equivalent to the old )J
f5_8 sf
.927(alloca)A
f2_8 sf
1.759 .176(.  With lazy)J
72 273 :M
.507 .051(allocation, one never calls the heap )J
f5_8 sf
.206(malloc)A
f2_8 sf
.096(/)A
f5_8 sf
.206(new)A
f2_8 sf
.538 .054( directly, but leaves)J
72 281 :M
.714 .071(it to the eviction trap to call these routines.  Since ephemeral objects)J
72 289 :M
1.017 .102(will be deallocated automatically when the enclosing stack frame is)J
72 297 :M
.524 .052(exited, )J
f5_8 sf
.192(free)A
f2_8 sf
.156 .016( \()J
f5_8 sf
.192(dispose)A
f2_8 sf
.509 .051(\) needn't do anything when handed a pointer)J
72 305 :M
.452 .045(into the stack.  However, for a small cost, some error checking can be)J
72 313 :M
1.491 .149(gained by marking the stack object as free, so that any access or)J
72 321 :M
.355 .036(attempted eviction will cause an error trap instead.)J
72 333 :M
f1_8 sf
-.019(B.\312\312Functional Arguments)A
72 343 :M
f2_8 sf
2.574 .257(The correct implementation of functional/procedural arguments)J
72 351 :M
.631 .063(\("funargs" [Moses70]\) in higher level languages is quite complicated.)J
72 359 :M
1.176 .118(The creators of the DoD standard Ada language were so fearful of)J
72 367 :M
.661 .066(these constructs, that they were summarily banned from the language)J
72 375 :M
5.612 .561([STEELMAN78, Requirement 5D].  In transmitting a)J
72 383 :M
2.321 .232(functional/procedural argument, not only must a pointer to the)J
72 391 :M
.226 .023(executable instructions be passed, but also a pointer to the environment)J
72 399 :M
.782 .078(of the function.  This is because a function defined at a lexical level)J
72 407 :M
1.047 .105(other than the topmost level may refer to local variables of another)J
72 415 :M
.787 .079(function.  These variables are not local to the function being passed,)J
72 423 :M
.605 .061(and they are referred to as "free" variables.)J
72 433 :M
1.039 .104(Some languages such as C finesse the free variable problem by not)J
72 441 :M
.224 .022(allowing functions to be defined at other than the topmost lexical level.)J
72 449 :M
1.006 .101(In this case, all free variables are global, and since global variables)J
72 457 :M
.866 .087(can be statically allocated, their addresses can be embedded into the)J
72 465 :M
.721 .072(instruction stream so that an additional environment pointer need not)J
72 473 :M
1.271 .127(be passed.  Much expressive power is lost in the language by this)J
72 481 :M
.678 .068(restriction, however.)J
72 491 :M
.732 .073(More powerful languages such as Algol, PL/I, Pascal and Lisp allow)J
72 499 :M
2.384 .238(the definition of functions and procedures within inner lexical)J
72 507 :M
.479 .048(contexts, and therefore must package up pointers to both the code and)J
72 515 :M
.947 .095(the environment when passing a function/procedure as an argument.)J
72 523 :M
.46 .046(While this involves more work, these functional/procedural arguments)J
72 531 :M
1.089 .109(are strictly more powerful than C-style functional arguments.  True)J
72 539 :M
2.828 .283(functional arguments are capable of simulating arbitrary data)J
72 547 :M
1.549 .155(structures\321at least within their lifetimes\321and therefore the work)J
72 555 :M
1.781 .178(necessary to allocate a new structure for their implementation is)J
72 563 :M
.169(required.)A
72 573 :M
.755 .076(Algol, PL/I and Pascal have carefully restricted the use of functional)J
72 581 :M
.573 .057(arguments to make sure that they can never escape the lifetime of the)J
72 589 :M
2.191 .219(stack frame in which they were created.  As a result of these)J
72 597 :M
.489 .049(restrictions, functional arguments can be safely allocated on the stack.)J
72 605 :M
1.014 .101(Therefore, these objects are not "first-class".  Part of the reason for)J
72 613 :M
1.029 .103(these language restrictions has to do with dangling references.  If a)J
72 621 :M
1.185 .119(functional argument refers to objects on the stack, and the stack is)J
72 629 :M
1.068 .107(popped to the point where these objects are no longer valid, then a)J
72 637 :M
.515 .051(dangling reference will be created which can cause nasty bugs.)J
72 647 :M
.5 .05(The restrictions on the use of functional arguments in Algol, PL/I and)J
72 655 :M
.88 .088(Pascal are rather arbitrary and constrain the expressive power of the)J
72 663 :M
.361 .036(programming language, although not so much as the restrictions of the)J
72 671 :M
2.029 .203(C language.  Several modern languages like Common Lisp and)J
72 679 :M
2.582 .258(Scheme offer "first-class" functional arguments, which can be)J
72 687 :M
.911 .091(returned from functions and stored in data structures.  However, the)J
72 695 :M
.704 .07(efficiency impact of this freedom is normally quite severe.  Not only)J
72 703 :M
1.268 .127(must the functional arguments themselves now be allocated on the)J
72 711 :M
.517 .052(heap, but much of the normal variable-binding environment must also)J
312 78 :M
1.803 .18(be heap-allocated.  Only in this way can dangling references be)J
312 86 :M
.097(avoided.)A
312 96 :M
2.659 .266(Lazy allocation can solve the problem of allowing functional)J
312 104 :M
.512 .051(arguments to be first-class, while keeping stack allocation for the vast)J
312 112 :M
1.693 .169(majority of these objects that do not escape the lifetime of their)J
312 120 :M
1.886 .189(creators.  In the case of Lisp languages like Common Lisp and)J
312 128 :M
.374 .037(Scheme, the environment stack is kept separate from the control stack,)J
312 136 :M
.311 .031(so that lazy allocation "almost" works without any change.  A problem)J
312 144 :M
.561 .056(which occurs in any language which offers both functional arguments)J
312 152 :M
.879 .088(and side-effects, however, is making sure that the object being side-)J
312 160 :M
.786 .079(effected is "the" object, rather than a copy of it.  In particular, when)J
312 168 :M
.792 .079(one creates multiple funargs which share the same free variable, and)J
312 176 :M
.477 .048(one or both of the funargs side-effect this variable, it is important that)J
312 184 :M
.778 .078(the side-effect be visible to all of the funargs.  The usual solution to)J
312 192 :M
.858 .086(this problem is to allocate a unique assignable "cell" in the heap for)J
312 200 :M
.398 .04(each such variable, which is then bound as the "value" of the variable;)J
312 212 :M
1.049 .105([Kranz88] calls this transformation )J
f0_8 sf
1.646 .165(assignment conversion)J
f2_8 sf
.14(.)A
f2_9 sf
0 -3 rm
.314(8)A
0 3 rm
f2_8 sf
.645 .064(  When)J
312 220 :M
.852 .085(multiple funargs are created which reference this variable, then each)J
312 228 :M
.644 .064(will then reference the same cell.  The Common Lisp example below)J
312 236 :M
-.063(exhibits this situation.)A
316 245 :M
f5_7 sf
-.203(\(let* \(\(x 3\)\)         ; Create cell x initialized to 3.)A
316 252 :M
-.212(  \(\(lambda \(y z\))A
316 259 :M
-.203(     \(let* \(\(ex x\)    ; Get the current value of x \(= 3\).)A
316 266 :M
-.206(            \(ey \(y\)\)  ; x <- 4)A
316 273 :M
-.203(            \(ez \(z\)\)\) ; New current value of x \(= 4\).)A
316 280 :M
-.208(       \(list ex ey ez\)\)\))A
316 287 :M
-.203(   #'\(lambda \(\) \(setq x 4\) x\)  ; Funarg with free var. x.)A
316 294 :M
-.203(   #'\(lambda \(\) x\)\)\)  ; Funarg with free var. x.)A
316 301 :M
-.221(=> \(3 4 4\))A
312 311 :M
f2_8 sf
1.241 .124(Unfortunately, assignment conversion is very expensive, because it)J
312 319 :M
.46 .046(causes )J
f0_8 sf
.118(every)A
f2_8 sf
.398 .04( variable to be bound to such a heap-allocated cell, unless)J
312 327 :M
.904 .09(it can be statically shown that either 1\) the cell is never assigned to)J
312 335 :M
1.851 .185(after initialization, or 2\) the cell is never shared among funargs)J
312 343 :M
2.326 .233([Kranz86] [Kranz88].  Using lazy allocation, however, we can)J
312 351 :M
1.488 .149(cheaply allocate an assignable cell for every variable in the same)J
312 359 :M
.31 .031(stack frame as the variable itself, and this cell will only be relocated to)J
312 371 :M
1.225 .122(the stack when it tries to escape from that stack frame's lifetime.)J
f2_9 sf
0 -3 rm
(9)S
0 3 rm
312 379 :M
f2_8 sf
1.292 .129(Thus, lazy allocation can be used for both the funarg environment)J
312 387 :M
1.317 .132(itself, as well as the assignable cells, so that in the most common)J
312 395 :M
.61 .061(situations all of the allocations for funargs occur on the stack and are)J
312 403 :M
.571 .057(never relocated to the heap.)J
312 413 :M
.881 .088(In the case of non-Lisp languages, where the environment stack and)J
312 421 :M
.794 .079(the control stack are usually merged, we must be more careful.  The)J
312 429 :M
.162 .016(simplest solution would be to utilize lazy allocation on the stack frames)J
312 437 :M
.872 .087(themselves, which would work because any frame relocated into the)J
312 445 :M
1.26 .126(heap would leave a forwarding address for any other object which)J
312 453 :M
.804 .08(pointed to it.  Unfortunately, the eviction of one stack frame has the)J
312 461 :M
.452 .045(undesired effect of immediately evicting all of the stack frames nearer)J
312 469 :M
.52 .052(to the bottom of the stack as well.  When using such a policy, the top)J
312 477 :M
.778 .078(stack frame's eviction causes the entire stack to be relocated into the)J
312 485 :M
.608 .061(heap.  While there may be occasions where this massive relocation is)J
312 493 :M
.671 .067(desired \(see the later section on Scheme continuations\), this policy is)J
312 501 :M
.293 .029(usually overkill for funargs.)J
312 511 :M
1.537 .154(A better solution for implementing first-class funargs in non-Lisp)J
312 519 :M
1.485 .149(languages would be to more closely follow the Lisp example.  A)J
312 527 :M
.479 .048(funarg environment need only retain the bindings of the variables free)J
312 535 :M
1.096 .11(in the function being passed, so the funarg environment could be a)J
312 543 :M
2.633 .263(simple vector of these variable values.  Of course, the same)J
312 551 :M
.834 .083("assignable cell" indirection must be made for free variables in non-)J
312 559 :M
1.582 .158(Lisp languages that we demonstrated above for Lisp.  Since lazy)J
312 567 :M
1.61 .161(allocation allows both the assignable cells and these environment)J
312 575 :M
.704 .07(vectors to be \(initially\) stack-allocated, we get excellent performance)J
312 583 :M
.496 .05(until a funarg is returned or stored into a global variable and becomes)J
312 591 :M
.083(first-class.)A
312 603 :M
f1_8 sf
-.004(C.\312\312Lazy Argument Evaluation)A
312 613 :M
f2_8 sf
.735 .073(Lazy evaluation of the arguments of a function call is the deferral of)J
312 621 :M
1.978 .198(the evaluation of the argument expression until the argument is)J
312 629 :M
2.796 .28(actually "used".  Lazy evaluation of arguments can be more)J
312 637 :M
.941 .094(expressive and efficient than so-called "applicative" evaluation if an)J
-4096 -4095 -1 1 -4094 -4095 1 -4096 -4096 @a
312 650.24 -.24 .24 455.24 650 .24 312 650 @a
312 661 :M
f2_9 sf
.213(8)A
f2_8 sf
0 3 rm
.667 .067(Erik Sandewall circulated a memo describing the same technique in)J
0 -3 rm
312 672 :M
1.404 .14(1974 [Sandewall74]; Greenblatt utilized this idea in the MIT Lisp)J
312 680 :M
.916 .092(Machine [Greenblatt74].)J
312 690 :M
f2_9 sf
.669(9)A
f2_8 sf
0 3 rm
1.622 .162(On a machine with a cache, the variable and its cell should be)J
0 -3 rm
312 701 :M
2.363 .236(initially located in the same cache line, so that the additional)J
312 709 :M
.953 .095(indirection through the variable reference to the cell will execute as)J
312 717 :M
.031 .003(quickly as possible.)J
endp
%%Page: 5 5
%%BeginPageSetup
initializepage
(Henry Baker; page: 5 of 10)setjob
%%EndPageSetup
-31 -31 :T
gS 31 31 552 730 rC
72 45 :M
f0_12 sf
.286 .029(ACM Sigplan Notices  )J
f1_12 sf
.095(27)A
f2_12 sf
.435 .044(,3 \(March 1992\),24-34.)J
72 751 :M
-.033(Copyright \251 1988,1990,1991 Nimble Computer Corporation)A
498 751 :M
(5)S
72 78 :M
f2_8 sf
.924 .092(argument is never used, because the argument expression will never)J
72 86 :M
.819 .082(be evaluated.)J
72 96 :M
1.367 .137(Lazy evaluation appeared in Algol-60 under the guise of "call-by-)J
72 104 :M
1.762 .176(name", and was implemented by means of "thunks" [Randell64].)J
72 112 :M
1.142 .114(Thunks are quite similar to functional arguments, in that they have)J
72 120 :M
1.24 .124(some executable code and an environment in which to execute the)J
72 128 :M
1.321 .132(code.  In fact, the semantics of Scheme's )J
f5_8 sf
.588(delay)A
f2_8 sf
1.788 .179( expressions are)J
72 136 :M
.367 .037(given in terms of functional arguments [IEEE-Scheme90].)J
72 146 :M
.617 .062(As a result of the simple implementation of lazy argument evaluation)J
72 154 :M
2.448 .245(using functional arguments, lazy allocation will work for lazy)J
72 162 :M
1.203 .12(evaluation in the same way that it works for functional arguments.)J
72 170 :M
.997 .1(Most "lazy" arguments will be evaluated before their defining stack)J
72 178 :M
1.246 .125(frame is exited, and those that have not, will most likely never be)J
72 186 :M
.997 .1(evaluated.  However, those that do escape from their defining stack)J
72 194 :M
.39 .039(frame will be evicted to the heap, where they will evaluate correctly if)J
72 202 :M
.547 .055(the need arises.)J
72 212 :M
.384 .038(The possibility of escaping Scheme )J
f5_8 sf
.135(delays)A
f2_8 sf
.424 .042( suggests an optimization)J
72 220 :M
.368 .037(that may sometimes be beneficial.  If a )J
f5_8 sf
.168(delay)A
f2_8 sf
.357 .036( is about to escape, one)J
72 228 :M
1.219 .122(may want to arrange for its immediate \("strict"\) evaluation.  If the)J
72 236 :M
f5_8 sf
.305(delay)A
f2_8 sf
.709 .071( is functional, then the time of its evaluation cannot affect its)J
72 244 :M
1.143 .114(value, yet this value may occupy less space than the )J
f5_8 sf
.499(delay)A
f2_8 sf
1.169 .117( itself)J
72 252 :M
.74 .074(\(zero if the value is an "immediate" quantity such as a floating point)J
72 260 :M
.909 .091(number\), thus improving heap utilization and performance.  We call)J
72 268 :M
.69 .069(the evaluation order resulting from this optimization "downward lazy)J
72 276 :M
.97 .097(evaluation", due to its similarity to "downward funargs"\321i.e., those)J
72 284 :M
.333 .033(functional arguments that obey stack ordering.)J
72 296 :M
f1_8 sf
-.01(D.\312\312Argument "Lists")A
72 306 :M
f2_8 sf
1.383 .138(Programming language designers have long been tantalized by the)J
72 314 :M
.37 .037(similarities between parameter lists and structured values \("records" or)J
72 322 :M
.998 .1("structures"\).  For example, Ada utilizes nearly the same syntax for)J
72 330 :M
.425 .042(declarations of both, and nearly the same syntax for function calls and)J
72 338 :M
.952 .095(record "aggregates" [Ada83].  Lisp semantics presume the existence)J
72 346 :M
1.122 .112(of a Lisp list of arguments [McCarthy65].  Yet nearly all language)J
72 354 :M
.814 .081(designers are forced to back down from unifying these two concepts)J
72 362 :M
.729 .073(due to the unacceptable loss of efficiency that would result.  Making)J
72 370 :M
1.336 .134(parameter lists into true first-class objects would force them to be)J
72 378 :M
1.001 .1(heap-allocated, with the concomitant problems of determining when)J
72 386 :M
.308 .031(and how to deallocate them.)J
72 396 :M
.37 .037(Lazy allocation offers the language designer the ability to unify record)J
72 404 :M
1.077 .108(structures and parameter lists without the loss of efficiency.  Every)J
72 412 :M
.562 .056(function and procedure can be elegantly defined as accepting just one)J
72 420 :M
.989 .099(parameter\321a record structure.  A function/procedure call constructs)J
72 428 :M
1.158 .116(an argument object on the stack by creating a new instance of this)J
72 436 :M
1.594 .159(structure initialized with the individual argument components.  A)J
72 444 :M
1.727 .173(pointer to this argument object is then passed to the function or)J
72 452 :M
.927 .093(procedure, where a "destructuring pattern match" of the argument is)J
72 460 :M
1.232 .123(made using the parameter record definition as a pattern.  Elegance)J
72 468 :M
2.048 .205(and power are obtained in two ways: the capabilities of record)J
72 476 :M
.507 .051(structures are made available to argument objects, and the capabilities)J
72 484 :M
1.203 .12(of argument objects \(e.g., pattern-matched )J
f0_8 sf
.269(destructuring)A
f2_8 sf
.946 .095(\) are made)J
72 496 :M
1.051 .105(available to record objects.)J
f2_9 sf
0 -3 rm
.318(10)A
0 3 rm
f2_8 sf
.796 .08(  Even more fascinating is the transfer)J
72 504 :M
2.776 .278(of other argument-passing ideas to data structures\321e.g., lazy)J
72 512 :M
.307 .031(evaluation becomes lazy component initialization [Friedman76].)J
72 522 :M
2.767 .277(In the most common case, argument objects are immediately)J
72 530 :M
.775 .078(destructured, and do not escape the lifetime of the called function or)J
72 538 :M
5.077 .508(procedure, and therefore can be deallocated when the)J
72 546 :M
1.561 .156(function/procedure returns.  However, should the argument object)J
72 554 :M
.482 .048(become first-class, it is evicted from the stack, and is thereby retained)J
72 562 :M
.59 .059(when the function/procedure returns.)J
72 572 :M
.706 .071(By giving argument objects a \(potentially\) first-class existence, some)J
72 580 :M
3.251 .325(efficiencies can be obtained.  For example, some recursive)J
72 588 :M
.95 .095(procedures pass on a number of arguments unchanged to successive)J
72 596 :M
.961 .096(recursions, where they are used only when the recursion terminates.)J
72 604 :M
1.079 .108(By passing a pointer to a portion of the argument object instead of)J
72 612 :M
.849 .085(copying these arguments, some effort can be saved.  Furthermore, if)J
72 620 :M
.667 .067(the number and/or size of these arguments are related to the depth of)J
72 628 :M
1.284 .128(the recursion, an algorithm that is quadratic in complexity may be)J
72 636 :M
.372 .037(reduced to linear complexity [Dybvig88].)J
72 648 :M
f1_8 sf
.257 .026(E.\312\312ANSI-C )J
f7_8 sf
.063(STDARG)A
f1_8 sf
.07('s)A
72 658 :M
f2_8 sf
1.236 .124(The programming language BCPL [Richards74], from which the C)J
72 666 :M
.578 .058(language descends, passed all arguments uniformly as a vector on the)J
72 674 :M
.822 .082(stack which could be accessed in exactly the same way as any other)J
-4096 -4095 -1 1 -4094 -4095 1 -4096 -4096 @a
72 679.24 -.24 .24 215.24 679 .24 72 679 @a
72 690 :M
f2_9 sf
.383(10)A
f2_8 sf
0 3 rm
.964 .096(So long as these argument objects are )J
0 -3 rm
f0_8 sf
0 3 rm
.276(functional)A
0 -3 rm
f2_8 sf
0 3 rm
1.25 .125( [Baker93], one)J
0 -3 rm
72 701 :M
1.284 .128(can still pass argument objects through RISC architecture registers)J
72 709 :M
.966 .097(rather than memory, because functional objects can be transparently)J
72 717 :M
.416 .042(copied\321even to a bank of registers.)J
312 78 :M
1.824 .182(vector.  This clean model depended upon a uniform size for all)J
312 86 :M
.569 .057(objects, and was therefore abandoned in C.  Until the development of)J
312 94 :M
1.248 .125(UNIX )J
f5_8 sf
.409(varargs)A
f2_8 sf
.805 .08( and then ANSI )J
f5_8 sf
.409(stdargs)A
f2_8 sf
.998 .1(, there was no portable)J
312 102 :M
1.582 .158(way to pass an arbitrary number of arguments to functions, most)J
312 110 :M
.676 .068(especially variants of )J
f5_8 sf
.246(printf)A
f2_8 sf
.529 .053(.  These portable forms offer a kind of)J
312 118 :M
.439 .044("stream" access to the argument "list", and the receiver of the variable)J
312 126 :M
.914 .091(argument "list" sequentially reads this stream, and provides the type)J
312 134 :M
.614 .061(information necessary to decode it.  These streams provide only data,)J
312 142 :M
.312 .031(and no pointers to these arguments are allowed.)J
312 152 :M
.296 .03(The )J
f5_8 sf
.138(stdargs)A
f2_8 sf
.342 .034( facility is currently the only facility that provides stack)J
312 160 :M
.702 .07(allocation of variable-sized quantities of storage in ANSI-C; ANSI-C)J
312 168 :M
1.153 .115(is highly tuned to allow only fixed-size stack frames whose size is)J
312 180 :M
1.654 .165(known by the compiler.)J
f2_9 sf
0 -3 rm
.509(11)A
0 3 rm
f2_8 sf
.781 .078(    With the demise of )J
f5_8 sf
.543(alloca)A
f2_8 sf
1.666 .167(, which)J
312 188 :M
1.6 .16(allocated variable-sized objects on the stack, ANSI-C's restriction)J
312 196 :M
2.404 .24(against taking the address of such an argument is particularly)J
312 204 :M
1.121 .112(obnoxious, because some applications of )J
f5_8 sf
.365(alloca)A
f2_8 sf
.911 .091( could have been)J
312 212 :M
.373 .037(\(painfully\) simulated using variable-sized )J
f5_8 sf
.11(stdargs)A
f2_8 sf
(.)S
312 222 :M
1.825 .183(Both )J
f5_8 sf
.748(stdargs)A
f2_8 sf
.97 .097( and )J
f5_8 sf
.748(varargs)A
f2_8 sf
1.982 .198( are ugly and non-modular, and)J
312 230 :M
.3 .03(introduce notions not used elsewhere in C.  Because C wants to charge)J
312 238 :M
.237 .024(all costs for variable-length argument lists to those functions which use)J
312 246 :M
.732 .073(them, these forms must not interfere with the passing of fixed-length)J
312 258 :M
2.03 .203(argument lists in registers \(the norm on RISC architectures\).)J
f2_9 sf
0 -3 rm
1.335(12)A
0 3 rm
312 266 :M
f2_8 sf
.189 .019(Because the simplest implementation of a stream is the incrementing of)J
312 274 :M
.878 .088(a pointer variable through a memory structure, the first step in most)J
312 282 :M
1.225 .123(implementations of )J
f5_8 sf
.358(va_start)A
f2_8 sf
.785 .078( is to store all of the register-passed)J
312 290 :M
.199 .02(arguments into memory, and then utilize simple pointer-stepping for all)J
312 298 :M
.989 .099(arguments.  Indeed, given the fact that the argument-reading stream)J
312 306 :M
.244 .024(may be passed on to additional functions, it is difficult to conceive of a)J
312 314 :M
1.38 .138(compiler smart enough to implement )J
f5_8 sf
.468(stdargs)A
f2_8 sf
.217(/)A
f5_8 sf
.468(varargs)A
f2_8 sf
.817 .082( in any)J
312 322 :M
.524 .052(other way.  The inability to create a pointer to a )J
f5_8 sf
.263(stdargs)A
f2_8 sf
.98 .098( argument)J
312 330 :M
.846 .085(is therefore unreasonably restrictive, since it almost certainly resides)J
312 338 :M
1.476 .148(in addressible memory.  Presumably, the no-pointers restriction is)J
312 346 :M
.604 .06(meant to protect the user from the particularities of storage allocation)J
312 354 :M
.413 .041(of the storage needed for the variable-length argument list, which may)J
312 362 :M
1.53 .153(be allocated by )J
f5_8 sf
.67(va_start)A
f2_8 sf
1.488 .149( and deallocated by )J
f5_8 sf
.67(va_end)A
f2_8 sf
1.181 .118(.  Such)J
312 370 :M
.433 .043(protection is out of character for C, since no such protections exist for)J
312 378 :M
.379 .038(other stack and heap-allocated objects.  Most implementations allocate)J
312 386 :M
1.566 .157(the storage needed for )J
f5_8 sf
.65(va_start)A
f2_8 sf
1.286 .129( on the main C stack \(using a)J
312 394 :M
1.401 .14(version of the now-banned )J
f5_8 sf
.507(alloca)A
f2_8 sf
1.267 .127(\), however, in which case the)J
312 402 :M
f5_8 sf
.474(va_end)A
f2_8 sf
1.098 .11( is extraneous.  Allocating storage for )J
f5_8 sf
.474(va_start)A
f2_8 sf
.828 .083( in any)J
312 410 :M
.842 .084(other place is almost certain to run afoul of )J
f5_8 sf
.394(longjmp)A
f2_8 sf
1.087 .109(, which must)J
312 418 :M
1.455 .146(then decode the stack and execute )J
f5_8 sf
.593(va_end)A
f2_8 sf
1.382 .138( for each stack frame)J
312 426 :M
2.746 .275(involving )J
f5_8 sf
.807(stdargs)A
f2_8 sf
1.43 .143( for which )J
f5_8 sf
.807(va_start)A
f2_8 sf
2.113 .211( was executed, but)J
312 434 :M
f5_8 sf
.129(va_end)A
f2_8 sf
.275 .028( was not.)J
312 444 :M
2.87 .287(A lazy allocation mechanism could dramatically simplify the)J
312 452 :M
f5_8 sf
.8(stdargs)A
f2_8 sf
2.135 .214( device of ANSI-C.  A new, first-class polymorphic)J
312 460 :M
.849 .085("stream" data structure could be defined which could be opened and)J
312 468 :M
.434 .043(read sequentially from a variable-length argument list.  Since this data)J
312 476 :M
1.117 .112(structure would exist either in the stack frame storage of either the)J
312 484 :M
.905 .091(calling or the called subprogram, no restrictions on taking addresses)J
312 492 :M
.414 .041(would be needed.  If any pointers survived, the targeted objects would)J
312 500 :M
.664 .066(be automatically moved into the heap.  Reading such a stream would)J
312 508 :M
1.01 .101(produce a truncated stream consisting of the rest of the list.  If any)J
312 516 :M
2.877 .288(stream \(")J
f5_8 sf
.897(ap)A
f2_8 sf
2.252 .225("\) pointers survived, then the "rest" of the stream)J
312 524 :M
.356 .036(\(including objects it referred to\) would be relocated to the heap.)J
312 536 :M
f1_8 sf
3.335 .334(F.\312\312Common Lisp )J
f7_8 sf
.936(&REST)A
f1_8 sf
2.779 .278( Arguments and Scheme ")J
f7_8 sf
2.16 .216(. z)J
f1_8 sf
(")S
312 544 :M
.099(Arguments)A
312 554 :M
f2_8 sf
1.624 .162(The semantics of the Lisp language were originally defined by a)J
312 562 :M
.489 .049("meta-circular" interpreter which created actual Lisp lists of evaluated)J
312 570 :M
3.419 .342(arguments as part of its evaluation of function application)J
312 578 :M
2.614 .261([McCarthy65].  While most modern Lisp implementations put)J
312 586 :M
.66 .066(evaluated arguments onto a stack instead of a list, Common Lisp and)J
312 594 :M
.543 .054(Scheme retain one vestige of the original Lisp evaluator\321the )J
f5_8 sf
.248(&REST)A
312 602 :M
f2_8 sf
.489 .049(argument.  Both Lisps allow for the passing of an arbitrary number of)J
312 610 :M
1.272 .127(arguments to a function, but the called function must somehow be)J
312 618 :M
1.086 .109(capable of addressing these arguments.  Common Lisp uses normal)J
-4096 -4095 -1 1 -4094 -4095 1 -4096 -4096 @a
312 626.24 -.24 .24 455.24 626 .24 312 626 @a
312 637 :M
f2_9 sf
.457(11)A
f2_8 sf
0 3 rm
1.348 .135(ANSI-C doesn't strictly require stack allocation \(on the main C)J
0 -3 rm
312 648 :M
1.079 .108(stack\) of variable-size argument lists, but any other implementation)J
312 656 :M
.597 .06(must deal with signals and )J
f5_8 sf
.254(setjmp)A
f2_8 sf
.118(/)A
f5_8 sf
.254(longjmp)A
f2_8 sf
.729 .073(, which require main-)J
312 664 :M
.504 .05(stack-allocation semantics.)J
312 674 :M
f2_9 sf
.284(12)A
f2_8 sf
0 3 rm
.851 .085(Curiously, arguments passed in registers are required to be stored)J
0 -3 rm
312 685 :M
1.887 .189(into memory upon entry to a function, unless the corresponding)J
312 693 :M
.992 .099(parameter is declared with a storage class of )J
f5_8 sf
.418(register)A
f2_8 sf
.948 .095( \(which is)J
312 701 :M
.437 .044(not the default\).  An optimization not always performed is to store the)J
312 709 :M
.933 .093(argument only if the address-of \(")J
f5_8 sf
.347(&)A
f2_8 sf
.803 .08("\) operator is ever applied to the)J
312 717 :M
.391 .039(parameter; this usage can easily be detected by the compiler.)J
endp
%%Page: 6 6
%%BeginPageSetup
initializepage
(Henry Baker; page: 6 of 10)setjob
%%EndPageSetup
-31 -31 :T
gS 31 31 552 730 rC
72 45 :M
f0_12 sf
.286 .029(ACM Sigplan Notices  )J
f1_12 sf
.095(27)A
f2_12 sf
.435 .044(,3 \(March 1992\),24-34.)J
72 751 :M
-.033(Copyright \251 1988,1990,1991 Nimble Computer Corporation)A
498 751 :M
(6)S
72 78 :M
f2_8 sf
2.448 .245(positional matching for the first several arguments, and has a)J
72 86 :M
1.194 .119(keyword-matching capability, but functions with a large number of)J
72 94 :M
1.481 .148(relatively homogeneous arguments such as "+" are most elegantly)J
72 102 :M
1.274 .127(handled using a )J
f5_8 sf
.539(&REST)A
f2_8 sf
1.17 .117( parameter.  The semantics of the )J
f5_8 sf
.673(&REST)A
72 110 :M
f2_8 sf
.325 .032(parameter are that it is bound to a Lisp list of the arguments remaining)J
72 118 :M
.743 .074(after all required and optional parameters have been bound.  Scheme)J
72 126 :M
.993 .099(does not have keyword arguments, but does allow the equivalent of)J
72 134 :M
1.871 .187(Common Lisp's )J
f5_8 sf
.581(&REST)A
f2_8 sf
1.448 .145( parameter which is denoted by putting a)J
72 142 :M
1.433 .143(symbol in the last "cdr" position of the parameter "list", which is)J
72 150 :M
.297 .03(therefore an )J
f0_8 sf
.09(improper)A
f2_8 sf
.223 .022( list.)J
72 160 :M
.806 .081(Unfortunately, the creation of first-class Lisp lists for handling these)J
72 168 :M
f5_8 sf
.218(&REST)A
f2_8 sf
.464 .046( parameters is quite expensive.  Yet to be safe, a true list must)J
72 176 :M
1.103 .11(be constructed for the )J
f5_8 sf
.466(&REST)A
f2_8 sf
1.31 .131( parameter, since the called function)J
72 184 :M
.782 .078(may do anything with this list it likes, including returning it or side-)J
72 192 :M
.757 .076(effecting it.  For example, Lisp's )J
f5_8 sf
.326(LIST)A
f2_8 sf
.774 .077( function itself has the trivial)J
72 200 :M
.131 .013(definition where it simply returns its )J
f5_8 sf
.053(&REST)A
f2_8 sf
.199 .02( argument:)J
76 214 :M
f5_7 sf
-.155(\(defun list \(&rest args\) args\))A
f2_9 sf
0 -3 rm
-.331(13)A
0 3 rm
72 224 :M
f2_8 sf
2.378 .238(Since there are many reasons for passing variable numbers of)J
72 232 :M
.258 .026(arguments to a function, and only a few of them involve creating a list,)J
72 240 :M
1.347 .135(it is unfortunate that Lisp forces a list allocation for this common)J
72 248 :M
-.061(situation.)A
72 258 :M
4.005 .401(The Lisp Machines derived from the MIT Lisp Machine)J
72 266 :M
.715 .072([Greenblatt74] actually do format their argument lists on the stack to)J
72 274 :M
.181 .018(look like Lisp lists so that they can be passed as )J
f5_8 sf
.09(&REST)A
f2_8 sf
.279 .028( arguments and)J
72 282 :M
.775 .078(traversed using the normal )J
f5_8 sf
.286(CAR)A
f2_8 sf
.371 .037( and )J
f5_8 sf
.286(CDR)A
f2_8 sf
.791 .079( functions.  However, these)J
72 290 :M
.464 .046(argument lists are not first-class Lisp lists, because the lists so created)J
72 298 :M
.466 .047(have the same lifetime as the enclosing stack frame.  Therefore, while)J
72 306 :M
.393 .039(these )J
f5_8 sf
.164(&REST)A
f2_8 sf
.403 .04( arguments can be passed down the stack, they can never)J
72 314 :M
2.501 .25(be stored into the heap, returned past their creation point, or)J
72 322 :M
f5_8 sf
.321(RPLACD)A
f2_8 sf
.793 .079('ed.  However, because they are formatted as lists, they can)J
72 330 :M
1.342 .134(be passed to other functions as lists\321e.g., as the last argument to)J
72 338 :M
f5_8 sf
.877(APPLY)A
f2_8 sf
2.621 .262(\321and thereby avoid a quadratic explosion of copying)J
72 346 :M
.068([Dybvig88].)A
72 356 :M
.297 .03(In our lazy allocation model, however, )J
f0_8 sf
.066(all)A
f2_8 sf
.323 .032( CONS'ing is first performed)J
72 364 :M
.806 .081(on the stack, so there is no additional penalty for CONS'ing )J
f5_8 sf
.43(&REST)A
72 372 :M
f2_8 sf
.61 .061(arguments.  Furthermore, using lazy CONS'ing, )J
f5_8 sf
.2(&REST)A
f2_8 sf
.405 .041( lists are truly)J
72 380 :M
2.504 .25(first-class lists, since they are created using exactly the same)J
72 388 :M
.132 .013(mechanism that is used to create )J
f0_8 sf
.045(any)A
f2_8 sf
.116 .012( Lisp list.)J
72 398 :M
1.8 .18(\(As an aside, we point out that if Lisp argument lists are to be)J
72 406 :M
.49 .049(constructed so that the )J
f5_8 sf
.204(CDR)A
f2_8 sf
.514 .051( pointers always point towards the base of)J
72 414 :M
.882 .088(the stack, and if each argument is to be inserted when its list cell is)J
72 422 :M
.405 .04(allocated, then this virtually requires that arguments to a Lisp function)J
72 430 :M
.599 .06(be evaluated in )J
f0_8 sf
.184(reverse)A
f2_8 sf
.752 .075( order of appearance.\))J
72 442 :M
f1_8 sf
-.039(G.\312\312Tail Recursion)A
72 452 :M
f2_8 sf
.641 .064(Tail recursion is a Lisp optimization that was elevated in the Scheme)J
72 460 :M
.882 .088(dialect into a requirement.  By requiring that a tail-recursive routine)J
72 468 :M
.714 .071(called to a depth of n is allowed to use only O\(1\) amount of )J
f0_8 sf
.287(control)A
72 476 :M
f2_8 sf
1.047 .105(stack, Scheme can simulate iterative control structures in a storage-)J
72 484 :M
2.182 .218(efficient manner without a distinct iteration construct.  Typical)J
72 492 :M
1.325 .132(implementations achieve this by reusing the stack frame on a tail-)J
72 500 :M
1.412 .141(recursive call.  The introduction of lazy allocation requires a new)J
72 508 :M
.573 .057(understanding of the meaning of a "tail recursion optimization", since)J
72 516 :M
.717 .072(any allocation performed during such a loop will increase the size of)J
72 524 :M
1.98 .198(the stack frame which is being reused, potentially allocating an)J
72 532 :M
.888 .089(unbounded amount of stack space.  One interpretation is that such a)J
72 540 :M
.584 .058(program utilizes additional storage during its execution, and therefore)J
72 548 :M
.466 .047(isn't "really" iterative at all.  Another interpretation is that the Scheme)J
72 556 :M
1.575 .157(tail recursion requirement is unreasonable, since a lazy allocation)J
72 564 :M
.424 .042(implementation utilizing arbitrary storage space may be more efficient)J
72 572 :M
.763 .076(\(within its storage limitations\) than a more strict stack frame reusing)J
72 580 :M
2.829 .283(strategy, and the Scheme requirement makes the programmer)J
72 588 :M
1.95 .195("subvert" the compiler in order to achieve his wish.  A default)J
72 596 :M
1.768 .177(interpretation is that a tail recursion "optimization" disables lazy)J
72 604 :M
.323 .032(allocation, and forces allocation directly into the heap.)J
72 616 :M
f1_8 sf
-.038(H.\312\312Scheme Continuations)A
72 626 :M
f2_8 sf
1.287 .129(Scheme is a dialect of Lisp which has a very interesting construct)J
72 634 :M
.755 .076(called a )J
f0_8 sf
.277(continuation)A
f2_8 sf
.961 .096(.  A continuation is a functional argument that)J
72 642 :M
.343 .034(embodies the "rest of the computation".  When a continuation function)J
72 650 :M
1.375 .138(is called with an argument, it does not act like a normal call, but)J
72 658 :M
1.392 .139(instead )J
f0_8 sf
.336(returns)A
f2_8 sf
1.391 .139( from a previous expression evaluation.  Normally,)J
72 666 :M
.889 .089(when a function is called, the arguments are evaluated, an argument)J
72 674 :M
.403 .04(list is constructed, the caller is suspended, and control is transferred to)J
72 682 :M
1.074 .107(the callee.  The callee creates a new frame on top of the stack and)J
72 690 :M
.514 .051(starts execution.  Eventually, the callee )J
f0_8 sf
.136(returns)A
f2_8 sf
.258 .026( with a )J
f0_8 sf
.806 .081(returned value)J
f2_8 sf
(.)S
72 698 :M
1.294 .129(A return is usually implemented by saving the returned value in a)J
-4096 -4095 -1 1 -4094 -4095 1 -4096 -4096 @a
72 703.24 -.24 .24 215.24 703 .24 72 703 @a
72 714 :M
f2_9 sf
.158(13)A
f2_8 sf
0 3 rm
.448 .045(In Scheme, this becomes )J
0 -3 rm
f5_8 sf
0 3 rm
.609 .061(\(define \(list . z\) z\).)J
0 -3 rm
312 78 :M
f2_8 sf
1.324 .132(register, popping the callee's frame from the stack, and continuing)J
312 86 :M
1.913 .191(execution at the point in the caller's code where the callee was)J
312 94 :M
.957 .096(originally called.  During the execution of the callee, the suspended)J
312 102 :M
1.551 .155(caller can be considered a kind of functional argument, which, if)J
312 110 :M
.762 .076(called, would execute the "rest of the computation".  This "function")J
312 118 :M
1.301 .13(even takes an argument\321the value to be returned from the callee.)J
312 126 :M
.713 .071(This "function"'s main fault is that if it is called, it will never return.)J
312 134 :M
1.967 .197(We designate this theoretical "function" the )J
f0_8 sf
.492(continuation)A
f2_8 sf
1.147 .115( of the)J
312 142 :M
.64 .064(suspended caller program.)J
312 152 :M
.357 .036(In a traditional stack implementation, the continuation has more than a)J
312 160 :M
.531 .053(passing resemblance to a functional argument.  It consists of a pair of)J
312 168 :M
.352 .035(values: the point in the program text where execution will resume, and)J
312 176 :M
1.889 .189(an environment\321the current stack\321in which to interpret lexical)J
312 184 :M
1.731 .173(variable occurrences in the program text.  If we could somehow)J
312 192 :M
.892 .089(package this continuation into a "real" functional argument, then we)J
312 200 :M
1.101 .11(could simplify the notion of function calling by always including a)J
312 208 :M
.183 .018(continuation argument, and no longer including the return "PC" and the)J
312 216 :M
.641 .064(return stack-pointer as integral parts of the function calling sequence.)J
312 224 :M
.695 .07(In fact, the "jump to subroutine" operation of most modern computer)J
312 232 :M
.636 .064(architectures can be viewed as an optimization of the sequence "push)J
312 240 :M
.106 .011(continuation argument; jump to the beginning of the called function".)J
312 250 :M
.693 .069(In the most primitive Scheme model, then, there are no )J
f0_8 sf
.199(returns)A
f2_8 sf
.755 .076( from)J
312 258 :M
.435 .043(subroutines, only )J
f0_8 sf
.087(calls)A
f2_8 sf
.379 .038( to continuations.  The basic difference between)J
312 266 :M
.563 .056(a normal function and a continuation is that calling a normal function)J
312 274 :M
.219 .022(will )J
f0_8 sf
.086(push)A
f2_8 sf
.252 .025( onto the stack, while calling a continuation will )J
f0_8 sf
.091(pop)A
f2_8 sf
.238 .024( from the)J
312 282 :M
.113(stack.)A
312 292 :M
2.192 .219(Traditional stack implementations of traditional languages work)J
312 300 :M
1.013 .101(correctly, because under normal conditions all continuations created)J
312 308 :M
5.276 .528(during the execution of a program have strict LIFO)J
312 316 :M
1.525 .153(allocation/deallocation behavior.  In other words, the continuation)J
312 324 :M
.479 .048(\(return point, stack pointer\) does not escape the lifetime of its creator,)J
312 332 :M
1.603 .16(and therefore no dangling references are created.  In the Scheme)J
312 340 :M
1.551 .155(language, however, since a function callee can gain access to his)J
312 348 :M
.355 .036(continuation through a special construct \()J
f5_8 sf
.118(call/cc)A
f2_8 sf
.38 .038(\), this continuation)J
312 356 :M
.772 .077(can escape the lifetime of its creator and become a first-class object.)J
312 364 :M
2.165 .216(\(ANSI-C [ANSI-C88] also defines the operations )J
f5_8 sf
.693(setjmp)A
f2_8 sf
1.505 .151( and)J
312 372 :M
f5_8 sf
.842(longjmp)A
f2_8 sf
2.037 .204(, which allow for the "capture" and application of a)J
312 380 :M
.132 .013(continuation which is )J
f0_8 sf
.033(not)A
f2_8 sf
.159 .016( first-class.\))J
312 390 :M
.8 .08(If a system utilizes lazy allocation, then stack frames will remain on)J
312 398 :M
2.542 .254(the stack, so long as LIFO allocation/deallocation behavior is)J
312 406 :M
.967 .097(observed.  If a continuation attempts to escape its creator's lifetime,)J
312 414 :M
1.078 .108(however, its stack frame will be evicted from the stack, which will)J
312 426 :M
1.294 .129(recursively cause all lower stack frames to also be evicted.)J
f2_9 sf
0 -3 rm
.466(14)A
0 3 rm
f2_8 sf
.62 .062(  An)J
312 434 :M
.264 .026(implementation of a language which must deal with the possibility of a)J
312 442 :M
1.01 .101(stack frame suddenly being moved can be quite inefficient, because)J
312 450 :M
.59 .059(virtually every access to the stack frame must check for the existence)J
312 458 :M
.835 .083(of a forwarding pointer.  )J
f0_8 sf
.277(Functional)A
f2_8 sf
1.155 .115( stack frames\321which may still)J
312 466 :M
1.981 .198(point to assignable local variables\321can relax this restriction by)J
312 478 :M
2.757 .276(allowing copying without forwarding.)J
f2_9 sf
0 -3 rm
.673(15)A
0 3 rm
f2_8 sf
1.312 .131(  We can thus obtain a)J
312 486 :M
2.164 .216(behavior analogous to that of many current implementations of)J
312 494 :M
1.796 .18(Scheme which copy the entire control stack to the heap when a)J
312 502 :M
.547 .055(continuation is captured.  Of course, assignable local variables cannot)J
312 510 :M
1.932 .193(be copied, but must be relocated in order to retain their shared)J
312 518 :M
.051(semantics.)A
312 528 :M
.45 .045(We do not contend that lazy allocation solves all problems in the high)J
312 536 :M
.488 .049(performance implementation of Scheme continuations, and experience)J
312 544 :M
.921 .092(may prove that Scheme continuations are better managed with more)J
312 552 :M
.623 .062(specialized techniques.  Nevertheless, it is interesting that the generic)J
312 560 :M
1.92 .192(lazy allocation model faithfully captures the behavior of several)J
312 568 :M
2.19 .219(existing Scheme implementations, without requiring any special)J
312 576 :M
(handling.)S
312 588 :M
f1_8 sf
-.071(I.\312\312Function Results and the )A
f4_8 sf
-.076(Result Expectation Optimization)A
312 598 :M
f2_8 sf
1.296 .13(As we have pointed out above, lazy allocation is not lazy when it)J
312 606 :M
.587 .059(comes to result values.  This is because results must be returned "up")J
312 614 :M
.218 .022(the stack, usually by assigning them to a temporary value in the caller's)J
312 622 :M
.457 .046(frame.  This is unfortunate, because the efficient handling of results is)J
312 630 :M
1.331 .133(as important as the efficient handling of arguments.  The efficient)J
312 638 :M
.247 .025(allocation of results, however, is a difficult problem.)J
-4096 -4095 -1 1 -4094 -4095 1 -4096 -4096 @a
312 650.24 -.24 .24 455.24 650 .24 312 650 @a
312 661 :M
f2_9 sf
.289(14)A
f2_8 sf
0 3 rm
.771 .077(Lower stacks frames will be evicted only if they have not already)J
0 -3 rm
312 672 :M
.293 .029(been evicted; this solves the multiple stack copy problem mentioned in)J
312 680 :M
.141([Hieb90].)A
312 690 :M
f2_9 sf
.303(15)A
f2_8 sf
0 3 rm
.877 .088(Stack frames in Scheme may have assignable slots even when no)J
0 -3 rm
312 701 :M
1.706 .171(side-effects are performed by the programmer; this behavior is a)J
312 709 :M
1.449 .145(result of the ability of Scheme continuations to be resumed many)J
312 717 :M
.455 .045(different times.)J
endp
%%Page: 7 7
%%BeginPageSetup
initializepage
(Henry Baker; page: 7 of 10)setjob
%%EndPageSetup
-31 -31 :T
gS 31 31 552 730 rC
72 45 :M
f0_12 sf
.286 .029(ACM Sigplan Notices  )J
f1_12 sf
.095(27)A
f2_12 sf
.435 .044(,3 \(March 1992\),24-34.)J
72 751 :M
-.033(Copyright \251 1988,1990,1991 Nimble Computer Corporation)A
498 751 :M
(7)S
72 78 :M
f2_8 sf
1.718 .172(The first optimization for reducing result eviction we call )J
f0_8 sf
.506(result)A
72 86 :M
.145(expectation)A
f2_8 sf
.537 .054(.  Since many functions are called "for side-effects" rather)J
72 94 :M
.625 .063(than "for result value" in expression-oriented languages like Lisp, the)J
72 102 :M
.741 .074(caller should notify the function of this expectation so that unneeded)J
72 114 :M
1.55 .155(function results can be thrown away instead of evicted.)J
f2_9 sf
0 -3 rm
.535(16)A
0 3 rm
f2_8 sf
1.015 .102(  Other)J
72 122 :M
.336 .034(functions are called for their result, but only 1 bit of result information)J
72 130 :M
1.363 .136(is actually used\321whether the result matches a distinguished value)J
72 138 :M
.151<28>A
f5_8 sf
.272(nil)A
f2_8 sf
.447 .045( in the case of Lisp, )J
f5_8 sf
.272(0)A
f2_8 sf
.496 .05( in the case of C\).  In such cases, we need)J
72 146 :M
.886 .089(preserve only the single bit of result information actually needed, to)J
72 154 :M
2.126 .213(avoid the eviction of large structures which are already mostly)J
72 162 :M
.241(garbage.)A
72 172 :M
1.614 .161(Another optimization for avoiding the heap-allocation of function)J
72 180 :M
1.011 .101(results is for the caller to allocate space for the result and pass this)J
72 188 :M
2.118 .212(space by reference; this technique, which we call "caller result)J
72 196 :M
.995 .1(allocation", has been used since at least the early 1960's in Fortran,)J
72 204 :M
.177 .018(Cobol and PL/I compilers.  Eviction upon callee return is avoided since)J
72 212 :M
1.527 .153(the callee no longer performs allocation.  While this technique is)J
72 220 :M
1.284 .128(widely used in programming language implementations, it depends)J
72 228 :M
.347 .035(upon the ability of the caller to guess the correct size of the result, and)J
72 236 :M
.334 .033(it forces the called routine to use side-effects to communicate its result)J
72 244 :M
.957 .096(information.  When the size cannot be guessed\321e.g., in the case of)J
72 252 :M
1.04 .104(some Ada unconstrained array results\321this method fails, and heap-)J
72 260 :M
.934 .093(allocation must be used.  Heap allocation, however, runs the risk of)J
72 268 :M
.691 .069("storage leakage" in non-garbage-collected language implementations)J
72 276 :M
.464 .046(if an error or other non-local transfer of control fails to deallocate this)J
72 284 :M
.433 .043(storage when the stack is contracted.)J
72 294 :M
.494 .049(Another method for avoiding the heap-allocation of function results is)J
72 302 :M
.858 .086(for the result to be allocated in the stack, but to redefine the caller's)J
72 314 :M
1.344 .134(stack frame to include this result before returning to the caller.)J
f2_9 sf
0 -3 rm
1.006(17)A
0 3 rm
72 322 :M
f2_8 sf
.467 .047(This scheme is similar to caller result allocation, except that the caller)J
72 330 :M
2.675 .267(conceptually passes the entire "rest-of-the-stack" as the result)J
72 338 :M
.78 .078(reference, which is then chopped back to its actual size before being)J
72 346 :M
1 .1(returned.  This scheme also works, and has been used in some Ada)J
72 354 :M
.78 .078(compilers [Sherman80], but can waste arbitrary amounts of space on)J
72 362 :M
.503 .05(the stack if the process is iterated.  Consider, for example, a recursive)J
72 370 :M
.604 .06(program which allocates a result at the bottom of the recursion.  This)J
72 378 :M
.901 .09(result, and all the intervening space, will become part of the caller's)J
72 386 :M
.598 .06(stack frame, even though most of this space is no longer used.  Since)J
72 394 :M
.404 .04(one knows the current extent of the stack, one could conceivably copy)J
72 402 :M
.426 .043(the result back to "close up" the space, but if this process is iterated, a)J
72 410 :M
.98 .098(quadratic explosion of copying could result [Dybvig88].  Therefore,)J
72 418 :M
1.053 .105(the non-lazy eviction of a result value to the heap just once can be)J
72 426 :M
.242 .024(more efficient than trying too hard to keep the result on the stack.)J
72 436 :M
.601 .06(Unlike previous schemes for redefining the stack frame [Sherman80],)J
72 444 :M
.641 .064(we suggest that whether the object is relocated to the heap or kept as)J
72 452 :M
.889 .089(part of the caller's stack frame should be the choice of the )J
f0_8 sf
.269(caller)A
f2_8 sf
.623 .062( as)J
72 460 :M
.881 .088(part of his result expectation.  In other words, the result expectation)J
72 468 :M
1.462 .146(code to be included in every function call consists of at least the)J
72 480 :M
.086 .009(following two bits of information:)J
f2_9 sf
0 -3 rm
.052(18)A
0 3 rm
72 490 :M
f2_8 sf
8 f3_1 :p
37.275 :m
-.005(ResultCode)A
<CACACACACA>S
21.771 :m
(Action)S
72 499 :M
1.59 .159(00\312\321\312don't return a result\312\312\(used for non-last position of "progn"\))J
72 507 :M
2.319 .232(01\312\321\312nil/non-nil as result\312\312\312\312\312\(used for boolean position of "if"\))J
72 515 :M
1.892 .189(10\312\321\312evict result if necessary\312\312\(normal lazy allocation operation\))J
72 523 :M
.417 .042(11\312\321\312don't pop frame\312\312\312\312\(redefine caller's frame to include result\))J
72 533 :M
.837 .084(The result expectation code inherited by a function from its caller is)J
72 541 :M
.135 .014(used only when the function attempts to return a result \(in Lisp, when it)J
72 549 :M
.737 .074(executes a function in the "tail-call" position\); the rest of the time, it)J
72 557 :M
.387 .039(computes its own result expectation code \(perhaps dependant upon the)J
72 565 :M
1.324 .132(caller's expectation code\) when calling out to other functions.  By)J
72 573 :M
.777 .078(propagating result expectation codes, the result consumer can inform)J
72 581 :M
.442 .044(the result producer of its wishes regarding the allocation of this result.)J
72 589 :M
.81 .081(A programmer or a compiler can therefore use result expectations to)J
-4096 -4095 -1 1 -4094 -4095 1 -4096 -4096 @a
72 629.24 -.24 .24 215.24 629 .24 72 629 @a
72 640 :M
f2_9 sf
.338(16)A
f2_8 sf
0 3 rm
1.008 .101(Result expectation is the run-time analogue of a classic compiler)J
0 -3 rm
72 651 :M
.199 .02(optimization used in expression-oriented languages like Lisp.)J
72 661 :M
f2_9 sf
.414(17)A
f2_8 sf
0 3 rm
1.231 .123(Although values are preserved on the stack, exited stack frames)J
0 -3 rm
72 672 :M
1.319 .132(are spliced out of the call-chain so that )J
f5_8 sf
.614(unwind-protect)A
f2_8 sf
1.168 .117('s in)J
72 680 :M
.54 .054(exited frames are not inadvertently executed.)J
72 690 :M
f2_9 sf
.513(18)A
f2_8 sf
0 3 rm
1.514 .151(The MIT Lisp Machine function call instruction uses a similar)J
0 -3 rm
72 701 :M
2.849 .285(coding \(without lazy allocation\) for its "destination operand")J
72 709 :M
.392 .039([Greenblatt74]; however, the callee does not utilize this information to)J
72 717 :M
.239 .024(avoid allocating useless results!)J
312 78 :M
.8 .08(avoid evictions when the amount of wasted space is calculated to be)J
312 90 :M
.315 .032(within acceptable limits.)J
f2_9 sf
0 -3 rm
.163(19)A
0 3 rm
312 102 :M
f1_8 sf
-.011(J.\312\312Extending Result Lifetimes and Multiple Return Values)A
312 112 :M
f2_8 sf
1.043 .104(There is another method for allocating function results on the stack)J
312 120 :M
.255 .025(which will not cause immediate eviction.  This method depends upon a)J
312 128 :M
2.42 .242(source-to-source conversion of a program called "continuation-)J
312 136 :M
.659 .066(passing-style conversion" \(CPS conversion\).  In converting to CPS, a)J
312 144 :M
.35 .035(program is turned inside out so that returns and returned values, which)J
312 152 :M
1.136 .114(can be viewed as implicit calls to continuations, are converted into)J
312 160 :M
.871 .087(explicit calls on explicit continuations with the values as arguments.)J
312 168 :M
.609 .061(While the CPS form of a program will execute and produce the same)J
312 176 :M
1.163 .116(answer as the original program, its execution on a traditional stack)J
312 184 :M
.86 .086(implementation will use considerably more stack space.  Since there)J
312 192 :M
1.093 .109(are no longer any returns, neither are there any stack pops, at least)J
312 200 :M
.333 .033(until the very end of the program, and so the amount of stack used can)J
312 208 :M
.098 .01(be substantial.)J
312 218 :M
.545 .054(The conversion to CPS form has certain benefits, however.  Since the)J
312 226 :M
.605 .06(stack is retained until the very end of the program, there is never any)J
312 234 :M
3.049 .305(possibility of dangling references for stack-allocated objects.)J
312 242 :M
.996 .1(Therefore, the CPS form of the program can execute correctly even)J
312 250 :M
.482 .048(when the original form of the program would have failed due to some)J
312 258 :M
.433 .043(stack-allocated object leaving the scope of its creator.  In other words,)J
312 266 :M
.227 .023(CPS style offers a "retention" rather than a "deletion" strategy for stack)J
312 274 :M
.847 .085(frames [Fischer72].)J
312 284 :M
1.649 .165(The "continuation-passing style" of programming thus offers new)J
312 292 :M
1.124 .112(flexibility to the programmer who wishes to utilize stack-allocation)J
312 300 :M
1.781 .178(whenever possible.  If he calls a function with a stack-allocated)J
312 308 :M
1.225 .123(argument which could then become part of that function's returned)J
312 316 :M
.606 .061(value, he is likely to get a dangling reference without lazy allocation,)J
312 324 :M
2.255 .226(or cause the eviction of a large structure with lazy allocation.)J
312 332 :M
1.333 .133(However, he can postpone the eviction for a while by calling that)J
312 340 :M
.389 .039(function with an explicit continuation which will accept the "returned")J
312 348 :M
.295 .029(value and continue executing without popping the stack or causing any)J
312 356 :M
.013(evictions.)A
312 366 :M
.383 .038(The most trivial example of all is the Lisp )J
f5_8 sf
.181(CONS)A
f2_8 sf
.504 .05( function itself which)J
312 374 :M
.307 .031(allocates a list cell.  If implemented as a true Lisp function in a system)J
312 382 :M
.551 .055(using lazy allocation, the list cell would be allocated on the stack and)J
312 390 :M
.799 .08(initialized with its "car" and "cdr" components.  As we have already)J
312 398 :M
1.003 .1(pointed out, however, returning a value typically causes its eviction)J
312 406 :M
.578 .058(\(and the eviction of its components\).  Therefore, although )J
f5_8 sf
.221(CONS)A
f2_8 sf
.484 .048( tries)J
312 414 :M
.457 .046(to be lazy, the effect of returning the newly allocated object causes its)J
312 422 :M
.777 .078(eviction to the heap, so our )J
f5_8 sf
.374(CONS)A
f2_8 sf
.654 .065( isn't lazy after all!  If we call this)J
312 430 :M
f5_8 sf
.176(CONS)A
f2_8 sf
.493 .049( with an explicit continuation, however, within which the newly)J
312 438 :M
.112 .011(allocated list cell is manipulated in a normal fashion, then the cell is not)J
312 446 :M
.353 .035(immediately evicted, and remains lazy.)J
312 460 :M
.189 .019(Below is such an implementation of a lazy )J
f5_8 sf
.08(CONS)A
f2_8 sf
.113 .011( in C.)J
f2_9 sf
0 -3 rm
.15(20)A
0 3 rm
316 469 :M
f5_7 sf
-.208(void lazy_cons\(x,y,cont\))A
316 476 :M
-.205(  int x; list y; void cont\(list\);)A
316 483 :M
-.203(  {struct {int car; list cdr;} z;    /* The cons cell. */)A
316 490 :M
-.203(   z.car=x; z.cdr=y; /* Initialize the lazy cons cell. */)A
316 497 :M
-.203(   cont\(&z\);}          /* Give cont ptr. to cons cell. */)A
312 507 :M
f2_8 sf
.708 .071(The use of continuation-passing-style allows the programmer himself)J
312 515 :M
.663 .066(to choose whether allocation will be lazy or not.  In this way, he can)J
312 523 :M
2.802 .28(use his greater knowledge of the program behavior to avoid)J
312 531 :M
.544 .054(unnecessary evictions, but also avoid the creation of large amounts of)J
312 539 :M
.451 .045(garbage in the stack.)J
312 549 :M
1.338 .134(Continuation-passing style has yet another benefit.  Unlike normal)J
312 557 :M
1.335 .134(nested function-application notation, continuation-passing style can)J
312 565 :M
.425 .043(deal with multiple returned values.  For example, a Euclidean division)J
312 573 :M
.866 .087(algorithm "function" can return both a quotient and a remainder.  In)J
312 581 :M
1.07 .107(such a case, the "continuation" function must utilize more than one)J
312 589 :M
1.044 .104(parameter in order to receive all of the results.  Common Lisp also)J
312 597 :M
.614 .061(provides a number of forms to handle "multiple values", but does not)J
312 605 :M
.75 .075(utilize continuation-passing style for their implementation.  Common)J
312 613 :M
.431 .043(Lisp multiple values are not strictly necessary, as all of the benefits of)J
312 621 :M
1.086 .109(multiple values can be achieved through the composing of multiple)J
312 629 :M
.335 .034(values into a Lisp structure which can then be decomposed by the user)J
312 637 :M
1.434 .143(of the function.  In order to save the time and garbage collection)J
312 645 :M
2.332 .233(required to compose and decompose these structures, however,)J
-4096 -4095 -1 1 -4094 -4095 1 -4096 -4096 @a
312 650.24 -.24 .24 455.24 650 .24 312 650 @a
312 661 :M
f2_9 sf
.716(19)A
f2_8 sf
0 3 rm
2.623 .262(The "continuation-passing style" \(CPS\) of programming, as)J
0 -3 rm
312 672 :M
.332 .033(discussed in the next section, can achieve the same allocation behavior)J
312 680 :M
1.231 .123(as result expectation, but with greater overhead.  Furthermore, one)J
312 688 :M
.326 .033(cannot use CPS on code for which one does not have the source\321e.g.,)J
312 696 :M
.441 .044(library code\321so result expectation is to be preferred.)J
312 706 :M
f2_9 sf
.611(20)A
f2_8 sf
0 3 rm
1.473 .147(Due to the lack of full function closures in C, we would have)J
0 -3 rm
312 717 :M
.162 .016(trouble actually using this )J
f5_8 sf
.062(CONS)A
f2_8 sf
.14 .014( in any serious way.)J
endp
%%Page: 8 8
%%BeginPageSetup
initializepage
(Henry Baker; page: 8 of 10)setjob
%%EndPageSetup
-31 -31 :T
gS 31 31 552 730 rC
72 45 :M
f0_12 sf
.286 .029(ACM Sigplan Notices  )J
f1_12 sf
.095(27)A
f2_12 sf
.435 .044(,3 \(March 1992\),24-34.)J
72 751 :M
-.033(Copyright \251 1988,1990,1991 Nimble Computer Corporation)A
498 751 :M
(8)S
72 78 :M
f2_8 sf
.933 .093(Common Lisp uses a special mechanism to provide multiple values.)J
72 86 :M
1.239 .124(We show that the benefits \(including stack allocation\) of Common)J
72 94 :M
.322 .032(Lisp's multiple-value mechanism can be simulated through a new first-)J
72 106 :M
.293 .029(class "multiple-value" structure type together with lazy allocation.)J
f2_9 sf
0 -3 rm
.172(21)A
0 3 rm
76 115 :M
f5_7 sf
-.207(\(defstruct multiple-value)A
76 122 :M
-.206(  \(values nil :read-only t\)\))A
76 136 :M
-.207(\(defun values \(&rest args\))A
76 143 :M
-.205(  \(make-multiple-value :values args\)\))A
76 152 :M
-.204(\(defun multiple-value-call \(fn &rest args\))A
76 159 :M
-.219(  \(apply fn)A
76 166 :M
-.212(         \(mapcan)A
76 173 :M
-.207(           #'\(lambda \(arg\))A
76 180 :M
-.204(               \(if \(multiple-value-p arg\))A
76 187 :M
-.204(                 \(multiple-value-values arg\))A
76 194 :M
-.206(                 \(list arg\)\)\))A
76 201 :M
-.211(           args\)\)\))A
72 211 :M
f2_8 sf
.376 .038(To provide the programmer with the retention benefits of CPS without)J
72 219 :M
.923 .092(the requirement of turning his source code inside-out, we define the)J
72 227 :M
f5_8 sf
.663(CONTCALL)A
f2_8 sf
1.401 .14( special form.  The semantics of )J
f5_8 sf
.663(CONTCALL)A
f2_8 sf
1.204 .12( can be)J
72 235 :M
.299 .03(defined as follows:)J
76 244 :M
f5_7 sf
-.204(\(defun contcall \(continuation fn &rest args\))A
76 251 :M
-.203(  \(multiple-value-call continuation \(apply fn args\)\)\))A
72 261 :M
f2_8 sf
.343 .034(In other words, )J
f5_8 sf
.149(CONTCALL)A
f2_8 sf
.378 .038( applies the function to the arguments, and)J
72 269 :M
2.975 .298(than applies the "continuation" function to this result.  The)J
72 277 :M
1.84 .184(implementation of )J
f5_8 sf
.551(CONTCALL)A
f2_8 sf
1.344 .134( is special, however.  Whereas the)J
72 285 :M
1.503 .15(stack would normally have been contracted after the execution of)J
72 293 :M
f5_8 sf
.153(\(apply\312fn\312args\))A
f2_8 sf
.318 .032(, it is not, so that the result\(s\) of this application)J
72 301 :M
1.224 .122(is \(are\) left on the stack for the application of )J
f5_8 sf
.601(continuation)A
f2_8 sf
(.)S
72 309 :M
4.174 .417(Using )J
f5_8 sf
1.518(CONTCALL)A
f2_8 sf
3.972 .397(, we can then define Common Lisp's)J
72 317 :M
f5_8 sf
.277(MULTIPLE-VALUE-BIND)A
f2_8 sf
.754 .075( special form, whose purpose appears to)J
72 325 :M
1.543 .154(be the extraction of multiple values from a function call )J
f0_8 sf
.541(without)A
72 333 :M
.186 .019(causing any extraneous heap allocation)J
f2_8 sf
(.)S
76 342 :M
f5_7 sf
-.206(\(defmacro\312multiple-value-bind)A
76 349 :M
-.204(          \(vars\312\(fn\312.\312args\)\312&body\312body\))A
76 356 :M
-.203(  `\(contcall #'\(lambda ,vars ,@body\) ,fn ,@args\)\))A
72 366 :M
f2_8 sf
1.523 .152(Of course, once we have lazy allocation and )J
f5_8 sf
.633(CONTCALL)A
f2_8 sf
1.183 .118(, we no)J
72 374 :M
1.15 .115(longer need to clutter up the Lisp language with "multiple values",)J
72 382 :M
1.632 .163(since the "non-consing" benefits can already be achieved without)J
72 390 :M
1.09 .109(multiple values.  )J
f5_8 sf
.456(CONTCALL)A
f2_8 sf
.878 .088( can also be used for a definition of a)J
72 398 :M
f5_8 sf
.229(LET)A
f2_8 sf
.534 .053( which extends the stack so that the variables are bound to stack-)J
72 406 :M
.556 .056(allocated values.  Such a stack-extending )J
f5_8 sf
.204(LET)A
f2_8 sf
.495 .05( is usually the intention)J
72 414 :M
2.476 .248(of the programmer; this is the motivation for proposals for a)J
72 422 :M
.276(")A
f5_8 sf
.406(dynamic-let)A
f2_8 sf
1.121 .112(" [Queinnec88], but without causing failure if the)J
72 430 :M
.424 .042(values escape the scope of the allocation.)J
76 439 :M
f5_7 sf
-.204(\(defmacro dlet \(\(var \(fn . args\)\) &body body\))A
76 446 :M
-.203(  `\(contcall #'\(lambda \(,var &rest ignore\) ,@body\))A
76 453 :M
-.207(             ,fn ,@args\)\))A
72 463 :M
f2_8 sf
1.039 .104(Below, we show how to program a complex division routine which)J
72 471 :M
.276 .028(allocates all intermediate results on the stack.)J
76 480 :M
f5_7 sf
-.21(\(defun cdiv \(z1 z2\))A
76 487 :M
-.205(  \(dlet \(\(z2bar \(conjugate z2\)\)\))A
76 494 :M
-.205(   \(dlet \(\(z2norm \(ctimes z2 z2bar\)\)\))A
76 501 :M
-.204(    \(dlet \(\(z1z2bar \(ctimes z1 z2bar\)\)\))A
76 508 :M
-.204(     \(dlet \(\(rz2norm \(realpart z2norm\)\)\))A
76 515 :M
-.204(      \(complex \(/ \(realpart z1z2bar\) rz2norm\))A
76 522 :M
-.203(               \(/ \(imagpart z1z2bar\) rz2norm\)\)\)\)\)\)\))A
72 532 :M
f2_8 sf
.841 .084(Using continuation-passing style to extend the life of stack-allocated)J
72 540 :M
.91 .091(objects can be used for more substantial applications.  For example,)J
72 548 :M
1.123 .112(the storage needed for the intermediate results in a chain of matrix)J
72 556 :M
.74 .074(multiplications can be allocated in this fashion, so that only the final)J
72 564 :M
.408 .041(product matrix becomes a first-class heap object.)J
72 576 :M
f1_8 sf
-.013(K.\312\312"Functional" Data Structures)A
72 586 :M
f2_8 sf
1.935 .194(So far, our lazy allocation model has utilized strict "relocation")J
72 594 :M
1.963 .196(semantics in order to preserve the "object identity" of allocated)J
72 602 :M
.83 .083(objects.  In this semantics, there is only one "true" location for each)J
72 610 :M
.565 .056(object, but this location can sometimes change.  For "functional" data)J
72 618 :M
1.503 .15(structures\321data structures which cannot be side-effected\321we can)J
72 626 :M
.451 .045(relax the strict "relocation" semantics and utilize "copying" semantics.)J
72 634 :M
2.49 .249(This is because the behavior of a functional data structure is)J
72 642 :M
.582 .058(determined by the values of its components, and since they cannot be)J
72 650 :M
.304 .03(changed, a copy of the data structure having the same components will)J
72 658 :M
1.908 .191(have the same behavior.  \(A more thorough treatment of object)J
72 666 :M
1.387 .139(identity for functional objects can be found in a companion paper)J
72 674 :M
.191([Baker93].\))A
-4096 -4095 -1 1 -4094 -4095 1 -4096 -4096 @a
72 695.24 -.24 .24 215.24 695 .24 72 695 @a
72 706 :M
f2_9 sf
.429(21)A
f2_8 sf
0 3 rm
1.351 .135(This multiple-value structure should be )J
0 -3 rm
f0_8 sf
0 3 rm
.309(functional)A
0 -3 rm
f2_8 sf
0 3 rm
1.269 .127( [Baker93] to)J
0 -3 rm
72 717 :M
.328 .033(achieve the maximum benefits of lazy allocation.)J
312 78 :M
1.023 .102(Copying semantics for functional objects can have some benefits in)J
312 86 :M
1.002 .1(our lazy allocation model.  When a functional object is copied, one)J
312 94 :M
.756 .076(need not necessarily leave a forwarding address, since the original is)J
312 102 :M
.324 .032(as good as the copy.  Since forwarding addresses must be detected and)J
312 110 :M
.414 .041(followed during execution, the cost of detection and following may be)J
312 118 :M
.377 .038(more than the costs of copying.  At the hardware level, the installation)J
312 126 :M
1.306 .131(of forwarding pointers also causes a cache write-back, which adds)J
312 134 :M
.981 .098(additional load to the memory system.  Thus, for small or unshared)J
312 142 :M
.69 .069(functional objects the cost of copying is less than the cost of storing,)J
312 150 :M
.386 .039(checking and following forwarding pointers.)J
312 160 :M
.696 .07(Copying semantics can be exponentially less efficient than relocation)J
312 168 :M
1.703 .17(semantics if substantial substructure sharing occurs, however.  A)J
312 176 :M
.358 .036(simple linear Lisp list of length )J
f1_8 sf
.146(n)A
f2_8 sf
.305 .031( in which the CAR of each list cell is)J
312 184 :M
1.404 .14(assigned to be the same as its CDR has been called a "blam list")J
312 194 :M
.298 .03([McCarthy65] because it explodes into a structure of 2)J
f1_8 sf
0 -3 rm
.102(n)A
0 3 rm
f2_8 sf
.243 .024( list cells when)J
312 202 :M
.365 .037(it is functionally copied.  The only exponential blowup of this type we)J
312 210 :M
.639 .064(have observed occurs in Macsyma's representation of the determinant)J
312 222 :M
1.166 .117(of an )J
f1_8 sf
.74(n)A
f2_8 sf
.666(x)A
f1_8 sf
.74(n)A
f2_8 sf
1.608 .161( matrix in O\()J
f1_8 sf
.74(n)A
f2_9 sf
0 -3 rm
.749(3)A
0 3 rm
f2_8 sf
1.992 .199(\) cells; this structure expands into an)J
312 230 :M
.745 .074(expression with O\()J
f1_8 sf
.207(n)A
f2_8 sf
.488 .049(!\) terms.  On the other hand, the extended size of)J
312 238 :M
2.903 .29(a functional data structure is constant and can be computed)J
312 246 :M
.604 .06(incrementally as it is constructed.  The information needed to make a)J
312 254 :M
.552 .055(copy/no-copy decision can therefore be gathered cheaply at run-time.)J
312 264 :M
1.657 .166(There are a number of "functional" structures even in imperative)J
312 272 :M
.567 .057(languages.  Argument lists and functional arguments are usually side-)J
312 280 :M
.801 .08(effect free.  In some languages, character strings cannot be modified)J
312 288 :M
1.855 .185(by side-effects.  ANSI C offers the )J
f5_8 sf
.833(const)A
f2_8 sf
2.185 .218( qualifier.  Scheme)J
312 296 :M
.239 .024(continuation structures, being similar to functional arguments, are side-)J
312 304 :M
.437 .044(effect free, although they may have pointers to non-functional objects.)J
312 312 :M
.721 .072(The various kinds of numbers in Common Lisp are functional\321even)J
312 320 :M
.456 .046(large objects like infinite precision integers and structured objects like)J
312 328 :M
1.418 .142(complex floating point numbers.  The "multiple values" structures)J
312 336 :M
.923 .092(returned from Common Lisp function calls are also functional, even)J
312 344 :M
.105 .01(though they are not first-class Common Lisp objects.)J
312 354 :M
.436 .044(The functionality of these objects\321at least their top level structures\321)J
312 362 :M
.996 .1(accounts for many of the other variations on lazy allocation.  Thus,)J
312 370 :M
1.338 .134(while MacLisp used lazy allocation for integers and floating point)J
312 378 :M
.809 .081(numbers [Steele77], it did not have to leave or check for forwarding)J
312 386 :M
.884 .088(addresses because these numeric objects were functional.  Similarly,)J
312 394 :M
3.207 .321(lazy allocation implementations of functional arguments and)J
312 402 :M
.374 .037(continuations do not bother to leave or check for forwarding addresses)J
312 410 :M
.303 .03(because there is very little potential sharing, and evictions happen very)J
312 418 :M
.179 .018(rarely, so copying is not a problem.)J
312 428 :M
.881 .088(Due to Common Lisp's insistence upon the use of true Lisp lists for)J
312 436 :M
f5_8 sf
.942(&REST)A
f2_8 sf
2.78 .278( arguments, however, one cannot legally use copying)J
312 444 :M
1.069 .107(semantics for these objects, because Common Lisp list cells can be)J
312 452 :M
.519 .052(side-effected.  As a result, the lazy allocation of )J
f5_8 sf
.229(&REST)A
f2_8 sf
.635 .063( arguments is)J
312 460 :M
.959 .096(less efficient than if )J
f5_8 sf
.444(&REST)A
f2_8 sf
.963 .096( arguments were based on a )J
f0_8 sf
.333(functional)A
312 468 :M
f2_8 sf
1.792 .179(sequence structure instead of non-functional list cells.  Scheme's)J
312 476 :M
.593 .059(requirement that )J
f5_8 sf
.193(&REST)A
f2_8 sf
.266 .027( lists be )J
f0_8 sf
.149(always)A
f2_8 sf
.427 .043( copied is just as bad, because)J
312 484 :M
.437 .044(the majority of such lists are functional and could otherwise be shared)J
312 492 :M
.835 .083(and thereby avoid a quadratic explosion of copying in deeply nested)J
312 500 :M
.583 .058(recursions [Dybvig87].)J
312 512 :M
f1_8 sf
.196 .02(6.\312\312Future Work \321 An Incremental Model)J
312 521 :M
f2_8 sf
.485 .048(The model as described above is not particularly incremental, because)J
312 529 :M
1.715 .171(a transporter trap in a deeply nested stack frame could cause an)J
312 537 :M
1.341 .134(unbounded number of objects to be copied before returning to the)J
312 545 :M
.687 .069(execution of the program.  One can view the copying effort involved)J
312 553 :M
.264 .026(in eviction as the effort which was )J
f0_8 sf
.085(deferred)A
f2_8 sf
.282 .028( by lazy allocation, and has)J
312 561 :M
1.384 .138(suddenly come due.  While this effort might still be less than the)J
312 569 :M
.781 .078(amount of effort saved by using lazy allocation, it is time that is not)J
312 577 :M
1.318 .132(easily interrupted, and can therefore cause problems in a real-time)J
312 585 :M
-.036(system.)A
312 595 :M
1.069 .107(A more incremental system would evict objects from a stack frame)J
312 603 :M
.588 .059(just before it is popped, and would evict only the "top level" of those)J
312 611 :M
2.865 .287(objects.  Unfortunately, this sort of a system leads to great)J
312 619 :M
.578 .058(complications.  In such a system, a stack frame must now be scanned)J
312 627 :M
1.123 .112(before popping, in order to evict any remaining objects.  However,)J
312 635 :M
.62 .062(unlike the non-incremental scheme where we could inductively prove)J
312 643 :M
.991 .099(that no pointers to the stack frame exist at the time of popping, the)J
312 651 :M
1.142 .114(incremental scheme has no such property.  If there are live objects)J
312 659 :M
1.759 .176(remaining in the stack frame, then )J
f0_8 sf
.501(ipso)A
f2_8 sf
.273 .027( )J
f0_8 sf
.48(facto)A
f2_8 sf
1.53 .153( there must be live)J
312 667 :M
.504 .05(pointers.  Unfortunately, we do not know where those pointers are, so)J
312 675 :M
.85 .085(we cannot update them when the objects are moved out of the stack)J
312 683 :M
.27(frame.)A
312 693 :M
2.141 .214(The only solution is to follow a technique invented by Bishop)J
312 701 :M
.977 .098([Bishop77] and used by Lieberman and Hewitt [Lieberman83].  We)J
312 709 :M
.352 .035(use a separate )J
f0_8 sf
.112(entry)A
f2_8 sf
.391 .039( table to keep track of those pointers which violate)J
312 717 :M
.52 .052(a stack's well-ordering.  This entry table initially starts out empty, but)J
endp
%%Page: 9 9
%%BeginPageSetup
initializepage
(Henry Baker; page: 9 of 10)setjob
%%EndPageSetup
-31 -31 :T
gS 31 31 552 730 rC
72 45 :M
f0_12 sf
.286 .029(ACM Sigplan Notices  )J
f1_12 sf
.095(27)A
f2_12 sf
.435 .044(,3 \(March 1992\),24-34.)J
72 751 :M
-.033(Copyright \251 1988,1990,1991 Nimble Computer Corporation)A
498 751 :M
(9)S
72 78 :M
f2_8 sf
.944 .094(when a stack frame is cleared of live objects, some of these objects)J
72 86 :M
1.274 .127(may continue to point into other stack frames.  These pointers are)J
72 94 :M
.272 .027(routed indirectly through the entry table.  When the next stack frame is)J
72 102 :M
.504 .05(to be cleared, the entry table is searched for objects entering the stack)J
72 110 :M
1.491 .149(frame, and those objects are then relocated.  In this way, we can)J
72 118 :M
.522 .052(incrementalize the eviction process.)J
72 128 :M
2.213 .221(Our incremental scheme is nearly equivalent to Lieberman and)J
72 136 :M
.288 .029(Hewitt's )J
f0_8 sf
.391 .039(generational garbage collection)J
f2_8 sf
.209 .021(, in which the global heap and)J
72 144 :M
1.403 .14(each stack frame are separate generations.  Unlike Lieberman and)J
72 152 :M
1.709 .171(Hewitt, however, who would move a result object through every)J
72 160 :M
.911 .091(intermediate generation, we move such objects directly to the oldest)J
72 168 :M
.68 .068(generation\321the global heap\321in order to avoid a quadratic explosion)J
72 176 :M
.155 .016(in copying effort [Dybvig88].  Our policy is similar to Ungar's )J
f0_8 sf
.052(tenuring)A
72 184 :M
f2_8 sf
.482 .048(policy [Ungar84], which also avoids the copying of long-lived objects)J
72 192 :M
.847 .085(through the intermediate generations.  The address ordering relation,)J
72 200 :M
.687 .069(the relocation process and the manipulation of the entry tables in our)J
72 208 :M
.383 .038(scheme are all identical to that of Lieberman and Hewitt, however.)J
72 220 :M
f1_8 sf
-.062(7.\312\312Conclusions and Previous Work)A
72 229 :M
f2_8 sf
.247 .025(We have shown how a general model called )J
f0_8 sf
.395 .04(lazy allocation)J
f2_8 sf
.257 .026( can simply)J
72 237 :M
2.755 .276(and elegantly explain many traditional programming language)J
72 245 :M
1.027 .103(optimizations aimed at increasing the fraction of storage allocations)J
72 253 :M
.555 .056(that can be performed on a stack.  Lazy allocation requires the ability)J
72 261 :M
.585 .059(to deal with objects which can be suddenly moved, but once this cost)J
72 269 :M
1.235 .124(has been paid, lazy allocation can result in great simplifications in)J
72 277 :M
.202 .02(other parts of a language implementation.  Lazy allocation puts most of)J
72 285 :M
.627 .063(its overhead burden on assignments, which makes it attractive for the)J
72 293 :M
.262 .026("mostly functional" programming styles of modern expression-oriented)J
72 301 :M
.484 .048(languages.  Lazy allocation also has benefits in shared-memory multi-)J
72 309 :M
1.456 .146(processor environments where the potential bottleneck of a global)J
72 317 :M
1.406 .141(allocator is shielded by lazy stack allocation from the bulk of the)J
72 325 :M
.273 .027(allocation load.)J
72 335 :M
1.971 .197(We have also described a new run-time technique called )J
f0_8 sf
.571(result)A
72 343 :M
.517(expectation)A
f2_8 sf
1.931 .193(, which informs called functions of what results are)J
72 351 :M
1.292 .129(expected and where they should be put, so that unexpected results)J
72 359 :M
.708 .071(need not be heap-allocated.  While interesting in its own right, result)J
72 367 :M
1.992 .199(expectation works with lazy allocation to reduce the number of)J
72 375 :M
1.549 .155(evictions of function results from functions called for their effect)J
72 383 :M
.415 .042(rather than for their result.)J
72 393 :M
.832 .083(The concept of lazy allocation is the result of 10 years of pondering)J
72 401 :M
1.584 .158(the possibility of "backing up"\321under certain circumstances\321the)J
72 409 :M
2.776 .278(allocation pointer of the author's real-time garbage collection)J
72 417 :M
.612 .061(algorithm [Baker78a], in order to improve its amortized performance.)J
72 425 :M
1.332 .133(The single-bit reference count [Wise77] for stack-allocated objects)J
72 433 :M
.604 .06(can be subsumed by address ordering, yielding the current concept of)J
72 441 :M
.453 .045(lazy allocation.)J
72 451 :M
.807 .081(Due to the ubiquity of the problem, the literature on stack-allocating)J
72 459 :M
.505 .05(various kinds of objects is so large that we can reference only a small)J
72 467 :M
1.979 .198(fraction.  The stack allocation of variable binding environments)J
72 475 :M
2.61 .261(encompasses the Algol-60 )J
f0_8 sf
.548(display)A
f2_8 sf
2.606 .261( [Randell64], Lisp's binding)J
72 483 :M
f0_8 sf
.039(environments)A
f2_8 sf
.15 .015( [Greenblatt74], Lisp's )J
f0_8 sf
.225 .023(shallow binding)J
f2_8 sf
.177 .018( [Baker78b], Lisp's)J
72 491 :M
f0_8 sf
.887 .089(cactus stacks)J
f2_8 sf
.645 .065( [Bobrow73].  The stack allocation of functional objects)J
72 499 :M
1.091 .109(like numbers is discussed in [Steele77] and [Brooks82].  "Dynamic)J
72 507 :M
1.953 .195(extent objects" [Queinnec88] have been proposed as part of the)J
72 515 :M
.572 .057(Eu_Lisp standard.  Our lazy allocation completely subsumes dynamic)J
72 523 :M
.437 .044(extent objects, and our trapping for the purpose of eviction is no more)J
72 531 :M
.344 .034(expensive than trapping to determine lifetime errors.)J
72 541 :M
2.116 .212(The deletion \(stack-allocation\) versus retention \(heap-allocation\))J
72 549 :M
.574 .057(implementation strategies for Algol-like compiled languages has been)J
72 557 :M
1.022 .102(studied by [Berry71] [Fischer72] [Berry78a] [Berry78b] [Berry78c].)J
72 565 :M
.753 .075([Blair85] describes an )J
f0_8 sf
1.209 .121(optimistic stack-heap)J
f2_8 sf
.82 .082(, which is approximately)J
72 573 :M
.512 .051(our lazy allocation applied to stack frames; unlike our lazy allocation,)J
72 581 :M
.548 .055(however, the optimistic stack-heap is not used for user-allocated data.)J
72 589 :M
.964 .096(In other words, these models do not separate the issues of language)J
72 597 :M
.414 .041(implementation \(frames\) from storage allocation \(stack allocation\).)J
72 607 :M
1.588 .159(The stack allocation of functional arguments has been studied by)J
72 615 :M
.696 .07([Johnston71], [Steele78], [McDermott80] and many others.  Johnston)J
72 623 :M
.143 .014([Johnston71] is said to have used the term )J
f0_8 sf
.233 .023(lazy contour)J
f2_8 sf
.122 .012( which is a close)J
72 631 :M
.343 .034(approximation to our lazily allocated stack frame.)J
72 641 :M
1.791 .179(The stack allocation of continuations has been studied by Steele)J
72 649 :M
2.546 .255([Steele78], Stallman [Stallman80], Bartley [Bartley86], Clinger)J
72 657 :M
.82 .082([Clinger88], Danvy [Danvy87], Deutsch and Schiffman [Deutsch84],)J
72 665 :M
.641 .064(Dybvig [Dybvig87], Kranz [Kranz86] [Kranz88], [Moss87], [Hieb90])J
72 673 :M
1.749 .175(and many others.  The straight-forward application of lazy stack)J
72 681 :M
.748 .075(allocation to Dybvig's heap model [Dybvig87] yields a large fraction)J
72 689 :M
1.75 .175(of the optimizations he performs by hand; the lazy allocation of)J
72 697 :M
1.806 .181(continuations also avoids the multiple stack copies mentioned in)J
72 705 :M
.54 .054([Hieb90].  Deutsch and Schiffman use the term )J
f0_8 sf
.133(volatile)A
f2_8 sf
.455 .046( for lazy stack)J
72 713 :M
.439 .044(frames, and )J
f0_8 sf
.114(stable)A
f2_8 sf
.443 .044( for evicted stack frames.)J
312 78 :M
.562 .056(Dybvig [Dybvig88] is apparently the first to have pointed out in print)J
312 86 :M
.486 .049(that the consistent copying of a large argument to successive levels of)J
312 94 :M
.396 .04(recursion can convert a linear algorithm into a quadratic one.)J
312 104 :M
.407 .041(The concept of lazy allocation was almost discoved by Lieberman and)J
312 112 :M
.587 .059(Hewitt [Lieberman83], since they had all of the necessary machinery.)J
312 120 :M
1.489 .149(However, the additional concept of "genetic order" [Terashima78])J
312 128 :M
2.153 .215(was missing.  McDermott discovered a form of lazy allocation)J
312 136 :M
1.01 .101([McDermott80] for implementing the variable-binding environments)J
312 144 :M
.992 .099(used in a lexically-scoped Lisp interpreter, and he also indicated its)J
312 152 :M
1.356 .136(possible use for managing Scheme continuations.  [Morrison82] is)J
312 160 :M
.271 .027(simply lazy allocation applied to the consing performed in [Baker78b]!)J
312 168 :M
.364 .036([Mellender89] implements Smalltalk with a scheme based on the same)J
312 176 :M
.19 .019(concepts as "lazy allocation", but with substantially greater complexity.)J
312 184 :M
.887 .089(Tucker Taft [Kownacki87] [Taft91] independently developed for the)J
312 192 :M
.878 .088(Ada-9X language the idea of a run-time "scope check", with a user-)J
312 200 :M
2.896 .29(defined copy-to-heap if required; this excellent proposal was)J
312 208 :M
.508 .051(unfortunately later withdrawn.)J
312 218 :M
1.998 .2(Stallman's )J
f0_8 sf
2.476 .248(phantom stacks)J
f2_8 sf
1.71 .171( [Stallman80], which were invented to)J
312 226 :M
1.97 .197(implement Scheme on the MIT Scheme Chip [Steele79], are an)J
312 234 :M
1.172 .117(interesting alternative to solving the same kinds of stack allocation)J
312 242 :M
1.264 .126(problems as lazy allocation.  In phantom stacks, objects are stack-)J
312 250 :M
1.143 .114(allocated in the same manner as in lazy allocation.  The difference)J
312 258 :M
.593 .059(between the two models comes when LIFO order is violated.  In lazy)J
312 266 :M
1.729 .173(allocation, we evict objects from the stack to the heap, while in)J
312 274 :M
.364 .036(phantom stacks, a new stack is initiated, the old stack is abandoned, in)J
312 282 :M
.952 .095(place, where it becomes a passive set of objects in the heap.  Thus,)J
312 290 :M
1.442 .144(lazy allocation and phantom stacks are duals of one another: lazy)J
312 298 :M
.574 .057(allocation moves objects from the stack, while phantom stacks moves)J
312 306 :M
.416 .042(the stack from the objects.  [Hieb90] rediscovered phantom stacks and)J
312 314 :M
1.668 .167(gives an analysis which is more appropriate for the execution of)J
312 322 :M
.273 .027(Scheme on a modern RISC processor.)J
312 332 :M
.668 .067(Both )J
f0_8 sf
.211(Prolog)A
f2_8 sf
.681 .068( [Warren83] and )J
f0_8 sf
.208(Forth)A
f2_8 sf
.882 .088( [Moore80] make more extensive)J
312 340 :M
1.805 .18(use of stacks than do traditional Lisp implementations, and gain)J
312 348 :M
.309 .031(substantially in elegance and speed as a result.)J
312 360 :M
f1_8 sf
.042(8.\312\312Acknowledgements)A
312 369 :M
f2_8 sf
1.057 .106(We wish to thank Dan Friedman, Andre van Meulebrouck, Carolyn)J
312 377 :M
.32 .032(Talcott and the referees for their helpful suggestions and criticisms.)J
312 389 :M
f1_8 sf
.208(9.\312\312References)A
312 397 :M
f2_7 sf
.694 .069(Aho, A.V.  "Nested stack automata".  )J
f0_7 sf
.311(JACM)A
f2_7 sf
.945 .095( 16,3 \(July 1969\),383-406.)J
312 404 :M
2.113 .211(ANSI-C.  )J
f0_7 sf
3.52 .352(Draft Proposed American National Standard Programming)J
318 411 :M
1.175 .117(Language C.)J
f2_7 sf
.678 .068(  ANSI, New York, NY, 1988.)J
312 418 :M
.708 .071(Appel, Andrew W.  "Garbage Collection Can Be Faster Than Stack Allocation".)J
318 425 :M
f0_7 sf
.897 .09(Info. Proc. Let. 25)J
f2_7 sf
1.618 .162( \(1987\),275-279.)J
312 432 :M
1.047 .105(Appel, A.; MacQueen, D.B.  "A Standard ML Compiler".  )J
f0_7 sf
1.443 .144(ACM Conf. Funct.)J
318 439 :M
.971 .097(Prog. & Comp. Arch.)J
f2_7 sf
1.263 .126(, Sept.\3121987.)J
312 446 :M
.85 .085(Appel, Andrew W.; Ellis, John R.; and Li, Kai.  "Real-time concurrent garbage)J
318 453 :M
1.792 .179(collection on stock multiprocessors".  )J
f0_7 sf
1.734 .173(ACM Prog. Lang. Des. and Impl.)J
f2_7 sf
(,)S
318 460 :M
.373(June\3121988,11-20.)A
312 467 :M
2.518 .252(Appel, Andrew W.  "Simple Generational Garbage Collection and Fast)J
318 474 :M
.815 .081(Allocation".  )J
f0_7 sf
.768 .077(SW Prac. & Exper. 19)J
f2_7 sf
1.529 .153(,2 \(Feb.\3121989\),171-183.)J
312 481 :M
.656 .066(Baker, Henry G.  "List Processing in Real Time on a Serial Computer".  )J
f0_7 sf
.441(CACM)A
318 488 :M
.869 .087(21,4 )J
f2_7 sf
1.915 .191(\(April\3121978\), 280-294.)J
312 495 :M
3.504 .35(Baker, Henry G.  "Shallow Binding in Lisp 1.5".  )J
f0_7 sf
6.192 .619(CACM 21)J
f2_7 sf
1.96(,7)A
318 502 :M
.321(\(July\3121978\),565-569.)A
312 509 :M
1.567 .157(Baker, Henry G.  "Unify and Conquer \(Garbage, Updating, Aliasing, ...\) in)J
318 516 :M
1.918 .192(Functional Languages".  )J
f0_7 sf
1.741 .174(Proc. 1990 ACM Conf. on Lisp and Functional)J
318 523 :M
.343(Progr.)A
f2_7 sf
2.263 .226(, June\3121990,218-226.)J
312 530 :M
2.334 .233(Baker, Henry G.  "Equal Rights for Functional Objects".  ACM OOPS)J
318 537 :M
.998 .1(Messenger 4,4 \(Oct.\3121993\), 2-27.)J
312 544 :M
.843 .084(Barth, J.  "Shifting garbage collection overhead to compile time".  )J
f0_7 sf
.39(CACM)A
f2_7 sf
.803 .08( 20,7)J
318 551 :M
.321(\(July\3121977\),513-518.)A
312 558 :M
.708 .071(Bartley, D.H., Jensen, J.C.  "The Implementation of PC Scheme".  )J
f0_7 sf
.815 .082(ACM Lisp &)J
318 565 :M
1.576 .158(Funct. Prog.)J
f2_7 sf
1.401 .14(, Aug.\3121986, 86-93.)J
312 572 :M
.676 .068(Berry, D.M.  "Block Structure: Retention vs. Deletion".  )J
f0_7 sf
.792 .079(Proc. 3rd Sigact Symp.)J
318 579 :M
.935 .094(Th. of Comp.)J
f2_7 sf
.927 .093(, Shaker Hgts., OH, 1971.)J
312 586 :M
1.865 .186(Berry, D.M., )J
f0_7 sf
1.332 .133(et al)J
f2_7 sf
1.941 .194(.  "Time Required for Reference Count Management in)J
318 593 :M
1.423 .142(Retention Block-Structured Languages, Part 1".  )J
f0_7 sf
1.227 .123(Int'l. J. Computer & Info.)J
318 600 :M
.949 .095(Sci. 7)J
f2_7 sf
1.777 .178(,1 \(1978\),11-64.)J
312 607 :M
1.865 .186(Berry, D.M., )J
f0_7 sf
1.332 .133(et al)J
f2_7 sf
1.941 .194(.  "Time Required for Reference Count Management in)J
318 614 :M
1.423 .142(Retention Block-Structured Languages, Part 2".  )J
f0_7 sf
1.227 .123(Int'l. J. Computer & Info.)J
318 621 :M
.973 .097(Sci. 7)J
f2_7 sf
1.886 .189(,2 \(1978\),91-119.)J
312 628 :M
2.104 .21(Berry, D.M., and Sorkin, A.  "Time Required for Garbage Collection in)J
318 635 :M
1.446 .145(Retention Block-Structured Languages".  )J
f0_7 sf
.939 .094(Int'l. J. Computer & Info. Sci. 7)J
f2_7 sf
.517(,4)A
318 642 :M
.322(\(1978\),361-404.)A
312 649 :M
.779 .078(Bishop, P.B.  )J
f0_7 sf
1.064 .106(Computer Systems with a very large address space and garbage)J
318 656 :M
.344(collection)A
f2_7 sf
1.319 .132(.  Ph.D. Thesis, TR-178, MIT Lab. for Comp. Sci., Camb., MA,)J
318 663 :M
.334(May\3121977.)A
312 670 :M
.963 .096(Blair, J.R., Kearns, P., and Soffa, M.L.  "An Optimistic Implementation of the)J
318 677 :M
.858 .086(Stack-Heap".  )J
f0_7 sf
.559 .056(J. Sys. & Soft. 5)J
f2_7 sf
1.353 .135( \(1985\),193-202.)J
312 684 :M
1.852 .185(Bobrow, D.G., and Wegbreit, B.  "A Model and Stack Implementation of)J
318 691 :M
.933 .093(Multiple Environments".  )J
f0_7 sf
1.162 .116(CACM 16)J
f2_7 sf
1.477 .148(,10 \(Oct.\3121973\),591-603.)J
312 698 :M
1.641 .164(Bobrow, et al.  "Common Lisp Object System Specification X3J13", )J
f0_7 sf
1.03(ACM)A
318 705 :M
3.996 .4(SIGPLAN Notices)J
f2_7 sf
2.408 .241(, v.23, Sept. 1988; also X3J13 Document 88-002R,)J
318 712 :M
.408(June\3121988.)A
endp
%%Page: 10 10
%%BeginPageSetup
initializepage
(Henry Baker; page: 10 of 10)setjob
%%EndPageSetup
-31 -31 :T
gS 31 31 552 730 rC
72 45 :M
f0_12 sf
.286 .029(ACM Sigplan Notices  )J
f1_12 sf
.095(27)A
f2_12 sf
.435 .044(,3 \(March 1992\),24-34.)J
72 751 :M
-.033(Copyright \251 1988,1990,1991 Nimble Computer Corporation)A
492 751 :M
(10)S
72 77 :M
f2_7 sf
.65 .065(Boehm, H.-J., Demers, A.  "Implementing Russell".  )J
f0_7 sf
.669 .067(Proc. Sigplan '86 Symp. on)J
78 84 :M
1.369 .137(Compiler Constr., Sigplan Not. 21)J
f2_7 sf
2.139 .214(,7 \(July\3121986\),186-195.)J
72 91 :M
1.436 .144(Brooks, R.A., )J
f0_7 sf
.986 .099(et al)J
f2_7 sf
1.449 .145(.  "An Optimizing Compiler for Lexically Scoped LISP".)J
78 98 :M
f0_7 sf
.917 .092(ACM Lisp & Funct. Prog. 1982)J
f2_7 sf
.27(,261-275.)A
72 105 :M
.764 .076(Brooks, R.A.  "Trading Data Space for Reduced Time and Code Space in Real-)J
78 112 :M
1.178 .118(Time Garbage Collection on Stock Hardware".  )J
f0_7 sf
1.207 .121(ACM Lisp & Funct. Progr.)J
78 119 :M
.443(1984)A
f2_7 sf
.425(,256-262.)A
72 126 :M
1.412 .141(Chase, David.  "Garbage Collection and Other Optimizations".  PhD Thesis,)J
78 133 :M
.9 .09(Rice U. Comp. Sci. Dept., Nov.\3121987.)J
72 140 :M
2.744 .274(Cioni, G., Kreczmar, A.  "Programmed Deallocation without Dangling)J
78 147 :M
.663 .066(Reference".  )J
f0_7 sf
.721 .072(IPL 18)J
f2_7 sf
.983 .098(, 4 \(May\3121984\),179-187.)J
72 154 :M
.755 .075(Clinger, W.D., Hartheimer, A.H., and Ost, E.M.  "Implementation Strategies for)J
78 161 :M
1.276 .128(Continuations".  )J
f0_7 sf
1.103 .11(ACM Conf. on Lisp and Funct. Prog.)J
f2_7 sf
1.985 .198(, July\3121988,124-131.)J
72 168 :M
.627 .063(CLtL:\312\312Steele, Guy L., Jr.  )J
f0_7 sf
.99 .099(Common Lisp: The Language)J
f2_7 sf
.637 .064(.  Digital Press, 1984.)J
72 175 :M
1.078 .108(Danvy, O.  "Memory Allocation and Higher-Order Functions".  )J
f0_7 sf
1.573 .157(Proc. Sigplan)J
78 182 :M
.987 .099('87 Symp. on Interpreters and Interpretive Techniques, ACM Sigplan Notices)J
78 189 :M
.389(22)A
f2_7 sf
2.287 .229(,7 \(July\3121987\),241-252.)J
72 196 :M
.63 .063(Dybvig, R.K.  "Three Implementation Models for Scheme".  Ph.D. Thesis, Univ.)J
78 203 :M
3.089 .309(N. Carolina at Chapel Hill Dept. of Comp. Sci., also TR#87-011,)J
78 210 :M
.332(April\3121987,180p.)A
72 217 :M
2.241 .224(Dybvig, R.K.  "A Variable-Arity Procedural Interface".  )J
f0_7 sf
2.527 .253(ACM Lisp and)J
78 224 :M
1.729 .173(Functional Prog)J
f2_7 sf
1.873 .187(. \(July\3121988\),106-115.)J
72 231 :M
1.438 .144(Fischer, M.J.  "Lambda Calculus Schemata".  )J
f0_7 sf
1.602 .16(Proc. ACM Conf. on Proving)J
78 238 :M
1.199 .12(Asserts. re Progs.)J
f2_7 sf
.267 .027(, )J
f0_7 sf
1.084 .108(Sigplan Not. 7)J
f2_7 sf
1.534 .153(,1 \(Jan.\3121972\).)J
72 245 :M
1.455 .146(Fisher, D.A.  "Bounded Workspace Garbage Collection in an Address-Order)J
78 252 :M
4.898 .49(Preserving List Processing Environment".  )J
f0_7 sf
6.123 .612(Inf.Proc.Lett. 3)J
f2_7 sf
1.954(,1)A
78 259 :M
.3(\(July\3121974\),29-32.)A
72 266 :M
1.109 .111(Friedman, D.P., and Wise, D.S.  "CONS Should not Evaluate its Arguments".)J
78 273 :M
2.684 .268(In S. Michaelson and R. Milner \()J
f0_7 sf
.83(eds)A
f2_7 sf
1.445 .144(.\), )J
f0_7 sf
4.682 .468(Automata, Languages and)J
78 280 :M
.305(Programming)A
f2_7 sf
1.217 .122(, Edinburgh U. Press., Edinburgh, Scotland, 1976,257-284.)J
72 287 :M
.634 .063(Goldberg, B., and Park, Y.G.  "Higher Order Escape Analysis: Optimizing Stack)J
78 294 :M
2.509 .251(Allocation in Functional Program Implementations".  )J
f0_7 sf
3.451 .345(Proc. ESOP'90)J
f2_7 sf
(,)S
78 301 :M
1.057 .106(Springer-Verlag, May\3121990.)J
72 308 :M
.89 .089(Greenblatt, R., )J
f0_7 sf
.609 .061(et al)J
f2_7 sf
.717 .072(.  "The Lisp Machine".  AI WP 79, MIT, Camb., MA, Nov.)J
78 315 :M
2.644 .264(1974, rev. vers. in Winston, P.H., and Brown, R.H., )J
f0_7 sf
.797(eds)A
f2_7 sf
.747 .075(. )J
f0_7 sf
.719(Artificial)A
78 322 :M
.471 .047(Intelligence, an MIT Perspective: Vol. II)J
f2_7 sf
.384 .038(.  MIT Press, Camb., MA, 1979.)J
72 329 :M
2.109 .211(Harbison, S.P., and Steele, G.L., Jr.  )J
f0_7 sf
2.586 .259(C: A Reference Manual, 2nd Ed.)J
78 336 :M
f2_7 sf
.752 .075(Prentice-Hall, Englewood Cliffs, NJ, 1987.)J
72 343 :M
.764 .076(Harrington, Steven J.  "Space efficient copying storage recovery".  )J
f0_7 sf
1.179 .118(Computer J.)J
78 350 :M
.383(24)A
f2_7 sf
2.128 .213(,4 \(1981\),316-319.)J
72 357 :M
1.263 .126(Hederman, Lucy.  "Compile Time Garbage Collection".  MS Thesis, Rice U.)J
78 364 :M
.968 .097(Computer Science Dept., Sept.\3121988.)J
72 371 :M
1.313 .131(Hieb, R., Dybvig, R.K., and Bruggeman, Carl.  "Representing Control in the)J
78 378 :M
1.03 .103(Presence of First-Class Continuations".  )J
f0_7 sf
1.012 .101(ACM Sigplan '90 Conf. Prog. Lang.)J
78 385 :M
1.036 .104(Design & Impl.)J
f2_7 sf
1.562 .156(, June\3121990,66-77.)J
72 392 :M
2.251 .225(IEEE-Scheme.  )J
f0_7 sf
2.451 .245(IEEE Standard for the Scheme Programming Language)J
f2_7 sf
(.)S
78 399 :M
.654 .065(IEEE-1178-1990, IEEE, NY, Dec. 1990.)J
72 406 :M
1.081 .108(Johnston, J.B.  "The Contour Model of Block Structured Processes".  )J
f0_7 sf
.351(Sigplan)A
78 413 :M
.202(Notices)A
f2_7 sf
.761 .076( \(Feb. 1971\).)J
72 420 :M
.745 .075(Jouppi, N.P.  "Improving Direct-Mapped Cache Performance by the Addition of)J
78 427 :M
.494 .049(a Small Fully-Associative Cache and Prefetch Buffers".  )J
f0_7 sf
.509 .051(Proc. 17th Int'l. Symp.)J
78 434 :M
.968 .097(on Computer Arch., ACM Computer Arch. News 18)J
f2_7 sf
1.347 .135(,2 \(June\3121990\).)J
72 441 :M
2.311 .231(Kownacki, R., and Taft, S.T.  "Portable and Efficient Dynamic Storage)J
78 448 :M
2.361 .236(Management in Ada".  )J
f0_7 sf
2.689 .269(Proc. ACM SigAda Int'l. Conf. "Using Ada")J
f2_7 sf
(,)S
78 455 :M
.318(Dec.\3121987,190-198.)A
72 462 :M
.526 .053(Kranz, D., et al.  "ORBIT: An Optimizing Compiler for Scheme".  )J
f0_7 sf
.901 .09(Proc. Sigplan)J
78 469 :M
1.154 .115('86 Symp. on Compiler Constr., Sigplan Notices 21)J
f2_7 sf
1.977 .198(,7 \(July\3121986\),219-233.)J
72 476 :M
.701 .07(Kranz, David A.  ORBIT: An Optimizing Compiler for Scheme".  Ph.D. Thesis,)J
78 483 :M
1.167 .117(Yale Univ., also YALEU/DCS/RR-632, Feb.\3121988,138p.)J
72 490 :M
1.713 .171(Lieberman, H., Hewitt, C.  "A Real-Time Garbage Collector Based on the)J
78 497 :M
.653 .065(Lifetimes of Objects".  )J
f0_7 sf
1.056 .106(CACM 26)J
f2_7 sf
1.019 .102(, 6 \(June\3121983\),419-429.)J
72 504 :M
.925 .092(McCarthy, J., )J
f0_7 sf
.644 .064(et al)J
f2_7 sf
.18 .018(.  )J
f0_7 sf
1.227 .123(LISP 1.5 Programmer's Manual)J
f2_7 sf
.79 .079(.  MIT Press, Camb., MA,)J
78 511 :M
.562(1965.)A
72 518 :M
.775 .078(McDermott, D.  "An Efficient Environment Allocation Scheme in an Interpreter)J
78 525 :M
3.531 .353(for a Lexically-scoped LISP".  )J
f0_7 sf
4.209 .421(1980 Lisp Conf.)J
f2_7 sf
4.107 .411(, Stanford, CA,)J
78 532 :M
.389(Aug.\3121980,154-162.)A
72 539 :M
.622 .062(Mellender, F, )J
f0_7 sf
.436 .044(et al)J
f2_7 sf
.627 .063(.  "Optimizing Smalltalk Message Performance".  In Kim, W.,)J
78 546 :M
2.251 .225(and Lochovsky, F.H., )J
f0_7 sf
.51(eds.)A
f2_7 sf
.536 .054(, )J
f0_7 sf
3.218 .322(Object-Oriented Concepts, Databases and)J
78 553 :M
.246(Applications)A
f2_7 sf
1.23 .123(.  Addison-Wesley, Reading, MA, 1989,423-450..)J
72 560 :M
.522 .052(Moon, D.  "Garbage Collection in a Large Lisp System".  )J
f0_7 sf
.58 .058(ACM Symp. on Lisp &)J
78 567 :M
1.652 .165(Funct. Prog.)J
f2_7 sf
1.345 .135(, 1984, 235-246.)J
72 574 :M
1.107 .111(Moore, Charles H.  "The Evolution of FORTH, an Unusual Language".  )J
f0_7 sf
.421(Byte)A
78 581 :M
4.146 .415(Magazine 5)J
f2_7 sf
3.179 .318(,8 \(special issue on the Forth Programming Language\))J
78 588 :M
.292(\(Aug.\3121980\),76-92.)A
72 595 :M
1.299 .13(Morrison, Donald F, and Griss, Martin, L.  "An Efficient A-list-like Binding)J
78 602 :M
1.078 .108(Scheme".  Unpublished manuscript, Dept. of Computer Science, U. of Utah,)J
78 609 :M
.398(Jan.\3121982,12p.)A
72 616 :M
1.106 .111(Moses, J.  "The function of FUNCTION in Lisp".  Memo 199, MIT AI Lab.,)J
78 623 :M
1.231 .123(Camb., MA, June\3121970.)J
72 630 :M
.907 .091(Moss, J.E.B.  "Managing Stack Frames in Smalltalk".  )J
f0_7 sf
1.129 .113(SIGPLAN '87 Symp. on)J
78 637 :M
4.373 .437(Interpreters and Interpretive Techniques)J
f2_7 sf
1.148 .115(, in )J
f0_7 sf
3.734 .373(Sigplan Notices 22)J
f2_7 sf
1.408(,7)A
78 644 :M
2.115 .211(\(July\3121987\), 229-240.)J
72 651 :M
3.07 .307(Queinnec, Christian.  "Dynamic Extent Objects".  )J
f0_7 sf
3.166 .317(Lisp Pointers 2)J
f2_7 sf
1.36(,1)A
78 658 :M
.242(\(July-Sept.\3121988\),11-21.)A
72 665 :M
1.661 .166(Randell, B., and Russell, L.J.  )J
f0_7 sf
3.196 .32(ALGOL 60 Implementation)J
f2_7 sf
1.633 .163(.  Acad. Press,)J
78 672 :M
1.277 .128(London and NY, 1964.)J
72 679 :M
.789 .079(Rees, J. and Clinger, W., )J
f0_7 sf
.684 .068(et al)J
f2_7 sf
.99 .099(.  "Revised Report on the Algorithmic Language)J
78 686 :M
.822 .082(Scheme".  )J
f0_7 sf
1.019 .102(Sigplan Not. 21)J
f2_7 sf
1.676 .168(,12 \(Dec.\3121986\),37-79.)J
72 693 :M
.457 .046(Richards, M., Evans, A., and Mabee, R.R.  "The BCPL Reference Manual".  MIT)J
78 700 :M
1.79 .179(MAC\312TR-141, Dec.\3121974,53p.)J
72 707 :M
2.169 .217(Ruggieri, C.; Murtagh, T.P.  "Lifetime analysis of dynamically allocated)J
78 714 :M
.543 .054(objects".  )J
f0_7 sf
.834 .083(ACM POPL '88)J
f2_7 sf
.202(,285-293.)A
312 77 :M
2.323 .232(Samples, A.D., Ungar, D, and Hilfinger, P.  "SOAR: Smalltalk without)J
318 84 :M
.951 .095(Bytecodes".  )J
f0_7 sf
1.021 .102(OOPSLA '86 Proc., Sigplan Not. 21)J
f2_7 sf
1.403 .14(, 11 \(Nov.\3121986\),107-118.)J
312 91 :M
1.067 .107(Sandewall, E.  "A Proposed Solution to the FUNARG Problem".  6.894 Class)J
318 98 :M
.76 .076(Notes, MIT AI Lab., Sept. 1974,42p.)J
312 105 :M
2.288 .229(Shaw, Robert A.  "Improving Garbage Collector Performance in Virtual)J
318 112 :M
.762 .076(Memory".  Stanford CSL-TR-87-323, March\3121987.)J
312 119 :M
.766 .077(Sherman, Mark, )J
f0_7 sf
.466 .047(et al)J
f2_7 sf
.626 .063(.  "An ADA Code Generator for VAX 11/780 with UNIX".)J
318 126 :M
f0_7 sf
.866 .087(ACM SIGPLAN ADA Conf)J
f2_7 sf
.233 .023(., )J
f0_7 sf
.901 .09(SIGPLAN Notices 15)J
f2_7 sf
1.224 .122(,11 \(Nov.\3121980\),91-100.)J
312 133 :M
.665 .066(Stallman, Richard M.  "Phantom Stacks: If you look too hard, they aren't there".)J
318 140 :M
.472 .047(AI Memo 556, MIT AI Lab., 1980.)J
312 147 :M
1.622 .162(Stanley, T.J., and Wedig, R.G.  "A Performance Analysis of Automatically)J
318 154 :M
.811 .081(Managed Top of Stack Buffers".  )J
f0_7 sf
.937 .094(Proc. 14th Int'l. Symp. on Computer Arch.,)J
318 161 :M
1.083 .108(ACM Computer Arch. News 15)J
f2_7 sf
1.716 .172(,2 \(June\3121987\),272-281.)J
312 168 :M
.771 .077(Steele, Guy L., Jr.  "Fast Arithmetic in Maclisp".  )J
f0_7 sf
1.224 .122(Proc. 1977 Macsyma User's)J
318 175 :M
1.402(Conference)A
f2_7 sf
4.574 .457(, NASA Sci. and Tech. Info. Off. \(Wash., DC,)J
318 182 :M
.692 .069(July\3121977\),215-224.  Also AI Memo 421, MIT AI Lab., Camb. Mass.)J
312 189 :M
1.028 .103(Steele, Guy L., Jr.  )J
f0_7 sf
1.623 .162(Rabbit: A Compiler for SCHEME \(A Study in Compiler)J
318 196 :M
.113(Optimization\))A
f2_7 sf
.524 .052(.  AI-TR-474, Artificial Intelligence Laboratory, MIT, May\3121978.)J
312 203 :M
.88 .088(Steele, Guy L., Jr., and Sussman, Gerald J.  "Design of LISP-Based Processors)J
318 210 :M
.932 .093(or SCHEME: A Dielectric LISP or, Finite Memories Considered Harmful or,)J
318 217 :M
.387 .039(LAMBDA: The Ultimate Opcode".  MIT AI Memo 514, March\3121979.)J
312 224 :M
2.204 .22(STEELMAN.  Dept. of Defense Requirements for High Order Computer)J
318 231 :M
1.089 .109(Programming Languages.  June\3121978.)J
312 238 :M
.731 .073(Taft, S. Tucker, )J
f0_7 sf
.655 .066(et al.)J
f2_7 sf
.119 .012(  )J
f0_7 sf
1.217 .122(Ada-9X Draft Mapping Document)J
f2_7 sf
.777 .078(.  Wright Lab., AFSC,)J
318 245 :M
1.029 .103(Eglin AFB, FL, Feb.\3121991.)J
312 252 :M
1.837 .184(Terashima, M., and Goto, E.  "Genetic Order and Compactifying Garbage)J
318 259 :M
.788 .079(Collectors".  )J
f0_7 sf
.763 .076(IPL 7)J
f2_7 sf
1.412 .141(,1 \(Jan.\3121978\),27-32.)J
312 266 :M
.724 .072(Unger, D.  "Generation Scavenging: A non-disruptive, high performance storage)J
318 273 :M
.767 .077(reclamation algorithm".  )J
f0_7 sf
.694 .069(ACM Soft. Eng. Symp. on Prac. Software Dev. Envs.,)J
318 280 :M
1.398 .14(Sigplan Notices 19)J
f2_7 sf
2.105 .211(,6 \(June\3121984\),157-167.)J
312 287 :M
2.102 .21(Warren, David H.D.  )J
f0_7 sf
2.738 .274(Applied Logic\321Its Use and Implementation as a)J
318 294 :M
2.238 .224(Programming Tool)J
f2_7 sf
1.091 .109(.  Ph.D. Thesis, U. of Edinburgh, 1977, also Tech. Note)J
318 301 :M
.986 .099(290, SRI Int'l., Menlo Park, CA, 1983,230p.)J
312 308 :M
1.651 .165(Wise, D.S., and Friedman, D.P.  "The One-Bit Reference Count".  )J
f0_7 sf
1.97 .197(BIT 17)J
318 315 :M
f2_7 sf
.322(\(1977\),351-359.)A
endp
%%Trailer
end
%%EOF
