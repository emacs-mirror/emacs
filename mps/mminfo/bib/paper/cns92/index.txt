                IMPROVING THE PERFORMANCE OF SML GARBAGE
    COLLECTION USING APPLICATION-SPECIFIC VIRTUAL MEMORY MANAGEMENT
              Eric Cooper;Scott Nettles;Indira Subramanian
                           ACM L&FP, 01/06/92

                              paper.cns92
                                 draft
                             dsm 1995-07-28


ABSTRACT:

We improved the performance of garbage collection in the Standard ML of
New Jersey system by using the virtual memory facilities provided by
the Mach kernel.  We took advantage of Mach's support for large sparse
address spaces and user-defined paging servers.  We decreased the
elapsed time for realistic applications by as much as a factor of 4.

REVIEWS:

[See also paper.subramanian91]

dsm: The NJ collector defines old objects which have survived at least one
collection and new objects which haven't.  When new space is full a
minor collection happens which collects new objects into old space.
When old space reaches half the heap size then a major collection
happens which collects everything.

There is a crude algorithm to determine the new free and heap sizes.
One improvement made was on a simple change to this size picking
algorithm.  This in itself sometimes gave a speed improvement by a
factor of over 2.5.

A significant gain was also made by using mapping to "allow the old
heap to drift through memory".  In the original scheme the old heap was
copied back to the beginning of the allocation area.

The Mach kernel allows memory to be managed by an `external pager'.
This was used by SML/NJ to inform the system that certain pages were
discardable, i.e. do not contain wanted info.  This allows the system
to throw away old pages, instead of swapping them out.  When pages are
made non-discardable again before use, they do not need to be paged in
but Mach does zero them.

Unfortunately, Mach will sometimes chuck out a non-discardable page
when there are discardable pages available.  It was therefore an
enhancement to explicitly flush discardable pages, either on a pageout
request or after a major collection.

The results were taken on a tiny 24Mb machine where inevitably there
was a disk I/O bottleneck due to paging.  The most alarming thing about
the results was that time decrease (up to 4 times) is of total
execution time and not just time spent in the collector.

---

From: Nick Barnes <nickb>
Date: Fri, 28 Jul 95 15:04:44 BST
To: David Moore <dsm>
Cc: mm
Subject: Application-Specific Virtual Memory Management

I did some work on this with Scott.

   A significant gain was also made by using mapping to "allow the old
   heap to drift through memory".  In the original scheme the old heap was
   copied back to the beginning of the allocation area.

The gain due to this point was, as I recall, very dependent on things
like real memory size, cache size etc. The copy-back step was
originally put in the GC by Appel in order to improve locality.

   The results were taken on a tiny 24Mb machine where inevitably there

I think calling a 24Mb machine 'tiny' is a little unfair. It was a
fair amount for a workstation in its day and that number is typical
even today (I think Sun ships its basic workstations with 16-32 megs
currently). Even with the Mach overhead that machine was perfectly
adequate for all sorts of work until one tried to run SML/NJ on
it. People still think of SML as a language requiring a lot of real
memory, because of the ruinous way in which SML/NJ used VM.

(MLWorks does better, though not as well as it could).

   was a disk I/O bottleneck due to paging.  The most alarming thing about
   the results was that time decrease (up to 4 times) is of total
   execution time and not just time spent in the collector.

Oh yes. SML/NJ is like that. Mutator execution time dropped
dramatically.

Nick

---

Date: Fri, 28 Jul 1995 08:57:56 -0400
To: David Moore <dsm>
From: ptw (P. Tucker Withington)
Subject: Re: Application-Specific Virtual Memory Management
Cc: mm

I think MM have a real opportunity if we can work with an interface such as
this.  The implication is that Copland will have such and interface.  Win95
have this ability (primitively) through the VDX interface.  It might be
worth looking at OS/2 to see what it has.

There is a lot you can do by having the GC cooperate with paging that will
get around many of the ill-effects of GC in a VM system.  (Two typical
effects are: scanning wants to page through all of memory and since the VM
can't distinguish scan from the mutator it mistakenly adjusts the working
set, leaving the mutator high and dry; secondly, GC typically has a sparse
image, whereas most VM page tables, being multi-level, are designed for
contiguous images -- often the VM page table structures themselves grow
large enough that they have to be paged, which is a dead lose.)

Some of the things that were done in Genera include: the scanner visited
resident pages first, then limited the amount of physical memory devoted to
paging in/out non-resident pages that were scanned; it was careful to only
page out scanned pages that the scanner itself had to bring in, thus
minimizing disruption of the mutator's working set.  When the VM needed to
page out a page, the GC was given the opportunity to update the RefSig for
the page (essentially putting a write barrier between physical and backing
store), thus page-in of non-resident pages for scanning was minimized.  The
Genera VM hardware used a flat hash-table to cache page-table entries for
physical memory, rather than a multi-level table structure -- the flat
table is unaffected by the sparseness of the VM image; faults were handled
in software using a B*-tree, which automatically adjusts it's depth as
necessary.

Some things are not as obvious as you might think.  The issue covered in
this paper, not paging-out collected pages, seems like a good policy.
Genera did this by freeing the page in swap space and marking the physical
page as unused (I infer this is what your paper means by "flush", although
I can't be sure).  For the nursury generation, though, this turned out to
actually be a bottleneck!  If you think about it, you realize that in the
nursury generation, you have two sections of VM that constantly swap roles
and are almost never paged out; the overhead of releasing and re-acquiring
the backing store for the unlikely event of page-out dominated the VM cost
for these pages.  There was a prototyped design for a separate VM policy
for nursury space that never reached production but showed significant
improvments on benchmarks from several customers whose programs had lots of
very short-term consing (the prototype simply reserved backing store, but
delayed assigning it until a page-out was actually required; the VM LIFO
scan was weighted to pick pages without backing store last (after unused,
unmodified, modified).

It's amazing what you can do when you control the hardware and the
operating system!


ATTACHMENT
   "ATTF7XC1"

