                   MOSTLY PARALLEL GARBAGE COLLECTION
               Hans-J. Boehm;Alan J. Demers;Scott Shenker
                          Xerox PARC, 01/06/91
      ACM PLDI 91, SIGPLAN Notices 26, 6 (June 1991), pp. 157-164
           ftp://parcftp.xerox.com/pub/gc/papers/pldi91.ps.Z

                              paper.bds91
                                 draft
                             dsm 1995-08-25


ABSTRACT:

We present a method for adapting garbage collectors designed to run 
sequentially with the client, so that they may run concurrently with it.  We 
rely on virtual memory hardware to provide information about pages that have 
been updated or "dirtied" during a given period of time.  This method has been 
used to construct a mostly parallel trace-and-sweep collector that exhibits 
very short pause times.  Performance measurements are given.

REVIEWS:

dsm: I believe this paper describes the basis of the incremental algorithm used 
in the Xerox PCR (rival.boehm).

The claimed very short pause times are order of 100ms on a SPARCStation 2.

These short pause times are achieved in a very simple way.  When a collection 
starts scanning is run in parallel with the mutator.  User implemented dirty 
bits are used to mark areas of memory that the mutator has written to during 
the scan.  Consistency can be achieved by, for example, stopping the collector 
and rescanning dirty pages.

The authors also describe a way of adapting this algorithm to a copying 
collector, but in a not very satisfactory way which involves extra space to 
store forwarding pointers.

This very simple algorithm could be really useful to us.  At the moment, the 
conservative part of our memory manager -- the ambiguous
root scan (in practice the stack), is intended to be atomic.  This may be fast 
enough, but if it is not, we could use their algorithm to reduce pause times.  
We use their trick to scan the ambiguous roots incrementally, and then use the 
approach described in paper.ael88 to finish off.



