      CACHE PERFORMANCE OF GARBAGE COLLECTED PROGRAMMING LANGUAGES
                            Mark B. Reinhold
             MIT Laboratory for Computer Science, 01/09/93
                             MIT/LCS/TR-581

                            paper.reinhold93
                                 draft
                             drj 1995-11-08


ABSTRACT:

As processor speeds continue to improve relative to main-memory access times, 
cache performance is becoming an increasingly important component of program 
performance.  Prior work on the cache performance of garbage-collected 
programming languages has either assumed or argued that conventional 
garbage-collection methods will yield poor performance, and has therefore 
concentrated on new collection algorithms designed specifically to improve 
cache-level reference locality.  This dissertation argues to the contrary:  
Many programs written in garbage-collected languages are naturally well-suited 
to the direct-mapped caches typically found in modern computer systems.

Using a trace-driven cache simulator and other analysis tools, five nontrivial, 
long-running Scheme programs are studied.  A control experiment shows that the 
programs have excellent cache performance without any garbage collection at 
all.  A second experiment indicates that the programs will perform well with a 
simple and infrequently-run generational compacting collector.

An analysis of the test programs' memory usage patterns reveals that the 
mostly-functional programming style typically used in Scheme programs, in 
combination with simple linear storage allocation, causes most data objects to 
be dispersed in time and space so that references to them cause little cache 
interference.  From this it follows that other Scheme programs, and programs 
written in similar styles in different languages, should perform well with a 
simple generational compacting collector; sophisticated collectors intended to 
improve cache performance are unlikely to be effective.  The analysis also 
suggests that, as locality becomes ever more important to program performance, 
programs written in garbage-collected languages may turn out to have 
significant performance advantage over programs written in more conventional 
languages.

REVIEWS:

Reinhold examines the cache behaviour of various Scheme programs compiled using 
Yale's T system (the ORBIT compiler).  He makes no attempt to examine anything 
other than he first cache level; other effects of the memory hierarchy are 
neglected.  His thesis is that the programs exhibit good low cache overheads 
without GC (none of the test programs allocate more than 128Mb, so he never 
runs out of VM).  He gives an interesting discussion of the typical behaviour 
of cache blocks and has some reasonably hand waving arguments to back up his 
thesis (the basic idea being that a linear allocator will spread objects out 
through the cache, and because most objects die before the allocation pointer 
sweeps through the cache again, you are unlikely to get thrashing in the cache 
due to two long-lived and frequently accessed objects mapping to the same cache 
block).  His results seem to indicate that in order to keep memory stall 
overhead at the same percentage you need a primary cache whose size varies in 
proportion to the CPU speed for the same speed memory, however he either 
doesn't notice this or neglects to mention it (possibly he wasn't interested).  
On the whole I don't think the paper is that useful, as it doesn't address the 
broader questions.  A GC has to be designed bearing in mind the impact it will 
have on all levels of the memory hierarchy, not just the L1 cache.



