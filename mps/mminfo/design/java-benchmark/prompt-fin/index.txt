            THE DESIGN OF THE PROMPTFINALIZE JAVA BENCHMARK
                    design.java-benchmark.prompt-fin
                           incomplete design
                             lth 1998-09-15


INTRODUCTION:

This is the design for the PromptFinalize Java benchmark.

.readership: MM group members.

.source: analysis.java-benchmark(1), design.java-benchmark.arch(3), 
design.java-benchmark.framework(0).


OVERVIEW:

The PromptFinalize benchmark is a synthetic benchmark that measures the time 
from object death to object finalization for a range of object ages.


REQUIREMENTS:

Critical requirements

.req.finalizers: The benchmark must test the reliability and timeliness of 
Java's finalization feature.

.req.age-distribution: The benchmark must test the finalization feature on a 
variety of object ages.

.req.output: For each object age, the benchmark must print the number of 
objects finalized, the minimal, average, and maximal delay between object death 
and finalization, and the number of dead but not finalized objects at program's 
end.

Optional requirements

.req.predictive: The benchmark should predict the behavior of finalization in 
real programs on the Java system being tested.  [This requirement is Optional 
because it is not clear that it can be met without using real programs, and 
it's not clear that real programs can be used.]


ARCHITECTURE:

.arch.lifetime: The benchmark uses the priority-based lifetime scheme 
(.sol.lifetime.priority) because it has a pleasing object death-time  
distribution.

.arch.benchmark: The class PromptFinalizeBenchmark subclasses JavaBenchmark and 
is the benchmark core class.

.arch.data: The class Tree is a binary-tree node and is used for the data 
structure.  
.arch.data.birth: A tree of parameter-dependent height is allocated at every 
time increment; the trees are annotated with their birth time and stored in the 
priority queue.  
.arch.data.death: When a tree dies, each node is annotated with the current 
timestamp (the death time).  
.arch.data.finalization: Each tree node has a finalize() method that calls the 
benchmark core object with the node's birth time and
death time when the node is finalized.  
.arch.unit-of-finalization: Each tree node will be given a finalizer.

.arch.recording: The class AgeRecord maintains a mapping from object age at 
death to a record that maintains statistics about finalization for objects of 
that age.

.arch.priority-queue: The framework class Heap implements a heap data structure 
with a configurable comparator.  PromptFinalizeBenchmark implements the 
framework Comparator interface and contains a compare method that performs a 
biased comparison of two trees.  The heap is used as a priority queue.


ANALYSIS:

.anal.time: Time is most naturally measured in object cluster allocations, 
since this measure is independent of other system activity. Observe that if 
time is measured in the number of object clusters allocated, then there is 
never more than one object cluster of any particular age alive.

.anal.death: There seems to be no good reason for choosing the lifetime of an 
object when the object is born; rather, at each step an object should be 
selected for death.

.anal.lifetime: All proposed lifetime schemes except .sol.lifetime.real have a 
problem in that the lifetime distributions are artificial; a garbage collector 
whose finalization handling is tuned for "real" programs may not do well with 
the artificial lifetimes but may still do well on real programs.

.anal.lifetime.real: Instrumenting real programs with finalization code is 
probably not much more realistic than writing synthetic programs in the first 
place, because the instrumented real programs will be using finalizers in 
artificial ways.  The one advantage of this strategy is that real programs at 
least have real object lifetime distributions.

.anal.lifetime.synthetic: Of the artificial lifetime schemes, the "priority" 
and "exact" lifetime schemes seem like better solutions because they do not 
skew the distribution toward young objects in the way that random and closest 
do.  

.anal.lifetime.priority: The "priority" scheme (.sol.lifetime.priority) is good 
in the sense that objects die at various ages, and objects of the same age die 
at different times.  This type of distribution seems somewhat realistic.

.anal.lifetime.exact: The "exact" scheme (.sol.lifetime.exact) is good in the 
sense that any desired number of objects can be allocated for each death age, 
but has a problem in that when objects for age m are tested, residue from age 
m-1 may disturb the results.

.anal.unit-of-finalization: If every node in an object cluster has a finalizer, 
then finalization for objects allocated at the same time may stretch out over 
multiple ticks of the logical clock.  Also, by letting every node have a 
finalizer, there will be more work for the finalization system.  On the other 
hand, letting every node have a finalizer may be to give the finalization 
system an unrealistic amount of work; this seems to be the biggest drawback 
with that solution, but since we're testing the finalization system I'm not 
sure this is a real problem.


IDEAS:

.sol.time: Time is used to measure both object age and the timeliness of 
finalization.  
.sol.time.physical: If the program is not interactive and subject to other 
delays, time can be measured in real time.
.sol.time.logical: Time can also be measured in the number of objects or groups 
of objects allocated.  
.sol.time.increment: If time is advanced after a group of objects has been 
allocated, then controlling the size of the group controls the advancement of 
time.  Allocating a large linked structure per clock tick results in 
coarse-grained measurements; conversely, allocating small structures result in 
fine-grained measurements.

.sol.population.stable: A stable object population makes it easier to see 
effects from the gc/finalization strategy; a growing population would make it 
harder to know which effects are from the gc/finalization strategy and which 
are from increased workload.

.sol.death.predicted: An object's death time can be chosen when the object is 
born; however, if the population needs to be stable, then only one object can 
die at any time, so picking the death time requires knowledge about the death 
times of other live objects.

.sol.death.chosen: An object's death time can be chosen implicitly: an object 
is selected to die at each step, and the current time becomes the object's 
death time.

.sol.lifetime: Several object lifetime distribution classes are possible.

.sol.lifetime.real: Objects with "real" lifetimes have a lifetime distribution 
similar to objects in actual programs; empirically, most objects die young and 
older objects die in unpredictable ways.  At the same time, lifetime profiles 
are highly application specific.  "Real" lifetimes can be had by instrumenting 
real programs with finalization code.

.sol.lifetime.random: A random lifetime distribution can be implemented by 
keeping the population in an array and randomly select an object for death.  
Each object is equally likely to die, and the probability of an object living 
to age m is inversely exponential in m.  If the population is n, then the 
average age at death is roughly n.  There is a long tail: some objects will 
live for a long time.

.sol.lifetime.priority: A priority-based lifetime distribution can be 
implemented by keeping the population in a priority queue and select the object 
to die by a function that makes older objects exponentially more likely to die 
than young objects.  That is, the priority queue key is (1.0+R)^age where R is 
a random number in [0..1).  Empirically, if the population is n, then the 
average age is roughly n/2, objects do not live past age 3n, and object death 
age is informally described by a bell curve with its peak at about n.

.sol.lifetime.exact: An exact lifetime distribution can be implemented by 
iterating over the ages m to be tested, and using a circular buffer of length m 
for intermediate storage.  Objects are placed in the buffer and die when the 
buffer slot is overwritten after m-1 other objects have been allocated.  The 
average age will be n/2 and all objects die at age n.

.sol.lifetime.closest: A closest-to-chosen lifetime distribution can be 
implemented by selecting an object age for death from some probability 
distribution and then killing the object in the population that is closest to 
the chosen age; the object age would be chosen from the interval of available 
ages.  A skip-list seems like a suitable data structure.  Empirically, if the 
population is n and the probability distribution is uniform, then the average 
death age is n, objects do not live past age 3n, and the fraction of objects 
that die at an age is related to the age by an inverse exponential function.

.sol.time-to-finalization: Time to finalization can be measured by annotating 
each object with its death time and have the object finalizer record the time 
it takes between death and finalization.  A data structure keyed on object age 
can track the time-to-finalization statistics for each object age.

.sol.unit-of-finalization: Note that even if the unit of allocation is the 
object group, the unit of finalization will be the node.  We can either have a 
"root" node in the group that has a finalization method (while none of the 
other nodes in the group do), or we can let every node have a finalization 
method.



TEXT:

.note.lifetime: Some Scheme and Java programs were crufted together to 
empirically evaluate the models, resulting in the following observations.

.note.lifetime.random: Empirical evaluation of .sol.lifetime.random yields the 
following results.  For a population of 100 over 10,000 iterations, ages killed 
ranged from 1 to 919, with an inverse exponential distribution and a peak 
between 2 and 5 somewhere.  There is a long, slender tail.

.note.lifetime.priority: Empirical data for .sol.lifetime.priority are based on 
experience with the initial benchmark implementation.

.note.lifetime.closest: Empirical evaluation of .sol.liftime.closest yields the 
following results.  For a population of 100 over 10,000 iterations, the ages 
killed ranged from 1 through 288.  The distribution of death ages is vaguely 
inversely exponential but with peculiar plateaus: age 1 had 98 killed, age 2 
had 62, age 3 had 64, then every age has between 60 and 40 killed (with a 
couple of dips into the 30s) until we get to about age 160, then it's between 
40 and 20 killed for a while, and then it drops off rapidly into the teens and 
then single digits.  The average death age was 99.8.

