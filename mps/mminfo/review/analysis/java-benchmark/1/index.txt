                  REVIEW OF ANALYSIS.JAVA-BENCHMARK(1)
                    review.analysis.java-benchmark.1
                           incomplete review
                           gavinm 1998-07-06

Loggingstart: 15:16 GMT
Loggingend: 16:04 GMT
Logginglength: 48
Loggingrate: 1.1

Actual checking time: 85

Kickoff start: 1998-06-19


ISSUES:

PTW: 15 minutes, M: 1, m: 3, C: 0, q: 1, I: 1
LTH: 2 major, 3 minor, 1 unsure, 15 minutes
RIT: 15 mins. 8 M, 9m.
DRJ: 2M 3m, ~20 minutes.  forgot to go backwards
Tony: 5M, 4m, 2c, 20minutes

DRJ:
1. M .req.early-bird clarity. it says: "first such products", I say "what such 
products?".  e.g. distinguish between this is a member of all hqn's benchmark 
products...
  and this as a member of all industry's benchmark
  and perhaps this as a member of all hqn's java related products
2. M .req.measure omission.
  There is no mention of finalization/weakness/persistence/
  multiprocessor issues / interoperability with native methods and foriegn 
languages
  no reference is made to the semantic specifications of java.lang.ref (JDK 1.1 
and higher) or java.lang.Runtime.MemoryAdvice (JDK 1.2 and higher)

Tony:
3. M .goal.use Sounds like a sub-goal of .goal.endure
  GavinM: .goal.use, I see a distinction between useful and used.
4. M .req.comparison I think there's a confusion between comparing JVMs
  & MMs
5. M .req.maintained Sounds like a solution, not a requirement. Why must it be 
Harlequin?
6. M .req.mps-compatible Sounds backwards? Requirement should be for MPS to run 
the benchmark. Contravenes .req.impartial?
7. M .goal.* There's no indication about why we're doing this. The only
  general goal that is served is goal.general.image. Should be a goal
  about increasing revenue for some saleable product.

RIT:
8. M .goal.* should relate to .goal.general
  and to docs on the MM Java product. I don't know what such docs are.
9. M .structure: As the comment says.
10. M .req.comparison: should also require comparison across platforms?
  DRJ sucks air through teeth
11. M .omission.identify: I've said it but it's still a defect.
12.  M .omission.measure: ditto
13. M .issue.goal.characterise: ditto
14. M .issue.req.mps-compatible: ditto

PTW:
15. M 42-97, req.* rule.req.test no tests are defined (although some are 
implicit)

LTH:
16. M .rec.scaleable: should note before I have to waste time on it that the 
scalability should not necessarily be automatic.
17. M .req.measure.functionality needs to exist (cf. rdj's comment about 
finalization etc)
  RIT: I don't understand how you can measure functionality.
  DRJ: MMQA is telling us they don't know how to measure functionality?
  LTH: You can look at eg. incrementality vs not, heap expansion and 
contraction vs not, and similar things.
  that is, what distinguishes reasonable from sucky
  DRJ: how do you know if the MM meets its requirements?
  RIT:  Yup. Functionality is have or have not. Not really measurable.
  PTW: testable then?
  DRJ:  so, because it's binary it's not measurable.
  RIT: Yes, testable. I intended that to be covered in .req.measure.correctness.
  But I see that it would be good to be much more explicit about it.
  Tony: There might be a quality issue with finalization

DRJ:
18. nM .req.measure doesn't mention reliability

LTH:
19. M .goal.inform mentions useful, but useful to whom, and in what way?  Not 
sure if this is M or m or C.

[ Brief intermission while GavinM reboots his Mac. ]

Tony:
20. m .req.impartial Arguably this also serves .goal.characterise
21. m .req.comparison Grammar
22. m .req.comparison Also serves .goal.characterise

DRJ:
23. m .source meeting minutes should be entered into infosys and reffed from 
here.
24. m .goal.use looks like a sub-thingy of .goal.inform to me (they are 
informed by using it).
  RIT: But only if they _do_ use it!
25. m .goal.endure extraneous ']'
26. nI rule.req.test is wrong, as it restricts the requirements we can harvest 
from clients which may lead us to forget/drop/ignore important customer requests
  rule.req.test says that requirements must define a test which can be applied 
to determine whether the requirement is satisfied
  but our clients may have requirements which are not easily testable
  which are very very important.
  e.g. "pause times must be psychologically acceptable", "must not cause OEMs 
to go ape and sign up with Adobe"
  PTW: I see.  So you fear we might leave out a requirement because we cannot 
define a test for it?
  DRJ: yes
  I think it's better to have a vague or hard to test (or possibly even define) 
requirement that you can work towards than it is to miss out the requirement 
altogether.

RIT:
27. m .goal.endure. "e" should be in bold.
  DRJ: we used a PC to print out the document, so naturally, none of it is in 
bold!
  RIT: Then my subliminal messages won't have worked!
28. m .req.impartial: The last sentence isn't strictly part of the req. Should 
be in brackets.
29. m .req.portable: punctuation
30. m .req.measure.leakage: punctuation
31. m paragraph after .justification-score.goal.endure: This para has no tag.
32. m ibid: and MPS should be in capitals

PTW:
33. I   Document under review should be formatted with line numbers to aid in 
cross-referencing defects
34. m 55, req.comparison type-oh \"The benchmarks should [allow? permit?] 
meaningful...\"
35. m 56, req.comparison clarity define JVM
36. q 118, omission.identify  Is a stake-holder analysis needed, appropriate?
37. m 42-97, req.* rule.req.sep requirements are not identified as functional 
or attribute
38. nI document the MM Java Product
39. nI proc.review.log specify the format of log entries

LTH:
40. m .rec.public: benchmarks should be available in source form
41. m .rec.comparison: missing 'allow' (Grammar)
42. m .rec.measure.speed: I prefer 'time' to 'speed'

GavinM:
43. rule.goal I For "which", read "that", throughout.
44. .source mN Should have had whiteboard as source document.
45. .goal.characterise m This should be merged in with .goal.inform
46. .req.coverage q Is this in the Java language or in the JVM?
47. .req.easy m This should say how easy.  What about describing the minimum 
target user?
48. .req.measure m Instead of "At least one of", how about "The set of"?
49. .justification-score.* m No semantic indication of which goals relate to 
which score
50. .omission.identify C Stakeholders include: JVM clients in HQN, JVM clients 
worldwide, MPS developers, JVM developers worldwide
51. .issue.goal.characterise m Not clear what "this" is.
52. .issue.req.mps-compatible m Not clear what "it" is.



Brainstorm start: 16:22 GMT
Brainstorm end: 16:42 GMT
Brainstorm length: 20


BRAINSTORM:

GavinM: Ok.  I've chosen four major issues.
  Remembr we're trying to find ways to prevent issues of this type occurring in 
future.
  > DRJ: 2. M .req.measure omission.  There is no mention of 
finalization/weakness/persistence/multiprocessor issues / interoperability with 
native methods and foriegn languages no reference is made to the semantic 
specifications of java.lang.ref (JDK 1.1 and higher) or 
java.lang.Runtime.MemoryAdvice (JDK 1.2 and higher)
  How did this happen?
RIT: Could (would?) have been spotted by drj if we'd done a RFC.
PTW: None of the participants of the source meeting are Java experts
DRJ: experts might be hard to come by, I'm certainly not one.
GavinM: So we should have had DRJ in on the meeting?
  OR had an RFC round?
PTW: Yes
DRJ: I think lack of RFC was contributory.
Tony: RFC sounds like it would have been useful
PTW: Where "have drj" means "invite appropriate attendees"
GavinM: I think I was over-keen to hold a review in 1CC.
  We could have taken more calendar time to get this document right.
DRJ: aha, hidden goals for the review
PTW: So chalk this up to inducting Lars into "The Process"
Tony: Sounds like gavin should have gone next week, then
DRJ: (but then he wouldn't have had the original meeting, perhaps he should've 
gone for two weeks)
GavinM: OK.  We have some ideas there.  Let's move on.
  (I wouldn't have minded two weeks.)

  > Tony 7. M .goal.* There's no indication about why we're doing this. The 
only general goal that is served is goal.general.image. Should be a goal about 
increasing revenue for some saleable product.
  How did this happen?
DRJ: indeed, I get the feeling that the whole effort (benchmarking java) has 
been rather sprung on the group.
PTW: We forgot to use goal.general as a source?
GavinM: It would have been less springy if I had been about in the last two 
weeks.
DRJ: Again I suspect squeezing things into a short timescale hasn't helped.
Tony: Incidentally, I'd like to know the answer, as well as the reason I wasn't 
given it
DRJ: ah yes, poxy managers.
  offence only intended humourously.
PTW: tony: what do you mean?
Tony: I mean, I want to know why we're doing this
GavinM: Tony, I think I have to make some input on that one.  I'll come up with 
something next week.
Tony: As well as why the document didn't say
RIT: Not, an answer, I know, but EP2000 is (largely) written in Java.
  Performance guarantee => we know about Java performance
   => either we measure a JVM or we adapt one?
GavinM: I believe it's a good idea, but the impetus and timing are partly 
political.
Tony: I can believe it's a good idea too. But it needs justification.
RIT: Also: if MPS is ever to be external product, we need experience of more gc 
languages than just Dylan.
GavinM: So this would probably have been better justified in the meeting if I'd 
had my head screwed on better.
  RIT, true, but that applies to the java product, not the benchmark.
Tony: Rit: making a benchmark suite available doesn't sound like the most 
productive way I can think of of getting language experience
PTW: I think the UK is just seeing a typical case of where one side of the pond 
has forgotten to communicate with the other
RIT: Indeed. I said it wasn't an answer. I can think of more reasons for 
putting MPS in java than I can for benchmarks.
PTW: We've had buy-in from Sr. mgmt (that spanish fellow) since last fall on 
this.
  Usually it's me that is surprised by new projects we have taken on.  So there.
RIT: Well make sure it gets said sometime.
GavinM: I know there's more to say here, but I'd like to move on.

  > DRJ: 18. nM .req.measure doesn't mention reliability
  How did this happen?
DRJ: I was wondering if we should have a requirements and goals template
  basically software requirements are all of the same form.
  once you've worked out what it should do, you then need to ask:
  what do you want when?
LTH: [Appropriate?] I'm not sure how reliability differs from correctness?
DRJ: how much time should it take, how much space?  how much hardware
PTW: [except for the EP ones ;-)]
DRJ: how reliable?  etcetc
  in practise we allow most software to be a bit buggy (or unreliable as we 
weaselly put it).
RIT: How is reliablility a gc-specific aspect of Java functionality?
DRJ: it's not
RIT: i.e. how to test for _gc_ reliablity rather than general jvm reliability
  Then maybe it's not required.
GavinM: How could we have avoided this (arguable) omission?
DRJ: however the java MM will have a certain reliability
  oh, it's hard to test, therefore not required.  q.v.
RIT: No, sorry, that's not what I mean.
PTW: drj's template
GavinM: How could we have ensured we considered this sort of point? 
DRJ: I was being a bit sarcastic.  oops
RIT: But we're not talking about producing a comprehensive Java benchmark 
suite. Just aJava MM benchmark suite. Or am I wrong?
GavinM: DRJ, could you come up with a draft?
DRJ: er, I could come with a draft.
PTW: rule.req to list categories of req that must be mentioned
GavinM: Thanks.
DRJ: how reliable do you want this draft to be?
LTH: Producing a comprehensive Java Benchmark Suite is certainly a Big Job.
DRJ: when do you want it?
GavinM: DRJ, medium, next week, no.

  > LTH: 19. M .goal.inform mentions useful, but useful to whom, and in what 
way?  Not sure if this is M or m or C.
PTW: Stakeholder analysis
GavinM: Yeah.  We should remember the stakeholder stage of analysis.



Number of major issues: 19
Number of minor issues: 25
Number of issues: 52
