                           PROFILING THE MPS
                              proc.profile
                            incomplete proc
                            pekka 1998-03-19


.intro: This document describes different ways of profiling the MPS, and how to 
use the results.


WHEN TO USE PROFILING

.performance: Profiling is best used to analyse performance problems.  
Verifying the existence of a performance problem should be done by benchmarking 
(with some fixed and documented benchmark), because profiling introduces random 
variation and systematic error.

.call-counts: Most profiling tools can be used to measure call counts of 
functions.  Similar information can be extracted from the event stream, but 
profilers can often provide more information about the (dynamic) call graph.


HOW TO PROFILE

General

.twice: Always do at least two separate profiling runs of the same program, to 
see what the random variation in the timings is (you will be surprised).  Note 
both the variation in the total time and individual function timings, and do 
more runs if the results aren't good enough.

.log: Keep logs of all the runs to help in the analysis, and don't throw away 
any of the result sets until you've finished using the profile data.


Gprof

.gprof: gprof is a sampling profiler [really? -rit 1998-05-19] available on 
some Unix platforms.  It requires recompilation of the code to be profiled (but 
you can have non-profiled code in the same executable), and linking with a 
special library.  The resulting executables run about twice as slow, and 
generate gmon.out files, which are then postprocessed to produce the profile 
data.

.gprof.compile: To support the recompilation, we have created builder.gp and 
platform.sos8gp.  Incidentally, the justification for having a separate 
platform, rather than a make option, or a target, is that: You want to generate 
gprof versions of all targets, including libraries; and generating this output 
slows the executables significantly and it is useful to alternate between 
profiling and benchmarking.

.gprof.compile.sw: You might want to compile the glue code for profiling as 
well.  This is done by editing (SWprod_motif)make:makefile.unx to include the 
-pg switch in CDEFINES.  To link with the right library, find the link.lic 
target in (SWprod_motif)make:makefile.unx, and change it to use 'gcc -pg' 
instead of '$(LDDBG)'.  You might also find that you need to change $(SYSLIBS) 
in this target to
  -lgcc -lm -lintl -lelf -lnsl -lsocket -ldl -lgen -lthread -lc -L/usr/ucblib 
-R/usr/ucblib -lucb

.gprof.postprocess: Once the program run has finished, do this
  /usr/ccs/bin/gprof -E internal_mcount image-file > profile-file
This will put the results in profile-file.

.gprof.postprocess.sw: For SW, you'll also want to exclude interpreter_loop.
  gprof -E internal_mcount -E interpreter_loop image-file > profile-file

.gprof.doc: See also 'man gprof' on a suitable Unix platform.

.gprof2html: person.gavinm has a gprof2html tool, to help in browsing the data.

.gprof.qa: To use gprof with the QA tests requires the use of an appropriate QA
platform.  See person.rit for details.


The Dylan Profiler

.dylan-profiler: On intel windows platforms, the dylan debugger (console-debug) 
contains a sampling profiler which can be used on C as well as Dylan programs. 
No recompilation or relinking is required. Wall time, inclusive and exclusive, 
is measured per function, and attributed according to the calling function. 
Because it is a sampling profiler, it's possible that memory accesses might 
skew the sampling and make some functions appear disproportionately high or low 
in the profile. The profiler is not particularly robust, and fails when 
profiling ScriptWorks.  [rit 1998-05-19]  @@@@


CAP

.cap: The Call Attributed Profiler, which comes in the NT 4 (Intel) SDK. This 
is a non-sampling profiler, which requires you to recompile and relink your 
program. It attributes times to arbitrary depth, allowing you to explore the 
whole call-graph. (Q: How does it deal with cycles? A: It doesn't -- it just 
writes out the call graph as deep as you recurse.) A fancy graphical program 
(CAPVIEW.EXE) lets you look at the results and colours hotspots for you, r you 
can process them yourself (they're in a text file). More robust and reliable 
than the Dylan profiler (you can use it on ScriptWorks), but I don't trust its 
time measurements -- only the percentage times seem to be at all reliable.  
[rit 1998-05-19]

.cap.info: Run CAPVIEW and look in Help, or in Visual C++ books "Platform, SDK, 
and DDK Documentation\Platform SDK\Building Applications\Tools 
Guide\Tuning\Performance Tuning Win32-based Applications\Call Attributed 
Profiler". [pekka 1999-05-24] But beware that documentation for CAP is not 
consistent about what compiler and linker settings it recommends. The most 
recent advice I have found is "Troubleshooting CAP/WST Utilities under Windows 
NT" at <URL=http://support.microsoft.com/support/kb/articles/q169/2/75.asp>.

.cap.cap-mapper: Tony has written a tool, cap-mapper, that postprocesses CAP 
profiles, filling in the names of symbols that CAP couldn't find. Since CAP 
never gives names for static symbols, this is invaluable. See tool.cap-mapper 
for details.

.cap.compile.mm: To compile a CAP-profiling version of MPS, you need an 
appropriate makefile. It will probably be called "w3i3cv.nmk" or "w3i3cp.nmk". 
If there isn't one in the version of MPS you have, you may be able to make one 
as follows: (Of course you can only use CAP on Intel NT.)

.cap.mps.makefile: Make a copy of "w3i3mv.nmk" and call it, say "w3i3cp.nmk". 
Then open it in your favourite editor and make the following changes:
1. global replace "w3i3mv" by "w3i3cv"
2. global insert "/Gh " before "$(CFLAGSCOMMONPOST)"
3. global insert " /DEBUGTYPE:coff cap.lib" after "$(LINKFLAGSCOMMON) $(LF..)"
   (where the ".." means match any two letters).

(e.g. if your favourite editor is vi:
 :%s/w3i3mv/w3i3cv/g
 :%s/\(\$(CFLAGSCOMMONPOST)\)/\/Gh \1/g
 :%s/\(\$(LINKFLAGSCOMMON) \$(LF..)\)/\1 \/DEBUGTYPE:coff cap.lib/g
)

Of course I don't guarantee this will work in all versions of the make files. 
It at least works in the trunk of MMsrc on 1999-06-10. In future MMsrc will 
probably include such a makefile (see mail.pekka.1999-05-27.16-34(0)).

.cap.mmqa: To profile MMQA tests, you will need a memory manager compiled for 
profiling as above and the MMQA test harness version 3.2 or later (see 
guide.mmqa for general instructions about the MMQA tests and harness). Then you 
should:

1. create a file CAP.INI in the current directory, as follows (don't include 
the "BEGIN" and "END" lines:
----BEGIN CAP.INI---
[EXES]
tmp_test.exe

[PATCH IMPORTS]

[PATCH CALLERS]

[NAME LENGTH]
128

---END CAP.INI---

2. set the QA harness's PLATFORM option to "nt_x86_cap" (e.g. by setting the 
environment variable MMQA_PLATFORM=nt_x86_cap).

3. set the harness options MPS_INCLUDE_DIR and MPS_LINK_OBJ to point to the 
profiling version of MPS (and plinth).

4. run tests as usual. Profiles will be written to 
mmqa\test\obj\nt_x86_cap\TMP_TEST.END. If you run more than one test (or one 
test more than once) you'll get several profiles appended in the same file. 
This isn't a good idea, so delete or move the file somewhere else before 
running each test.

5. run "cap-mapper mmqa\test\obj\nt_x86_cap\TMP_TEST.END 
mmqa\test\obj\nt_x86_cap\tmp_test.exe" to generate an improved profile which 
includes symbols for static functions (in the file TMP_TEST.END.scap). (See 
.cap.cap-mapper above.)

.cap.sw: To profile the MPS in Scriptworks:

1. build a profiling version of mmsw.lib (you'll want variety.wi for 
performance measurements).

2. set Scriptworks to use this memory manager, by editing pc\mm\make\makefile.pc

3. set Scriptworks' link options: look in pc\tools\makebits\general.pc, and 
find the section "Intel NT options". Add two lines (after the one that 
currently sets EXTLNOPTS) as follows:
  EXTLNOPTS=-debug:full -debugtype:both -pdb:none
  NTPROFLIB=cap.lib

4. build Scriptworks with "tools\swmake -ms +r". If you're already built it, 
you only need to make sure it relinks with the new MM. One way to ensure this 
is to delete the directory pc\mm\oon and its contents before running the build 
command.

5. create a file CAP.INI in the current directory, as follows:
----BEGIN CAP.INI---
[EXES]
guin.exe

[PATCH IMPORTS]

[PATCH CALLERS]

[NAME LENGTH]
128

---END CAP.INI---

6. Run SW. Profile will be output in GUIN.END. Run "cap-mapper GUIN.END 
guin.exe" to obtain symbols for static functions (see .cap.cap-mapper above).




MSVC profiler

.msvc-profiler: Works with MSVC. Non sampling. Relink required, then a 
complicated series of calls to PREP and PROFILE. Can be calibrated, but there 
are no proper instructions on how to do so, and it's _impossible_ to get 
consistently plausible exclusive function times. These are probably useless; 
percentages also vary quite a bit but give you a rough idea where time is 
spent. CAP seems both more useful and more convenient.  [rit 1998-05-19]  @@@@



HOW TO USE PROFILING DATA

.compare: Basically, we either compare two profiles and look for differences, 
or look at one profile and compare the numbers against our mental model of the 
computation.  When we find a function that is taking too long, we need to 
consider whether it's being called too much, whether one of the subfunctions is 
too slow, ot whether it is itself too slow, or all three.

.error: The most important thing to do is to determine the accuracy of the 
results.  It is not unusual to get unexplained variation of 20% in the timings, 
and in small functions the random variation can completely swamp the 
differences that you are looking for.

.error.sampling: For random sampling errors, the variation should be relatively 
smaller in those timings that consist of a larger number of measurements.

.error.calibration: Profilers spend time (and other resources) doing their 
measurements, and then try to subtract this out the measurements to show only 
the part due to the application itself.  Sometimes is adjustment is 
miscalibrated.  In such cases, the error would usually be proportional to the 
call counts: look for two functions with similar code, but different call 
counts and see whether the numbers make sense.

.error.sw: SW dongle validation and other security checking can take .3-.5s at 
random points in the program.

.error.other: If you think you have identified a systematic error and plan 
massage the figures to take it into account, extract the all relevant numbers 
out of the results and do a statistical analysis: if it was that simple, they'd 
have done it already.  Do not fall into the trap of only believing those 
profile runs that produce results in line with your preconceptions.

.error.living-with: Even profiles that contain unreliable timings can be 
useful: they still give you an overall picture of what's important and what's 
not; the call counts are usually reliable; and benchmarks can be used to 
validate conjectures made on the basis of inaccurate profiles (after changing 
the program according to the conjecture).


