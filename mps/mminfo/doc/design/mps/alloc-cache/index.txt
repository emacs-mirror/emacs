                    THE DESIGN OF ALLOCATION CACHES
                         design.mps.alloc-cache
                             incomplete doc
                            pekka 1999-03-02

INTRODUCTION

.intro: This document describes allocation caches, a feature for exporting 
certain parts of the allocation mechanism to client code, for speed and thread 
synchronization.

.readership: MM developers.


Document History

.hist.0: Pekka wrote the initial draft based on Tony's writeup, 
mail.tony.1999-01-14.18-59, on the notion of a more general form of allocation 
point as discussed in mail.pekka.1998-02-05.12-40 et seq. (Subject: Allocation 
points for manual pools) and verbally discussed between Pekka and Tony on 
1999-01-12.


OVERVIEW

.overview: Allocation caches provide a way of open-coding allocation from a 
cache separate from the pool that it gets its memory from.  Some cache types 
also allow frees to insert the block into the cache without a costly function 
call.

.color: The initial implementation is meant to improve the performance of the 
SW color pool.  The color pool has a very high turnover of allocations and 
frees, although the amount allocated at any instant in time is not particularly 
high.  The objects allocated have varying sizes - although some sizes are 
particularly common.  We know (from Andy Cave's experimentation) that the 
requirements of the color pool can be very successfully met by a segregated-fit 
policy, keeping a separate freelist for each size class.  Andy's experiments 
involved extensions to the SW glue code.  However, EPcore would prefer a 
solution that is maintained and supported by MM directly.


REQUIREMENTS


Initial

.initial: The initial requirements are only for release.epcore.brisling.4, to 
support the color pool.

.req.init.speed: Allocate color pool objects faster than is possible with 
mps_alloc and mps_free on MV (critical).

.req.init.risk: Low technical & quality risk (essential).


Future

.req.common: Common interface with allocation points (see design.mps.buffer).

.req.extensible: Extensible to future types of allocation cache/point.

.req.speed: Allocate objects with minimal overhead, given the basic data 
structure chosen for each type of cache.  In particular, function calls should 
be minimized.

.req.sync: Synchronize with the collector (when used with a scannable pool and 
appropriate alloc interface), with minimum overhead to the mutator.

.req.control: Allow the client to flush the allocation cache, so that caches no 
longer (actively) used don't hold onto memory needlessly.

.req.share: Allow the MPS to ask the cache to return memory to the pool (and 
the pool has a similar requirement to return stuff to the arena) -- this 
doesn't need to happen synchronously (because it would place an larger burden 
on the mutator).

@@@@


Discussion

.extensible: In addition to segregated caches and current allocation points, we 
can imagine two other forms of cache: fixed-length caches (just pop the first 
one off a list), and first-fit caches (data structure to be determined).  
Neither seems particularly urgent, once we have segregated-fit caches, since 
fixed-length is just a special case of segregated-fit, with a small overhead, 
and first-fit seems pointless if the segregated-fit cache is fast enough.



ARCHITECTURE

.ac: An allocation cache (AC) holds some memory (acquired from an associated 
pool) for its exclusive use in some data structure that allows fast in-lined 
allocation.  As with APs, the client is responsible for synchronising access to 
the cache, but if the cache decides to access the pool, the MPS will properly 
synchronize with any other threads that might be accessing the same pool.

.terms: The new terminology

  AC  (Allocation Cache)
   Generic name for objects which support lightweight allocation/deallocation

  SAC (Segregated Allocation Cache)
   Specific type of AC for implemementing segregated fit

  BAC (Blocked Allocation Cache)
   Specific type of AC for implemementing buffered allocation a.k.a. allocation 
point

.sac: A segregated allocation cache (SAC) implements a segregated fit policy.  
It will hold a client-specified number of free lists for different size 
classes.  The choice of size classes is a client-specified option.

.ap: APs will be reconceptualized as a type of AC.  Changing the naming 
convention gives us a chance to fix the parameter lists of mps_reserve & 
mps_commit.

.alloc: Typically, all allocation caches support both one-phase (mps_*_alloc) 
and two-phase  (mps_*_reserve &  mps_*_commit) allocation interfaces.  The 
one-phase interface will include enough synchronization to allow the MPS to 
claim back memory held in the cache, but, respecting .req.share, only when the 
client traps into the MPS.  (This could be used to synchronize with an 
incremental collector, if we ever implement an mps_*_alloc_zero interface or 
equivalent.)  We believe that the synchronization mechanism can be shared by 
all interfaces.

.pools: Allocation caches would typically work on top of one or more of our 
existing pools (e.g., MVFF, EPDL or MV, but not MFS), although in the future we 
might craete pool classes specially suited for this purpose.  If used with an 
automatic pool, calling mps_*free will assert (unless of course we have 
implemented some extension that allows this).


MPS Control

.sync: As is the case with APs, client code can access the SAC memory resources 
(freelists) without locking.  If MPS is to maintain any control of this memory 
(e.g., if it wants to be able to return it to the arena) there must be a 
lightweight synchronization mechanism for trapping the AC.  When the mutator 
trips the SAC it calls into MPS which may then modify the SAC safely.  In order 
to reduce the size of the in-line code, it may well be desirable to pun the 
trap actions with normal out-of-line alloc & free calls (similarly to APs).  
Hence we need some SAC-specific "fill" and "empty" functions.


SACs

.inline: Allocation and deallocation requests will be implemented with in-line 
code (via macros in mps.h).  Without locking, this code will round the size up 
to the nearest segregated size, and pop the first block off the freelist of 
that size if there is one.  If there is no free block, the allocation will be 
handled out of line by allocating from the associated pool.  Free requests will 
also be implemented with in-line code, which simply pushes the block onto the 
freelist of the appropriate size.  If the freelist gets suitably big, it could 
be reduced in size by freeing some of the blocks back to the pool.  This is 
desirable - but might not be strictly necessary for the color pool given its 
allocation patterns.


INTERFACE


/* Allocation Caches Interfaces for mps_sac (segregated fit) */

typedef struct mps_sac_s     *mps_sac_t;     /* allocation point */

typedef struct mps_sac_s {       /* allocation point descriptor */
  mps_bool_t trap;           /* "trap" status */
  mps_size_t freelist_size;  /* size of data on the freelist */
   ...
  mps_addr_t freelists[10];  /* freelists - details TBD */
} mps_sac_s;

typedef struct mps_sac_classes_s {
  size_t max;
  size_t cache_size;
} mps_sac_classes_t[MPS_SAC_CLASS_LIMIT];

mps_res_t mps_sac_create(mps_sac_t *sac_o, mps_pool_t pool, size_t 
classes_count, mps_sac_classes_t classes);
  /* create an SAC object */

void mps_sac_destroy(mps_sac_t);
  /* destroy an SAC object */

mps_res_t (mps_sac_alloc)(mps_addr_t *, mps_sac_t, size_t, mps_bool_t);
  /* alloc an object, using cached free space where possible */

void (mps_sac_free)(mps_sac_t, mps_addr_t, size_t);
  /* free an object, making it available to the cache where possible */

mps_res_t (mps_sac_reserve)(mps_addr_t *, mps_sac_t, size_t, mps_bool_t);
  /* reserve space an object, using cached free space where possible */

mps_bool_t (mps_sac_commit)(mps_addr_t *, mps_sac_t, size_t);
  /* commit reserved object, or clear pointer */

void mps_sac_flush(mps_sac_t);
  /* flush the cache, releasing all memory held in it */

.interface.reservoir: mps_sac_alloc and mps_sac_reserve take a boolean to 
indicate whether they have permission to use the reservoir.  This doesn't cost 
much, since the parameter is only used in the event of a cache miss.

.interface.future: There will probably be debug versions of alloc and reserve 
in the future, but that's the limit of it.


IMPLEMENTATION


.impl.struct: In the same way that an AP is but a part of a BufferStruct, so an 
SACStruct = mps_sac_s will be but a part of a larger struct 
(InternalSACStruct).  There is definitely scope for shared protocols for all 
types of ACs -- but that's not being designed now.


SAC implementation

.impl.sac.params: mps_sac_create expects to receive information about the sizes 
of the
segregated allocation classes.  Ideally, these would be supplied in the 
following form, in decreasing order of expectancy of allocation frequency:

   (5, 128, 100, 512, 64, MPS_MAX_SIZE)

The initial 5 is the number of classes being described (should there be an 
implementation limit?).  The remaining numbers imply that the following 
allocation classes will be used:

   128    -- for sizes in the range (100 - 128]
   100    -- for sizes in the range (64 - 100]
   512    -- for sizes in the range (128 - 512]
   64     -- for sizes in the range (0 - 64]
   exact  -- for sizes in the range (512 - infinity]

.impl.sac.decision-tree: Ideally, the decision tree for choosing the size would 
check for the most common range first and optimize further choices similarly on 
failure.  But that may tricky to do -- and may also be too slow for the color 
pool's needs -- so we might choose to simply sort these numbers for now.  FWIW, 
sorting them downwards has the slight implementational advantage that it puts 
the special case of oversize objects first (which may be streamline the code 
given that there's a dynamic number of cases).  But note that this might be 
poor for some allocation patterns.  It's probably OK for the color pool, though.

.impl.sac.decision: mps_sac_alloc & mps_sac_free must each implement this 
decision tree, in order to pick the appropriate freelist.  For simplicity, they 
may well not use a freelist at all for "oversize" objects (which are exactly 
sized), in which case alloc & free calls will go out of line.

.impl.sac.alloc: mps_sac_alloc must check the trap first on each invocation, 
and call out-of-line (via mps_sac_fill) if set.  Similarly it must call 
mps_sac_fill if the freelist is empty.  OTOH, if it can allocate from the 
freelist, it should do so without involving MPS (but remembering to decrement 
freelist_size).

.impl.sac.free: mps_sac_free should also check the trap first on each 
invocation and call mps_sac_empty if set.  Otherwise, it should check the 
freelist_size, and if adding the free block would make it "too big" (concept 
TBD, and possibly overkill for brisling.4), it should also call mps_sac_empty.  
In other cases, it should push the block onto the appropriate freelist, and 
increment freelist_size.

.impl.freesize: Functions inside MPS are entitled to read freelist_size at any 
time (e.g., in order to determine the total allocation of the pool).  However, 
they may only write this field when synchronized with the SAC -- e.g., inside 
mps_sac_empty & mps_sac_fill.  .impl.freesize.pool: Pool implementations will 
have to be modified if they are required to work with SACs and also maintain 
accurate information about their total free bytes.

.impl.sac.internal: mps_sac_fill & mps_sac_empty must be implemented inside 
MPS.  We add a new pool protocol to support these, and have PoolTriv* methods 
which invoke the pool's alloc & free methods.  If we wished to make things even 
simpler for brisling.4, we could avoid the new protocols and have mps_sac_fill 
& mps_sac_empty always call the "triv" function.

.impl.sac.fill: mps_sac_fill could allocate a number of blocks and link them 
all up on the appropriate freelist, but it's not strictly necessary to do this, 
and it wouldn't make much difference for the color pool.  I suggest we don't do 
this for Brisling.

.impl.sac.empty: mps_sac_empty should always free the block it's given via the 
pool free method.  It could also reduce the number of blocks on the freelist if 
there are too many or if MPS wants the memory back.  We might choose not to 
implement too much of this part for brisling -- but whatever we do should take 
into account the implementation of mps_sac_free.


NOTES

Brisling.4

.brisling.4: There's good empirical evidence that the use of segregated fit and 
mostly-in-line allocation/free sequences will improve the color pool 
performance substantially, since this is essentially just what Andy did 
(AFAIK).  Hence this should meet .req.alloc & .req.free.


Future-proofing

.new: We can add new types of allocation caches in the future.  Each addition 
would require a new set of interface functions to be defined.  Clients wishing 
to use them instead of an existing AC type would have to modify their code, but 
the naming conventions can all follow the same standard so the cognitive 
overhead is low.  It's necessary for there to be some degree of client source 
code changes, anyway, in order to get the benefit of the in-line macro 
expansion.

.class: It might be more appropriate to define AC classes, so that the create & 
destroy operations are generic functions on the class.  It would be possible to 
make that change in the future.

