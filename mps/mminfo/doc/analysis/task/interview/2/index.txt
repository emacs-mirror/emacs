               INITIAL TASK ANALYSIS -- INTERVIEW 2: TONY
                       analysis.task.interview.2
                             temporary doc
                           richard 1996-07-09

 - Report 2 

Interview Number 2. Tony. 

Normal Development Tasks: 

Compiler for Dylan.  Also compilers and language demonstrators for Lisp, in the 
past.  

Experience: 

Over 8 years. 

Platforms: 

PC, UNIX.

Software tools and environments: 
  
Past use of MM tools: 

Memory Problems in past: 

Compilers tend to be very memory-hungry.  You have to try to get adequate 
performance, and there are a number of problems associated with doing this.  
Compilers also tend to hang onto things forever.  This is not helped by garbage 
collection, if the compiler is embellishing its representations, so that the 
roots of your program reference more and more information.  One problem is that 
of trying to find why they hang onto more and more data. 

Another problem is the "Pig in the Python" problem.  This is to do with 
generational garbage collectors.  There is a whole mass of information 
generated during a compilation which is used for the duration of the 
compilation, and then thrown away at the end of it.  What should the GC do?  If 
it keeps it in the "first" generation, i.e.. the one collected most frequently, 
then this generation is very expensive to collect because there is so much of 
it.  If the information is "promoted", it is very expensive to get the world 
back to normality after the compilation is over.  What useful heuristics can be 
applied to the memory management model while the data is being generated?

Another problem: sometimes it is very hard to predict why an application 
allocates as much as it does.  I have used allocation profilers to work on 
this.  This applies to both frequency and size of allocation, although the ones 
that have caught me out have usually been related to frequency.  This implies 
that when writing code I may know the size of the allocation, but I may not 
have understood the control flow well enough to grasp how may times it was 
going to happen.  Alternatively, the allocation may be hidden, going on in 
system code which may not be as efficient as I thought.  

Solutions: 

There is no single solution which covers them all. Normally I have found a way 
around them on a case by case basis.  Where I have determined that more was 
being allocated than I thought due to some low-level function being less 
efficient than expected, I would typically use some other low-level 
functionality.  I would only find this out by lots of profiling and hard 
graft.  Sometimes the choice of data structures can make a significant 
difference, as when using vectors instead of lists, or when avoiding copying, 
if you can do destructive operations.  These minor changes have been solutions 
in the past: "coding around the problem".  

The solution to the "pig in the python" is typically to set up some heuristics 
such as "I have just finished a compilation, now might be a good time to do a 
serious GC".  (This is the LispWorks strategy).  

The solution to hanging on to memory, other than staring hard at the code, is 
to look at what  memory you have got, and see what you have got that you did 
not expect.  Look for what is confusing about it, and try to analyse it.  There 
are utilities around for looking at a heap, and for trying to work out what is 
pointing at it.  Try to work out why the GC is hanging onto it.  Typically the 
problem is as follows: once you have worked out what memory is being held, then 
you have to analyse what is causing that and fix it.  This may involve 
destructively modifying data structures to get them back to some sane value to 
specifically make them forget about data at the end of a compilation run. 

Other Tools that would be useful; Other ways of looking at the data: 

I can certainly imagine some tools.  Basic ones were available, and these with 
more polish on them would certainly be very useful.  The main ones were 
allocation profilers, which tell me quickly what it is in my program that is 
allocating.  What memory am I referencing , and what is it that is referencing 
it?  This would be a very good tool to have.  It could be a summative account, 
or a snapshot that changed as the program executed.  The choice could depend on 
the form of the User Interface.  The basic tool I have used in the past 
collects data from a run of the program, and then may display it in a sorted 
form.  The quality of the visualisation may vary greatly.  A standard profiler 
can also be a useful way of tackling allocation problems.  

Software Development

Any particular approach to software or development that works for you? 

No.  I work out what I am trying to do - formally or informally - i.e. a 
requirements capture phase.  This is followed by a design phase, almost 
certainly formal.  If there are other people involved we will probably at least 
end up with some written document describing interfaces.  On my own I probably 
won"t do this.  For a complex problem I may go through a prototype phase, but 
for something simpler I probably just start developing it, and go to bug fixing 
instead of replacement of prototype.  Normally I use both top-down and 
bottom-up approaches.  The balance depends on the problem.  

Is there a point in development when you specifically consider MM issues?

Yes, much of the work I am doing now is specifically about how I can get Dylan 
to work in conjunction with the memory managers.  This is not just about how my 
code while running is going to work with the memory managers, but how the 
memory manager is going to work with other people"s code in the run-time system 
that we are compiling for.  I need to think about it in two ways. 

How do you handle these issues? 

I don"t really have a set of "good practice" steps.  I rely on my experience, 
and talk to the different groups such as the MM group.  I know how GCs work, 
and I try to think it through.  There are some very specific issues in how 
Dylan might work with memory managers which are probably not very relevant 
here.  You probably want to know how an end-user would go about making sure 
that the MM interacted effectively with his code, so that you can design a GUI 
for him.  Is that what you want? 

An example of a specific problem is that for our example of Dylan we are using 
a conservative garbage collector.  This means that some data item on the heap 
might look like an pointer to some area of memory, and so would not be GC"d.  
This, though unlikely, could in theory be very severe, so we have to think 
about how often it might happen, and how we can deal with it if it does happen 
too often.  

How do you test the results of your decisions? 

We have not done this, as it is hard to meter the performance of a MM.  Richard 
and Co. are thinking hard about this.  Also our implementation is in its 
infancy.  We would thus expect to do a lot of metering at a later date.  We 
know what information we would want to see, even if we don"t know just how it 
should look.  

We want to know: 

  - how effective our MM has been, i.e.. what the heap looks like, in terms of 
a breakdown of different objects:

  - how long-lived they are, how much we are allocating;


  - how often we reference data in the heap that is a from a conservatively 
scanned reference rather than from a hard reference;

  - how much time we spend in GC, how much time in the different parts of 
phases of GC: conservative stack scan, tracing, processing, normal objects,  
copying; 
lots if information about efficiency.  

Another implementation detail about the interface to the MM we are using is 
that we have read and write barriers which are triggered by page faults inside 
the hardware.  We don"t now how often these will occur, or even just how 
expensive each one of these will be.  This is something we will need to measure 
very carefully.  We want to know how well the system will behave with very 
little memory, with lots of memory.  We will need to do lots of metering.  We 
want the MM tools to give us a good handle on this.  

Do you have tools to help with this?

Do you avoid particular techniques because of your requirements? 

Thinking about possible MM products. 

For a gain in performance or size, do you want a product "out of the box" or 
tuneable?  

Don't know.  If it did what we wanted straight out of the box I"d feel no need 
to tweak it.
 
Would you value a range of MM policies to suit the jobs at hand? 

I think it in inevitable that we will find specific needs for Memory Managers.  
Obvious examples are for "real-time" MM for applications, or for Multimedia 
applications.  Another is for applications with time constraints of various 
sorts.  This will certainly require some special tuning of the GC, if not a 
dedicated GC for the applications.  The other end you can imagine much less 
interactive programs where the cost of supporting an incremental GC is not 
really necessary.  The quest here would be for overall efficiency, rather than 
for good interactive pause times.  Where efficiency is an important 
consideration, whether overall efficiency, or GC efficiency, then the ability 
to tune or select the MM will be important.  

Would it help to have precise feedback on how a given policy affected your 
code?  

Yes I can imagine that if efficiency was important to me I would want to see 
how the parameters I could change were affecting my program.  Also, I would 
want to see how my program was working with the MM.  If there are very 
significant sections then I have the chance to find them and make modifications 
to improve the performance.  Small sections of code can often have a very 
important effect on overall performance, and you need to isolate these.  An 
example is a hard real-time loop, where one or two ways through it break your 
time constraints.  It is only those one or two that you are interested in.  

Would you consider any re-engineering of your software to work with the MM 
products?

Yes.  As an implementor of Dylan, I would like to support people building hard 
real-time applications and also very efficient applications, so we want GCs to 
cover a whole range of usage.  If this means that different parts of Dylan have 
to be implemented in different ways in order to fit in with different memory 
managers, then I can believe that is the right thing to do.  

As an application programmer, if I was concerned about real-time performance, 
then I would certainly be prepared to go in and modify my program in order to 
get it.  I am actually sceptical about the possibility of getting it without 
thinking about performance modifications at the low level.  

Do you have any reservations about using MM products? 

Hard to say without seeing any tools etc.  I don"t see any real downside as 
long as it works.  As long as it does not affect performance when I am not 
using it.  I think it is an important area. 

Would this apply for the rest of your team? 

I expect so.  They might have other things to say, but I think they would agree 
with what I have said so far.  

Would you want your users (the OEMs) to have access to the MM tools?  Or even 
the end users?

Yes certainly.  To application developers.  There are two different levels of 
interest in the MM.  One is the language implementor who is trying to make his 
language work with the memory manager, the other is the application developer 
who wants to use the combined system.  Both have an interest in tools which 
show them what is going on.  The language implementor probably wants more, and 
will probably respond to it in different ways, but the application developer, 
if he has a program that is at all challenging or complex, will want to get at 
that information. 

As well as the feedback from instrumentation, we might want to make the MM 
parameters also available in some sanitised fashion.  I hope that we might make 
some form of bolt-on MM modules available in Dylan, with different ones tuned 
for different purposes. For example, the standard GC might be replaced with the 
real-time GC, or the "null" GC where you have a simple program that does not 
need the overhead of a GC. 

Anything else to add that we have not covered? 

I have written some applications in non-GC languages before, and met the normal 
problems such as forgetting to free memory, and then having to find out why.  I 
doubt if this is new to you.  

Any problems in that context related to speed or size? 

Yes - this was some years ago you understand.  The routines for "free" and 
"new" were larger than I would have liked.  They typically took up a word of 
header, and I was running on machines that would be scraping the amount of 
memory available.  I realised that one part of my program allocated objects 
with dynamic extent; i.e. it allocated them, used them, and then threw them 
away.  Instead of using the heap allocator to allocate them I implemented a 
stack allocator of my own, and used this to allocate an array of objects on the 
stack.  I just went and used one of these when I needed to, and simply gave the 
whole array back when the function had returned.  Interestingly, this had a 
huge impact on the efficiency of the application.  In Dylan or similar 
languages, this is just the kind of thing I would expect to be done by the 
compiler rather than the application developer.  

Were there particular tools that would have helped you work out what is going 
on? 

The same ones I mentioned before, but which were not available then: 

  - What is in my Heap? 

  - What is taking up all that space? 

  - What is allocating?

  - What is hanging on to memory? 

I was programming in Modula C, not a mainstream language, and the support tools 
were crap.

ATTACHMENT
   "Report 2"

