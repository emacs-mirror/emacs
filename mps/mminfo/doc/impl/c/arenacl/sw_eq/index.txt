                ARENA IMPLEMENTATION USING CLIENT MEMORY
                          impl.c.arenacl.sw_eq
                               draft doc
                           gavinm 1996-12-04

     1 /* impl.c.arenacl: ARENA IMPLEMENTATION USING CLIENT MEMORY
     2  *
     3  * $HopeName: MMsrc!arenacl.c(MMdevel_sw_eq.1) $
     4  * 
     5  * Copyright (C) 1996 Harlequin Group, all rights reserved.
     6  *
     7  * .readership: MM developers
     8  * 
     9  * .design: See design.mps.arena.client.
    10  *
    11  *
    12  * .req: The requirements are not fully known. They are inherited from
    13  * req.epcore, and from other requirements on the MPS. They include:
    14  * 
    15  * .req.client: Manage memory provided by the client.
    16  * 
    17  * .req.client.only: Operate entirely within client-provided memory.
    18  * 
    19  * .req.extend: Allow extension by the client providing additional chunks
    20  *   of memory.
    21  * 
    22  * .req.extend.few: Normal operation will be in one chunk; "a few" 
chunks is
    23  *   unusual; "many" chunks is very unlikely.
    24  * 
    25  * .req.extend.slow: Speed may degrade proportionally to the number of 
    26  *   chunks of memory. 
    27  *
    28  * .req.place: Allow preferential placement of segments.
    29  */
    30 
    31 #include "mpm.h"
    32 
    33 #ifndef TARGET_ARENA_CLIENT
    34 #error "Client arena not configured"
    35 #endif
    36 
    37 SRCID(arenacl, "$HopeName: MMsrc!arenacl.c(MMdevel_sw_eq.1) $");
    38 
    39 Bool ArenaCheck(Arena arena)
    40 {
    41   CHECKS(Arena,arena);
    42   CHECKL(RingCheck(&arena->chunkRing));
    43   /* no possible check on arena->chunkSerial */
    44   CHECKL(arena->pageShift < WORD_WIDTH);
    45   CHECKL(arena->pageSize == 1uL << arena->pageShift);
    46   return TRUE;
    47 }
    48 
    49 typedef struct ChunkStruct *Chunk; /* chunk type */
    50 typedef struct PageStruct *Page; /* page type */
    51 typedef Word *BT;                /* bool table type */
    52 
    53 #define ChunkSig ((Sig)0x519C409c)
    54 
    55 typedef struct ChunkStruct {    /* chunk structure */
    56   Sig sig;                      /* impl.h.misc.sig */
    57   Arena arena;   /* the arena */
    58   RingStruct arenaRing;  /* ring of chunks within the arena */
    59   Serial serial;  /* serial within the arena */
    60   Size pages;                   /* number of pages in chunk */
    61   Addr base;                    /* base address of chunk */
    62   Addr limit;                   /* limit address of chunk */
    63   Addr pageBase;                /* base of first managed page in chunk */
    64   Page pageTable;               /* the page table */
    65   BT freeTable;                 /* page free table */
    66 } ChunkStruct;
    67 
    68 static Bool ChunkCheck(Chunk chunk)
    69 {
    70   CHECKS(Chunk, chunk);
    71   CHECKU(Arena, chunk->arena);
    72   CHECKL(RingCheck(&chunk->arenaRing));
    73   CHECKL(chunk->serial <= chunk->arena->chunkSerial);
    74   CHECKL(chunk->pages >= 0);
    75   /* check base and limit: */
    76   CHECKL(chunk->base != (Addr)0);
    77   CHECKL(chunk->limit != (Addr)0);
    78   CHECKL(chunk->base < chunk->limit);
    79   /* check the control structures are not NULL: */
    80   CHECKL(chunk->pageBase != (Addr)0);
    81   CHECKL(chunk->pageTable != NULL);
    82   CHECKL(chunk->freeTable != NULL);
    83   /* check the control structures are between base and limit */
    84   /* (allowing for the case in which the chunk manages no pages): */
    85   CHECKL((Addr)chunk >= chunk->base);
    86   CHECKL((Addr)chunk < chunk->limit);
    87   CHECKL(chunk->pageBase > chunk->base);
    88   CHECKL(chunk->pageBase <= chunk->limit);
    89   CHECKL((Addr)chunk->pageTable > chunk->base);
    90   CHECKL((Addr)chunk->pageTable <= chunk->limit);
    91   CHECKL((Addr)chunk->freeTable > chunk->base);
    92   CHECKL((Addr)chunk->freeTable <= chunk->limit);
    93   /* check order of control structures within chunk: */
    94   CHECKL((Addr)chunk < (Addr)chunk->pageTable);
    95   CHECKL((Addr)chunk->pageTable <= (Addr)chunk->freeTable);
    96   CHECKL((Addr)chunk->freeTable <= (Addr)chunk->pageBase);
    97   /* check size of control structures within chunk: */
    98   CHECKL(AddrSub((Addr)chunk->pageTable, (Addr)chunk) >= 
sizeof(ChunkStruct));
    99    /* enough space for page table: */
   100   CHECKL(AddrSub((Addr)chunk->freeTable, (Addr)chunk->pageTable) /
   101   sizeof(PageStruct) >= chunk->pages);
   102  /* enough space for free table: */
   103   CHECKL(AddrSub(chunk->pageBase, (Addr)chunk->freeTable) / sizeof(Word) 
>=
   104   SizeAlignUp(chunk->pages,WORD_WIDTH) >> WORD_SHIFT);
   105    /* enough space for pages */
   106   CHECKL((AddrSub(chunk->limit, chunk->pageBase) >> 
chunk->arena->pageShift)
   107   == chunk->pages);
   108   /* .check.tables: could check the consistency of the tables, but not 
O(1) */
   109   return TRUE;
   110 }
   111 
   112 /* PageStruct -- page structure
   113  *
   114  * The page table is lifted entirely from arenavm. See
   115  * design.mps.arenavm.table.* */
   116 
   117 typedef struct PageStruct {     /* page structure */
   118   union {
   119     SegStruct head;             /* segment */
   120     struct {
   121       Pool pool;                /* .page: NULL, must be first field
   122                                  * see impl.h.mpmst.seg.pool */
   123       Seg seg;                  /* segment at base page of run */
   124       Addr limit;               /* limit of segment */
   125     } tail;                     /* tail page */
   126   } the;
   127 } PageStruct;
   128 
   129 /* would like to be able to write a PageCheck, but Pages don't even
   130  * have a signature */
   131 
   132 /* Page Index to Base address mapping
   133  *
   134  * See design.mps.arenavm.table.linear
   135  */
   136 
   137 #define PageBase(chunk, pi) \
   138   AddrAdd((chunk)->pageBase, ((pi) << (chunk)->arena->pageShift))
   139 
   140 /* Index Types
   141  * 
   142  * PI is the type of a value used to index into a page table.
   143  * 
   144  * BI is the type of a value used to index into a bool table (See BTGet
   145  * and BTSet in this module).
   146  */
   147 
   148 typedef Size PI;
   149 typedef Size BI;
   150 
   151 /* BTGet -- get a bool from a bool table
   152  *
   153  * Note: The function version of BTGet isn't used anywhere in
   154  * this source, but is left here in case we want to revert from
   155  * the macro.
   156  */
   157 
   158 #if 0
   159 static Bool (BTGet)(BT bt, BI i)
   160 {
   161   Size wi = i >> WORD_SHIFT;            /* word index */
   162   Size bi = i & (WORD_WIDTH - 1);       /* bit index */
   163   return (bt[wi] >> bi) & 1;
   164 }
   165 #endif /* 0 */
   166 
   167 #define BTGet(bt, i) \
   168   (((bt)[(i)>>WORD_SHIFT] >> ((i)&(WORD_WIDTH-1))) & 1)
   169 
   170 
   171 /* BTSet -- set a bool in a bool table */
   172 
   173 static void BTSet(BT bt, BI i, Bool b)
   174 {
   175   Size bi = i & (WORD_WIDTH - 1);       /* bit index */
   176   Word mask = ~((Word)1 << bi);
   177   Size wi = i >> WORD_SHIFT;            /* word index */
   178   bt[wi] = (bt[wi] & mask) | ((Word)b << bi);
   179 }
   180 
   181 /* Space Arena Projection
   182  * 
   183  * Only the arena module needs to discuss the arena object, hence, this
   184  * method is private to this module.
   185  */
   186 
   187 #define SpaceArena(space)       (&(space)->arenaStruct)
   188 
   189 /* ChunkCreate -- create a chunk */
   190 
   191 static Res ChunkCreate(Chunk *chunkReturn, Addr base, Addr limit, Arena 
arena)
   192 {
   193   Chunk chunk;
   194   Addr a;
   195   Size tablePages;
   196   Size freeTableWords;
   197   PI i;
   198 
   199   AVERT(Arena, arena);
   200   AVER(chunkReturn != NULL);
   201   AVER(base != (Addr)0);
   202   AVER(limit != (Addr)0);
   203   AVER(limit > base);
   204 
   205   /* allocate the chunk */
   206 
   207   a = AddrAlignUp(base,ARCH_ALIGN);
   208   chunk = (Chunk) a;
   209 
   210   /* figure out the sizes and locations of the control structures */
   211   a = AddrAlignUp(AddrAdd(a,sizeof(ChunkStruct)), ARCH_ALIGN);
   212 
   213   if (a > limit) /* the chunk is too small */
   214     return ResRESOURCE;
   215 
   216   tablePages = AddrSub(limit,a) >> arena->pageShift;
   217 
   218   chunk->pageTable = (Page) a;
   219   a = AddrAlignUp(AddrAdd(a,sizeof(PageStruct) * tablePages), 
ARCH_ALIGN);
   220 
   221   chunk->freeTable = (BT) a;
   222   freeTableWords = SizeAlignUp(tablePages, WORD_WIDTH) >> WORD_SHIFT;
   223   a = AddrAlignUp(AddrAdd(a,freeTableWords * sizeof(Word)), ARCH_ALIGN);
   224 
   225   /* the rest is in managed pages; there may be some wastage at the end 
*/
   226   chunk->pageBase = a;
   227 
   228   /* initialize the remaining slots */
   229   chunk->base = base;
   230   chunk->limit = limit;
   231   chunk->pages = AddrSub(chunk->limit, chunk->pageBase) >> 
arena->pageShift;
   232   chunk->arena = arena;
   233 
   234   /* initialize the freeTable */
   235   /* .improve.twiddle.init: Could go a lot faster with bit twiddling */
   236   for(i = 0; i < tablePages; ++i)
   237     BTSet(chunk->freeTable, i, TRUE);
   238 
   239   /* link to the arena */
   240   RingInit(&chunk->arenaRing);
   241   RingAppend(&arena->chunkRing, &chunk->arenaRing);
   242   chunk->serial = arena->chunkSerial;
   243   ++ arena->chunkSerial;
   244 
   245   /* sign it, check it, return it */
   246   chunk->sig = ChunkSig;
   247   AVERT(Chunk, chunk);
   248 
   249   *chunkReturn = chunk;
   250   return ResOK;
   251 }
   252 
   253 /* ArenaCreate -- create the arena
   254  *
   255  * In fact, this creates the space structure and initializes the
   256  * arena part, and makes the first chunk from the memory left over.
   257  */
   258 
   259 Res ArenaCreate(Space *spaceReturn, Size size, Addr base)
   260 {
   261   Space space;
   262   Arena arena;
   263   Addr limit;
   264   Res res;
   265   Chunk chunk;
   266   
   267   AVER(spaceReturn != NULL);
   268   AVER(size > 0);
   269   AVER(base != (Addr)0);
   270 
   271   limit = AddrAdd(base,size);
   272 
   273   /* allocate the space */
   274   base = AddrAlignUp(base,ARCH_ALIGN);
   275   space = (Space) base;
   276   base = AddrAlignUp(AddrAdd(base,sizeof(SpaceStruct)),ARCH_ALIGN);
   277 
   278   arena = SpaceArena(space);
   279   arena->pageSize = ArenaClientPageSize;
   280   arena->pageShift = SizeLog2(arena->pageSize);
   281 
   282   RingInit(&arena->chunkRing);
   283   arena->chunkSerial = (Serial)0;
   284 
   285   /* have to have a valid arena before calling ChunkCreate */
   286   arena->sig = ArenaSig;
   287   
   288   AVERT(Arena, arena);
   289 
   290   res = ChunkCreate(&chunk, base, limit, arena);
   291   if (res)
   292     return res;
   293   
   294   /* Set the zone shift to divide the initial chunk into the same
   295    * number of zones as will fit into a reference set (the number of
   296    * bits in a word). Note that some zones are discontiguous in the
   297    * arena if the size is not a power of 2. */
   298 
   299   space->zoneShift = SizeFloorLog2(size >> WORD_SHIFT);
   300 
   301   *spaceReturn = space;
   302   return ResOK;
   303 }
   304 
   305 /* ArenaDestroy -- finish the arena and destroy the space structure */
   306 
   307 void ArenaDestroy(Space space)
   308 {
   309   Arena arena;
   310   AVERT(Arena, SpaceArena(space));
   311   arena = SpaceArena(space);
   312   arena->sig = SigInvalid;
   313 }
   314 
   315 /* ArenaExtend: this extends the arena */
   316 
   317 res ArenaExtend(Space space, Addr base, Addr limit)
   318 {
   319   Arena arena;
   320   Chunk chunk;
   321   Res res;
   322 
   323   AVERT(Space,space);
   324   AVER(base != (Addr)0);
   325   AVER(limit != (Addr)0);
   326   AVER(limit > base);
   327   
   328   arena = SpaceArena(space);
   329   res = ChunkCreate(&chunk, base, limit, arena);
   330   return res;
   331 }
   332 
   333 /* ArenaRetract returns ResFAIL if there is no such chunk, or if it
   334    exists but is not fully free. */
   335 
   336 res ArenaRetract(Space space, Addr base, Addr limit)
   337 {
   338   Arena arena;
   339   Chunk chunk;
   340   Ring node;
   341   
   342   AVERT(Space, space);
   343   AVER(base != (Addr)0);
   344   AVER(limit != (Addr)0);
   345   AVER(limit > base);
   346 
   347   arena = SpaceArena(space);
   348 
   349   RING_FOR(node, &arena->chunkRing) {
   350     Chunk chunk = RING_ELT(Chunk, arenaRing, node);
   351     AVERT(Chunk, chunk);
   352     if ((chunk->base == base) &&
   353  (chunk->limit == limit)) {
   354       /* check that it's empty */
   355       PI pi;
   356       for (pi = 0; pi < chunk->pages; pi++) {
   357  if (BTGet(chunk->freeTable, pi) != FALSE)
   358    return ResFAIL;
   359       }
   360       return ResOK;
   361     }
   362   }
   363 
   364   return ResFAIL; /* no such chunk */
   365 }
   366 
   367 
   368 /* ArenaReserved -- return the amount of reserved address space
   369  * ArenaCommitted -- return the amount of committed virtual memory
   370  * 
   371  * since this uses real client memory, these two numbers are both the 
same.
   372  */
   373 
   374 Size ArenaReserved(Space space)
   375 {
   376   Arena arena;
   377   Size size;
   378   Ring node;
   379 
   380   AVERT(Arena, SpaceArena(space));
   381 
   382   arena = SpaceArena(space);
   383 
   384   size = 0;
   385   RING_FOR(node, &arena->chunkRing) { /* .req.extend.slow */
   386     Chunk chunk = RING_ELT(Chunk, arenaRing, node);
   387     AVERT(Chunk, chunk);
   388     size += AddrSub(chunk->limit, chunk->base);
   389   }
   390 }
   391 
   392 Size ArenaCommitted(Space space)
   393 {
   394   return ArenaReserved(space);
   395 }
   396 
   397 /* SegCheck -- check the consistency of a segment structure */  
   398 
   399 Bool SegCheck(Seg seg)
   400 {
   401   CHECKU(Pool, seg->pool);
   402   /* .seg.check-little: all other fields can't be checked */
   403   return TRUE;
   404 }
   405 
   406 /* preferences... */
   407 
   408 #define SegPrefSig ((Sig)0x5195e997)
   409 
   410 struct SegPrefStruct { /* segment placement preferences */
   411   Sig sig;  /* impl.h.misc.sig */
   412   Space space;  /* the owning space */
   413   Bool high;  /* high or low */
   414 } SegPrefStruct;
   415 
   416 typedef struct SegPrefStruct *SegPref;
   417 
   418 typedef int SegPrefKind;
   419 
   420 enum {
   421   SegPrefHigh = 0, /* allocate segments downwards from top of chunk */
   422   SegPrefLow  /* allocate segments upwards from bottom of chunk */
   423 };
   424 
   425 Bool SegPrefCheck(SegPref pref)
   426 {
   427   CHECKS(SegPref, pref);
   428   CHECKU(Space, pref->space);
   429   CHECKD(Bool, pref->high);
   430   /* nothing else to check */
   431   return TRUE;
   432 }
   433 
   434 /* SegPrefCreate */
   435 
   436 Res SegPrefCreate (SegPref *prefReturn, Space space)
   437 {
   438   void *p;
   439   Res res;
   440   SegPref pref;
   441 
   442   AVERT(Space, space);
   443   AVER(sp != NULL);
   444 
   445   res = SpaceAlloc(&p, space, sizeof(SegPrefStruct));
   446   if (res)
   447     return res;
   448 
   449   pref = (SegPref)res;
   450 
   451   pref->space = space;
   452   pref->high = FALSE;
   453 
   454   pref->sig = SegPrefSig;
   455   AVERT(SegPref, pref);
   456   *prefReturn = pref;
   457   return ResOK;
   458 }
   459 
   460 void SegPrefDestroy (SegPref sp)
   461 {
   462   Space space;
   463 
   464   AVERT(SegPref, sp);
   465   space = sp->space;
   466 
   467   sp->Sig = SigInvalid;
   468   SpaceFree(space, (void*)sp, sizeof(SegPrefStruct));
   469 }
   470 
   471 Res SegPrefExpress (SegPref sp, SegPrefKind kind, void *p)
   472 {
   473   AVERT(SegPref,sp);
   474   switch(kind) {
   475   case SegPrefHigh:
   476     AVER(p == NULL);
   477     sp->high = TRUE;
   478     return ResOK;
   479   case SegPrefLow:
   480     AVER(p == NULL);
   481     sp->high = FALSE;
   482     return ResOK;
   483   default:
   484     /* see design.mps.pref.default */
   485     return ResOK;
   486   }
   487 }
   488 
   489 /* ChunkSegAlloc: allocate a segment in a chunk */
   490 
   491 static Res ChunkSegAlloc(Seg *segReturn, SegPref pref, Size pages, Pool 
pool,
   492     Chunk chunk)
   493 {
   494   PI pi, count, base;
   495   Seg seg;
   496   Res res;
   497   Arena arena;
   498 
   499   AVER(segReturn != NULL);
   500   AVERT(Chunk, chunk);
   501 
   502   if (chunk->pages == 0)
   503     return ResRESOURCE;
   504   
   505   arena = chunk->arena;
   506 
   507   /* Search for a free run of pages in the free table.
   508    * .improve.bit-twiddle:  This code can probably be seriously
   509    * optimised by twiddling the bit table.
   510    */
   511 
   512   count = 0;
   513 
   514   if (pref->high) {
   515     pi = chunk->pages;
   516     while (pi != 0) {
   517       pi--;
   518       if (BTGet(chunk->freeTable,pi)) {
   519  ++count;
   520  if (count == pages) {
   521    base = pi;
   522    goto found;
   523  }
   524       } else
   525  count = 0;
   526     }
   527   } else {
   528     pi = 0;
   529     while (pi != chunk->pages) {
   530       if(BTGet(chunk->freeTable, pi)) {
   531  if(count == 0)
   532    base = pi;
   533  ++count;
   534  if(count == pages)
   535    goto found;
   536       } else
   537  count = 0;
   538       pi++;
   539     }
   540   }
   541   
   542   /* No space was found.
   543    * .improve.alloc-fail: This could be because the request was
   544    * too large, or perhaps because of fragmentation.  We could return a
   545    * more meaningful code.
   546    */
   547   return ResRESOURCE;
   548 
   549 found:
   550   /* Initialize the generic segment structure. */
   551   seg = &chunk->pageTable[base].the.head;
   552   seg->pool = pool;
   553   seg->p = NULL;
   554   seg->rank = RankEXACT;    /*  exact by default */
   555   seg->condemned = TraceIdNONE;
   556 
   557   seg->pm = AccessSetEMPTY; /* see impl.c.shield */
   558   seg->sm = AccessSetEMPTY;
   559   seg->depth = 0;
   560 
   561   /* Allocate the first page, and, if there is more than one page,
   562    * allocate the rest of the pages and store the multi-page information
   563    * in the page table.
   564    */
   565   AVER(BTGet(chunk->freeTable, base));
   566   BTSet(chunk->freeTable, base, FALSE);
   567   if(pages > 1) {
   568     Addr limit = PageBase(chunk, base + pages);
   569     seg->single = FALSE;
   570     for(pi = base + 1; pi < base + pages; ++pi) {
   571       AVER(BTGet(chunk->freeTable, pi));
   572       BTSet(chunk->freeTable, pi, FALSE);
   573       chunk->pageTable[pi].the.tail.pool = NULL;
   574       chunk->pageTable[pi].the.tail.seg = seg;
   575       chunk->pageTable[pi].the.tail.limit = limit;
   576     }
   577   } else {
   578     seg->single = TRUE;
   579   }
   580   
   581   AVERT(Seg, seg);
   582 
   583   *segReturn = seg;
   584   return ResOK;
   585 }
   586 
   587 
   588 /* SegAlloc -- allocate a segment from the arena */
   589 
   590 Res SegAlloc(Seg *segReturn, SegPref pref, Space space, Size size, Pool 
pool)
   591 {
   592   Arena arena;
   593   Res res;
   594   Ring node;
   595   Size pages;
   596 
   597   AVER(segReturn != NULL);
   598   AVERT(SegPref, pref);
   599   AVER(size > 0);
   600   AVERT(Pool, pool);
   601   
   602   /* NULL is used as a discriminator (see
   603    * design.mps.arenavm.table.disc), therefore the real pool must be
   604    * non-NULL.
   605    */
   606   AVER(pool != NULL);
   607 
   608   arena = SpaceArena(space);
   609 
   610   AVERT(Arena, arena);
   611   AVER(SizeIsAligned(size, arena->pageSize));
   612 
   613   pages = size >> arena->pageShift;
   614 
   615   RING_FOR(node, &arena->chunkRing) { /* .req.extend.slow */
   616     Chunk chunk = RING_ELT(Chunk, arenaRing, node);
   617     res = ChunkSegAlloc(segReturn, pref, pages, pool, chunk);
   618     if (res == ResOK)
   619       return res;
   620   }
   621   return ResRESOURCE;
   622 }
   623 
   624 /* SegChunk: identify the chunk (and index) in which a segment resides */
   625 
   626 static Res SegChunk(chunk *chunkReturn, PI *piReturn, Seg seg, Arena 
arena)
   627 {
   628   Page page;
   629   Ring node;
   630   
   631   AVER(chunkReturn != NULL);
   632   AVERT(Seg, seg);
   633   AVERT(Arena, arena);
   634 
   635   page = PARENT(PageStruct, the.head, seg);
   636 
   637   RING_FOR(node, arena->chunkRing) {
   638     Chunk chunk = RING_ELT(Chunk, arenaRing, node);
   639     if ((page >= chunk->pageTable) &&
   640  (page < (chunk->pageTable + chunk->pages))) {
   641       *piReturn = page - chunk->pageTable;
   642       *chunkReturn = chunk;
   643       return ResOK;
   644     }
   645   }
   646   return ResFAIL;
   647 }
   648 
   649 
   650 /* SegFree - free a segment in the arena */
   651 
   652 void SegFree(Space space, Seg seg)
   653 {
   654   Arena arena;
   655   Chunk chunk;
   656   Page page;
   657   PI pi, pl, pn;
   658   Addr base, limit; 
   659   Res res;
   660 
   661   AVERT(Seg, seg);
   662 
   663   arena = SpaceArena(space);
   664   AVERT(Arena, arena);
   665 
   666   res = SegChunk(&chunk, &pi, seg, arena);
   667   AVER(res == ResOK);
   668 
   669   limit = SegLimit(space, seg);
   670 
   671   /* Remember the base address of the segment so it can be */
   672   /* unmapped .free.unmap */
   673   base = PageBase(chunk, pi);
   674 
   675   /* Calculate the number of pages in the segment, and hence the
   676    * limit for .free.loop */
   677   pn = AddrOffset(base, limit) >> arena->pageShift;
   678   pl = pi + pn;
   679   /* .free.loop: */
   680   for( ; pi < pl; ++pi) {
   681     AVER(BTGet(chunk->freeTable, pi) == FALSE);
   682     BTSet(chunk->freeTable, pi, TRUE);
   683   }
   684 
   685   /* Double check that .free.loop takes us to the limit page of the
   686    * segment.
   687    */
   688   AVER(PageBase(chunk, pi) == limit);
   689 }
   690 
   691 
   692 /* ArenaAlign -- return the alignment of segments */
   693 
   694 Align ArenaAlign(Space space)
   695 {
   696   Arena arena;
   697   AVERT(Arena, SpaceArena(space));
   698   arena = SpaceArena(space);
   699   return arena->pageSize;
   700 }
   701 
   702 
   703 /* SegBase -- return the base address of a segment
   704  *
   705  * The segment base is calculated by identifying the chunk and page
   706  * index, then multiplying that by the page size and adding it to
   707  * the chunk base address. */
   708 
   709 Addr SegBase(Space space, Seg seg)
   710 {
   711   Arena arena;
   712   PI pi;
   713   Chunk chunk;
   714   Res res;
   715   
   716   AVERT(Seg, seg);
   717 
   718   arena = SpaceArena(space);
   719   AVERT(Arena, arena);
   720 
   721   res = SegChunk(&chunk, &pi, seg, arena);
   722   AVER(res == ResOK);
   723 
   724   return PageBase(chunk, pi);
   725 }
   726 
   727 
   728 /* SegLimit -- return the limit address (end+1) of a segment
   729  *
   730  * If the segment is a single page, then the limit is just
   731  * the next page, otherwise it is stored on the next page
   732  * table entry.
   733  */
   734 
   735 Addr SegLimit(Space space, Seg seg)
   736 {
   737   Arena arena;
   738 
   739   AVERT(Seg, seg);
   740 
   741   arena = SpaceArena(space);
   742   AVERT(Arena, arena);
   743 
   744   if(seg->single)
   745     return AddrAdd(SegBase(space, seg), arena->pageSize);
   746   else {
   747     page = PARENT(PageStruct, the.head, seg);
   748     return page[1].the.tail.limit;
   749   }
   750 }
   751 
   752 
   753 /* SegSize -- return the size (limit - base) of a segment
   754  *
   755  * .improve.redundant-calc: There is scope for optimizing this,
   756  * because both base and limit calls do roughly the same thing twice.
   757  */
   758 
   759 Size SegSize(Space space, Seg seg)
   760 {
   761   AVERT(Arena, SpaceArena(space));
   762   AVERT(Seg, seg);
   763   return AddrOffset(SegBase(space, seg), SegLimit(space, seg));
   764 }
   765 
   766 
   767 /* SegOfAddr -- return the segment which encloses an address
   768  *
   769  * If the address is within the bounds of the arena, calculate the
   770  * page table index from the address and see if the page is allocated.
   771  * If it is a head page, return the segment, otherwise follow the
   772  * tail's pointer back to the segment in the head page.
   773  */
   774 
   775 Bool SegOfAddr(Seg *segReturn, Space space, Addr addr)
   776 {
   777   Arena arena;
   778   Ring node;
   779   
   780   AVER(segReturn != NULL);
   781   
   782   arena = SpaceArena(space);
   783   AVERT(Arena, arena);
   784 
   785   RING_FOR(node, &arena-chunkRing) {
   786     Chunk chunk = RING_ELT(Chunk, arenaRing, node);
   787     if(chunk->base <= addr && addr < chunk->limit) {
   788       PI pi = AddrOffset(chunk->pageBase, addr) >> arena->pageShift;
   789       if(!BTGet(chunk->freeTable, pi)) {
   790  Page page = &chunk->pageTable[pi];
   791  if(page->the.head.pool != NULL)
   792    *segReturn = &page->the.head;
   793  else
   794    *segReturn = page->the.tail.seg;
   795  return TRUE;
   796       }
   797     }
   798   }
   799   
   800   return FALSE;
   801 }
   802 
   803 
   804 /* SegSearchChunk -- search for a segment in a given chunk
   805  *
   806  * Searches for a segment in the chunk starting at page index pi,
   807  * return NULL if there is none.  A segment is present if it is
   808  * not free, and its pool is not NULL.
   809  *
   810  * This function is private to this module and is used in the segment
   811  * iteration protocol (SegFirst and SegNext).
   812  */
   813 static Seg SegSearchChunk(Chunk chunk, PI pi)
   814 {
   815   AVERT(Chunk, chunk);
   816   AVER(pi <= chunk->pages);
   817 
   818   while(pi < chunk->pages &&
   819         (BTGet(chunk->freeTable, pi) ||
   820          chunk->pageTable[pi].the.head.pool == NULL))
   821     ++pi;
   822   
   823   if(pi < chunk->pages)
   824     return &chunk->pageTable[pi].the.head;
   825   
   826   AVER(pi == chunk->pages);
   827   return NULL;
   828 }
   829 
   830 
   831 /* SegFirst -- return the first segment in the arena
   832  *
   833  * This is used to start an iteration over all segments in the arena.
   834  */
   835 
   836 Seg SegFirst(Space space)
   837 {
   838   Arena arena;
   839   Chunk chunk;
   840   Ring node;
   841 
   842   arena = SpaceArena(space);
   843   AVERT(Arena, arena);
   844 
   845   /* must do the right thing for chunks with no pages */
   846   RING_FOR(node, &arena->chunkRing) {
   847     Chunk chunk = RING_ELT(Chunk, arenaRing, node);
   848     Seg seg = SegSearchChunk(chunk, 0);
   849     if (seg != NULL)
   850       return seg;
   851   }
   852 
   853   return NULL;
   854 }
   855 
   856 
   857 /* SegNext -- return the next segment in the arena
   858  *
   859  * This is used as the iteration step when iterating over all
   860  * segments in the arena.
   861  */
   862 
   863 Seg SegNext(Space space, Seg seg)
   864 {
   865   Arena arena;
   866   Chunk chunk;
   867   Page page;
   868   PI pi;
   869   Res res;
   870   Seg next;
   871 
   872   AVERT(Space, space);
   873   AVERT(Seg, seg);
   874 
   875   AVERT(Arena, SpaceArena(space));
   876   arena = SpaceArena(space);
   877 
   878   res = SegChunk(&chunk, &pi, seg, arena);
   879   AVER(res == ResOK);
   880 
   881   next = SegSearchChunk(chunk, pi+1);
   882 
   883   while (next == NULL) { /* then we've reached the end of the chunk */
   884     Ring node = &chunk->arenaRing;
   885     node = node->next;
   886     if (node == &arena->chunkRing)
   887       return NULL;
   888     chunk = RING_ELT(Chunk, arenaRing, node);
   889     next = SegSearchChunk(chunk,0);
   890   }
   891   return next;
   892 }

