             NOTES FROM MM DEVELOPMENT AND PRODUCT MEETING
                        meeting.devel.1999-04-20
                             incomplete doc
                            tony 1999-04-21

Telecon: Andy Sizer <andys>, Dave Berry <daveb>, Pekka Pirinen <pekka>,
Richard Tucker <rit>, Tony Mann <tony>

David Jones <drj> was ill.


NEWS

tony: Since our meeting with Martin last week, there's been some discussion
within the group about how we would implement a save-image mechanism.
We're awaiting information on when/if this is likely to be needed, before
we commit any resources.

tony: Andy sent out a more detailed proposal about the stack-maps for
Dylan. Much the same situation here: we know most of the implications for
MPS. Some detailed design and implementation work to do, but we don't know
the time-scale yet.

tony: There's been a bit more discussion with ASG.


RELEASES

+ release.web.diadem

tony: Candidate sampler CDs have been made, and gone to QA. Presumably
these don't have the fixed links for the work Pekka did last week.

pekka: ... the missing links to the bibliography? no they don't.

daveb: It looks like there may be one of two changes to documentation files
in the sampler CD, so if we have a new version of the MM References, as
long as it doesn't include any more files, we could put it in. Need to
consider what the risks and benefits are.

pekka: Benefits probably not that great -- it's just a few bibliography
links missing. Equally the risks are small. Also, there probably hasn't
been any QA work on it other than what we've done.

pekka: Running off a new version takes 20 minutes or less. That's not very
hard.

tony: So if it's not going to be a problem from the manufacturing point of
view, it's probably worth it.

pekka: Yes... well, we'll see.

tony: Who should we tell?

pekka: Well, they are telling me about how QA is going. But Gary is away.

daveb: I think it should best go to Jo Blishen. I'll mention it at the
quartet meeitng this afternoon.


+ release.java.amaretto

tony: drj's not here, but I do know that he didn't make a lot of progress
last week. Don't know why. We need to talk to him and find out if it's
turning out to be a harder task than at first we thought.


+ release.dylan.kinglet

tony: The sunset-on-segments work is ready for approval from drj, when he
has time to do it.

tony: Pekka's been working on the telemetry reading tool...

pekka: Yes. I'm having to do binary structure reading manually -- the old
code was all wrong, so unfortunately I have to rewrite it.


+ Dr Dobbs

tony: I had some feedback from Tim Kientzel, the editor, after I sent him
the outline. He seemed to be quite enthusiastic. Hopefully he will still be
enthusiastic when he sees the text! -- it was probably a bit hard to work
out what everything was from the outline. He sounded as though he would be
prepared to relax the word limit if that would help. I'm starting to write
it now.


+ Make system

pekka: We've had some problems with our make system for a long time (there
are several requests about it). Just recently I found a new problem: we
can't use any of the stuff that people have put in the HQNc-standard
compound. This is mostly the fault of the people who wrote the stuff. The
problem is basically how to make it. A radical solution is to move from
using gmake and nmake and whatever on the Mac to a tool called Jam, which
is a portable replacement. We have some papers on the construction and use
thereof. They have a web-site. It's open-source and portable, and available
on all our current platforms (but see later). And SW has decided to use it.
EP2000 is also converting over. So I think it's a pretty good alternative.
Obviously converting all our makefiles over is going to take some time: I
estimate 2 weeks.

daveb: What are the current problems?

pekka: One is that we have three different systems. When you add a file,
you have to change three files. Also, some things are hard in nmake, and we
don't even try to do everything on the Mac.

daveb: gnumake for windows?

pekka: Yes, we looked at that. Two things: (1) sysadmins aren't supporting
it, though ML were using it; (2) it doesn't help on the Mac, and doesn't
help with the problem I was having reusing the supposedly public code. I
must admit I'm not _sure_ I can do that anyway, as it's not being
maintained. But Jam is a solution as when they rewrote the SW make system
they separated all the generic (e.g. platform and compiler settings) from
the SW-specific stuff. We hope that the generic stuff is reusable for us.

rit: So would we discard our current system of naming platforms, and adopt
one that SW uses?

pekka: Not necessarily. We could use their stuff for determining the
platform, as an internal switch in the makefiles, and then establish a
translation into our platform codes. I'm not sure it's worth the effort, as
you'd probably have to know both codes anyway.

tony: We also have the opportunity to remove the problem that different
targets use the same build directory even though they build in different
ways.

pekka: Jam is more like a programming language than make.

pekka: It works on a Mac, but the public version was ported to use
Metroworks CodeWarrior, whereas we and SW use MPW. Peter Glasscock is
working on a port to make it use MPW.

tony: Is that another build, or just new rules?

pekka: I don't know -- it may be necessary to rebuild something that
invokes the compiler. He says it will be finished in another month.

daveb: So, advantages: Unify current make files,

tony: ... easier to use Harlequin's reusable code.

daveb: How urgent is this?

pekka: Good question. (1) Some things we only build on Unix, and some
things we only build on Unix and PC, because we haven't done all the make
files. Basically some tests and some varieties which we don't deliver to
anybody at the moment. So not very urgent. (2) Reusing. I understand that
Richard Brooksby looked at reusing some years ago, and concludeed it wasn't
feasible. Not just lack of documentation or anybody responsible for the
code, but that you end up being dependent on code that you can't change.
It's not truly reusable unless you have a policy of how to change it, or
what you do if it's buggy.

rit: You could reuse it by copying it.

tony: But then you lose the benefit of maintenance by other people.

pekka: HQNc-standard contains lots of clever macros, which we don't really
need ('cos we wrote what we needed for ourselves). Also some string
handling routines. What I happen to need right now is hash tables, which
isn't in C-standard. There is a thing called the Framework which the SW GUI
people factored out of their code. It doesn't make the claim that any
Harlequin c-developer should be able to use it (which claim _is_ made for
HQNc-standard). So I'm slightly unwilling to use it, but equally unwilling
to hack up another hash-table implementation just becuase I need it for a
dictionary.

pekka: Jam would definitely help because the code has platform-switches to
do various tweaks. With the same make system, you'd get that working for
free. But what I'm saying is there may be other problems in reusing the
code.

andys: Lack of contract between writer and people who might use it.

tony: So, two issues. (1) Need hash-table code. (2) Use JAM?

daveb: Are sysadmins going to support JAM?

pekka: I think the fact that SWIG are using it is enough for our purposes,
as that covers almost all of our platforms already.

daveb: Ok. It sounds to me like it's probably better to copy an
implementation of hash tables rather than reuse it at this point. JAM
sounds like a good idea, but may not be that urgent.

tony: If we were going to take on a new client like LW, or anything major
like that, we might do well to move to JAM before that.

pekka: Right now there are also smaller issues like: lack of automatic runs
of (internal) tests on PC.

daveb: Yes, sounds like it's a good idea, but not right now.

tony: Well, I can add a task to the schedule, and see what dependencies
there might be (e.g. with tasks to clean up varieties). They're beyond the
immediate set of releases that we're looking at right now.

daveb: Ok. The broader question is code-reuse in Harlequin, which maybe I
should take up with John and Keith.

andys: One which has always bitten in the past has been the license server.
That is a substantial piece of code which receives no support, and yet is
subject to arbitrary changes.

daveb: EP2000 are doing some work on it...

andys: ... in recognition that other people are using it?

daveb: Yes. They're porting it to NT.

andys: What I mean is: The license server is a good example of code reuse
in the company. It demonstrates that reuse isn't a new problem, but one
which already exists.


+ Future products

daveb: I wanted to refresh my memory of where we are vis-a-vis external
products. As I understand it, we have two approaches: (1) JVM -- working
towards an initial version, not handling weakness, no emphasis yet on
performance or flexibility. (2) Drop-in replacements for malloc and free,
but we haven't really been working on that. Plan to have various levels of
use.

pekka: Yes. Plan for configuration tool that you could use to speed up your
malloc and frees. Then you could move on to using pools &c. It's a lot of
work, though. Each platform is going to have a number of non-standard
interfaces details for drop-in malloc.

pekka: Automatic (GC) tools for drop-in malloc is also a large piece of work 
that be haven't done, although we have most of the technology.

daveb: Diagnostic tools? What plans, and where at?

tony: Two lines of approach. (1) Telemetry. (2) Tools to look at heap while
live. Collaborative work with Dylan on the latter, but not much has
happened in the last six months.

pekka: Telemetry can be relatively real-time as well, if we don't use a
disc file.

tony: But telemetry is a very large amount of data. It could be quite slow.

pekka: So use telemetry filtering.

pekka: I think we're miles away from having diagnostic tools. We have
instrumentation in the code (telemetry and other), but we don't really have
a single line for any of the tools. Sheep wrote some things, but most of
that is dead, because nobody knows what he wrote or how it works.

andys: By diagnosis, do you include debugging?

tony: Yes. Anything from "why is my heap 100MB?" to "why is my program not
working?"

andys: Do we intend to compete with e.g. Purify?

pekka: No, but we want to interoperate with it. Product plan took the view
that we don't want to compete with it, as our strengths are elsewhere (in
garbage collection). Great Circle, on the other hand, we want to compete
with (that's a debugging tool as well as a MM package).

daveb: So what sort of debugging tools might we provide (if not like Purify)?

pekka: Hard question.

andys: Don't Great Circle get their debugging out of replacing malloc/free
with a garbage collector?

pekka: Yes. Some problems found this way can be fixed in code, and then
client need not use GC in release version. Some problems you can't solve
this way (e.g. leaks in 3rd party libraries), and then you have to include
GC in release.

pekka: I think we'd have a similar approach. Debugging tools largely a
by-product of our other technologies. We wouldn't write something that was
specifically aimed at debugging (like Purify). We don't want to start
modifying executables, etc.

andys: Seems to me Great Circle are competing with Purify. Need to fit in
with Purify, don't you? What does it mean to be complementary? If
somebody's already got Purify, and they want to use both it and our stuff,
how does that work?

pekka: We had a preliminary look at this. Purify is configurable: you can
tell it what your allocation and freeing functions are, and it can then
track allocations in MPS.

rit: Does it work without replacing the allocator by its own?

pekka: Yes.

andys: But it does things like not immediately freeing things, etc.

andys: What does "complementary" mean?

rit: E.g. does it mean you should be able to take program that uses the
MPS, and run it with Purify?

pekka: Yes.

andys: And if it turns out that can't be done without having a technical
relationship with Rational, what do we do?

daveb: ... Well, we don't even know if we're going to follow the plan at
the moment.


daveb: Another area: Real-time GC.

tony: Current technology in MPS: well-suited to incremental GC, but not to
real-time GC. Would be a major redesign to put real-time GC into framework.

tony: E.g. optimisations based on zones and segments are large-scale
incremental, not so good at small units of work.

andys: Does code do explicit accounting of the time it thinks it's taking?

tony: No. But even if it did, you wouldn't be able to get your bounds down
that small with the framework as it stands. Things like the units of
condemnation (zones) and the coarse granularity of the entry tables, are
not particularly suited to real-time GC.

pekka: Real-time requires that you think about the cost of everything, and
we haven't written the code like that.

andys: You'd have to change the nature of the way you write code.

daveb: Ok, I think that's all I need to know.



PLAN

tony: There is a new version available. Updates are quite minor, and
reflect only input about what was done last week.

daveb: Lisp; exact scanning; Dylan linux port.

tony: Dylan Linux port is in the plan.

andys: Is it largely a NOP for MM?

tony: No, because we have to write some code. We need the VM arena (which
EP also need), and the protection stuff (which EP don't).

tony: At present, the task for "finish support for Linux" is scheduled for
December 1999! Probably will have to be sooner for that, and indeed can be
scheduled sooner if needed.

tony: We could also add tasks for Lisp and exact scanning, but it may be a
bit early for that. In both cases, there's some design work to be done, but
we are probably in a position to quantify that now.

daveb: For Dylan, Linux port is more important than performance
improvements such as stack-scanning.

tony: Actually for stack-scanning, MPS work is really quite small. Most of
the work is for Dylan.

andys: And it's probably feasible to work out now how much work it is for
Dylan. It's probably less time to implement what we've described than we've
taken so far to describe it. Would be a good idea to write a plan.

daveb: Yes. Summary of benefits?

andys: 2.5% increase in code size. Stack scanning shouldn't be
significantly slower. GC might speed up because less would be kept alive.

andys: Real big unknown is what it actually does to the size of the heap.

daveb: Figure of 10% was mentioned?

andys: That's from some other work, using a JVM. And I don't know if they
were comparing exact but not precise with exact and precise (i.e. using
liveness analysis). So the start point is different from where we are.

tony: Also, temporary storage on the stack is done very differently by the
Dylan compiler and the JVM. I'd expect therefore to see less of an
advantage with Dylan than with Java.

tony: Potentially 2 benefits: (1) less conservative (2) better use of fact
that we have mostly-copying collector.

daveb: Ok, let's produce a plan for that (including the Dylan side) and see
how long it would take.



daveb: LispWorks MPS port. I've looked at the plan.

andys: ... which is very preliminary. It's just a shopping-list of tasks,
with rough estimates. I wouldn't want to defend it too strongly. What's
your first impression? More work than you anticipated? Total time is about
9 months.

daveb: No. Well, maybe Lisp side of MPS work is slightly more than I
anticipated, but overall time is slightly less than I anticipated.

andys: I used the optimistic estimates of the multi-processor work. There's
considerable scope for some parallelism though.

daveb: Why is it all only about LispWorks for Windows?

andys: Mainly because it simplifies the task. On unix you have to worry
about different process models. Lots of strategic issues and implementation
questions, and many platforms.

daveb: Is there no standard approach to multiprocessing on Unix?

andys: No, and not even on each platform either.

andys: Also because it's useful even on single processor machine (because
native threads are easily available on Windows) hence benefit for whole
product.

daveb: Roughly how much effort would it be to go from the end of this plan
to supporting multithreading on linux or solaris?

andys: It depends what that would mean. On linux there's about 3 or 4
different threading models. There's 2 different (incompatible) ones on SGI.
You could e.g. decide to support only Posix threads, but that might not be
useful if the rest of the world isn't using them.

andys: But, off the top of my head, it's probably no less than 3 months,
and nearer 6. I think that's a pretty meaningless figure, but it's of the
right order.

tony: Presumably extra work for the first unix platform we do.

andys: One other big gotcha on Unix, which is motif and things. Unless we
lock motif (i.e. global lock on all calls to motif), it's not multithreaded.



WORK PRACTICES


tony: Story last week was: nothing was ready to review. Plan was to review
design.mps.bt (bit tables) this week, and drj would spend some time last
week updating it getting it ready to be reviewed. I know he's made some
changes to the document; I'm not sure whether it's quite ready. So we'll
hopefully have a review tomorrow. We could alternatively consider holding
it on Thursday.

pekka: Where do we stand on ranking the requests?

tony: Weren't we going to get some feedback...?

daveb: I wanted to leave it to see how Dylan group got on with the
questionnaire. They seem to be getting on quite well.

andys: How does ranking fit in with the scheduling tools?

tony: It doesn't -- the link is manual -- but it's useful data for making
scheduling decisions. In the scheduling I've got priorities, but so far
they've been chosen by hand and intuition, and we haven't necessarily been
able to think about everything in the databse and see if it needs adding.
Hopefully we can come up with a procedure for that.

tony: At the moment, scheduling is based on prioritising for releases.
Hopefully there's a reasonable correspondance between the schedule and the
database in terms of when release happen and what's in them.

andys: When schedule gets tweaked, you'll need to adjust ranking in
database too. Is there a manual override?

pekka, rit: yes.


Meeting time: about 74 minutes.


