                            LEAF POOL CLASS
                               impl.c.lo
                               draft doc
                           gavinm 1997-06-18

     1 /* impl.c.lo: LEAF POOL CLASS
     2  *
     3  * $HopeName: MMsrc!lo.c(trunk.29) $
     4  * Copyright (C) 1997 The Harlequin Group Limited.  All rights reserved.
     5  *
     6  * READERSHIP
     7  *
     8  * .readership: Any MPS developer
     9  *
    10  * DESIGN
    11  *
    12  * .design: see design.mps.poollo
    13  *
    14  * This is the implementation of the leaf pool class.
    15  */
    16 
    17 
    18 #include "mpm.h"
    19 #include "lo.h"
    20 #include "mps.h"
    21 #include "mpsclo.h"
    22 
    23 
    24 SRCID(lo, "$HopeName: MMsrc!lo.c(trunk.29) $");
    25 
    26 
    27 /* LOStruct -- leaf object pool instance structure */
    28 
    29 #define LOSig           ((Sig)0x51970B07) /* SIGnature LO POoL */
    30 
    31 typedef struct LOStruct {
    32   PoolStruct poolStruct;        /* generic pool structure */
    33   RingStruct groupRing;         /* ring of groups */
    34   Format format;                /* format for allocated objects */
    35   Shift alignShift;             /* log_2 of pool alignment */
    36   Sig sig;                      /* impl.h.misc.sig */
    37 } LOStruct;
    38 
    39 
    40 /* LOGroupStruct -- group structure */
    41 
    42 typedef struct LOGroupStruct *LOGroup;
    43 
    44 #define LOGroupSig      ((Sig)0x51970960) /* SIGnature LO GROup */
    45 
    46 typedef struct LOGroupStruct {
    47   Sig sig;                      /* impl.h.misc.sig */
    48   LO lo;                        /* owning LO */
    49   RingStruct loRing;            /* attachment to the LO structure */
    50   BT mark;                      /* mark bit table */
    51   BT alloc;                     /* alloc bit table */
    52   Seg seg;                      /* segment containing objects */
    53 } LOGroupStruct;
    54 
    55 
    56 /*  MACROS  */
    57 
    58 #define PoolPoolLO(pool)        PARENT(LOStruct, poolStruct, pool)
    59 
    60 #define loGroupBuffer(group)    ((group)->seg->buffer)
    61 
    62 
    63 static Bool LOCheck(LO lo);
    64 
    65 
    66 static Pool (LOPool)(LO lo)
    67 {
    68   AVERT(LO, lo);
    69   return &lo->poolStruct;
    70 }
    71 
    72 
    73 static Bool LOGroupCheck(LOGroup group)
    74 {
    75   CHECKS(LOGroup, group);
    76   CHECKU(LO, group->lo);
    77   CHECKL(RingCheck(&group->loRing));
    78   CHECKL(group->mark != NULL);
    79   CHECKL(group->alloc != NULL);
    80   CHECKL(SegCheck(group->seg));
    81   /* Check that the bit-table is of the right size */
    82   /* Depends on the mark and alloc tables being allocated */
    83   /* together as one block.  See .group.init.tables */
    84   CHECKL(BTSize(SegSize(PoolSpace(LOPool(group->lo)), group->seg) >>
    85                 group->lo->alignShift) ==
    86          AddrOffset((Addr)group->mark, (Addr)group->alloc));
    87   return TRUE;
    88 }
    89 
    90 
    91 /* Attempt to allocate free block of size size in the group.
    92  * Return pointer to base and limit of block (which may be
    93  * bigger than the requested size to accommodate buffering).
    94  */
    95 static Bool loGroupAlloc(Addr *bReturn, Addr *lReturn,
    96                          LOGroup group, Size size)
    97 {
    98   Index i, j;
    99   LO lo;
   100   Space space;
   101   Count agrains;
   102   unsigned long tablesize;
   103 
   104   AVER(bReturn != NULL);
   105   AVER(lReturn != NULL);
   106   AVERT(LOGroup, group);
   107   lo = group->lo;
   108   AVER(SizeIsAligned(size, LOPool(lo)->alignment));
   109   space = PoolSpace(LOPool(lo));
   110 
   111   /* agrains is the number of grains corresponding to the size */
   112   /* of the allocation request */
   113   agrains = size >> lo->alignShift;
   114   AVER(agrains >= 1);
   115 
   116   if(loGroupBuffer(group) != NULL) {
   117     /* Don't bother trying to allocate from a buffered group */
   118     return FALSE;
   119   }
   120   if(SegSize(space, group->seg) < size) {
   121     /* Segment not large enough */
   122     return FALSE;
   123   }
   124 
   125   tablesize = SegSize(space, group->seg) >> lo->alignShift;
   126   if(!BTFindResRange(&i, &j, group->alloc, tablesize, agrains)) {
   127     return FALSE;
   128   }
   129 
   130   /* check that BTFindResRange really did find enough space */
   131   AVER((j-i) << lo->alignShift >= size);
   132   *bReturn = AddrAdd(SegBase(space, group->seg), i << lo->alignShift);
   133   *lReturn = AddrAdd(SegBase(space, group->seg), j << lo->alignShift);
   134 
   135   return TRUE;
   136 }
   137 
   138 
   139 /* Creates a group of size at least size.
   140  * Groups will be ArenaAlign aligned */
   141 static Res loGroupCreate(LOGroup *groupReturn, Pool pool, Size size)
   142 {
   143   BT tables;
   144   LO lo;
   145   LOGroup group;
   146   Res res;
   147   Seg seg;
   148   Size asize;           /* aligned size */
   149   Size tablebytes;      /* # bytes in each control array */
   150   Space space;
   151   unsigned long bits;   /* number of bits needed in each control array */
   152   void *p;
   153 
   154   AVER(groupReturn != NULL);
   155   AVERT(Pool, pool);
   156   AVER(size > 0);
   157 
   158   lo = PARENT(LOStruct, poolStruct, pool);
   159   AVERT(LO, lo);
   160 
   161   space = PoolSpace(pool);
   162 
   163   asize = SizeAlignUp(size, ArenaAlign(space));
   164   
   165   res = SpaceAlloc(&p, space, (Size)sizeof(LOGroupStruct));
   166   if(res != ResOK)
   167     goto failGroup;
   168   group = (LOGroup)p;
   169 
   170   res = PoolSegAlloc(&seg, SegPrefDefault(), pool, asize);
   171   if(res != ResOK)
   172     goto failSeg;
   173 
   174   group->seg = seg;
   175   seg->p = (void *)group;
   176 
   177   /* .group.init.tables: Space for the mark and alloc bit tables */
   178   /* is allocated together as one block.  This makes the error */
   179   /* handling simpler. */
   180   bits = asize >> lo->alignShift;
   181   tablebytes = BTSize(bits);
   182   res = SpaceAlloc(&p, space, tablebytes*2);
   183   if(res != ResOK)
   184     goto failTables;
   185   tables = (BT)p;
   186 
   187   group->mark = tables;
   188   group->alloc = (BT)AddrAdd((Addr)tables, tablebytes);
   189   BTResRange(group->mark, 0, bits);
   190   BTResRange(group->alloc, 0, bits);
   191 
   192   AVER(seg->white == TraceSetEMPTY);
   193 
   194   group->lo = lo;
   195   RingInit(&group->loRing);
   196   RingAppend(&lo->groupRing, &group->loRing);
   197 
   198   group->sig = LOGroupSig;
   199 
   200   AVERT(LOGroup, group);
   201 
   202   *groupReturn = group;
   203   return ResOK;
   204 
   205 failTables:
   206   PoolSegFree(pool, seg);
   207 failSeg:
   208   SpaceFree(space, (Addr)group, (Size)sizeof(LOGroupStruct));
   209 failGroup:
   210   return res;
   211 }
   212 
   213 
   214 static void loGroupDestroy(LOGroup group)
   215 {
   216   LO lo;
   217   Size tablesize;
   218   Space space;
   219   unsigned long bits;
   220 
   221   AVERT(LOGroup, group);
   222 
   223   lo = group->lo;
   224   space = PoolSpace(LOPool(lo));
   225 
   226   bits = SegSize(space, group->seg) >> lo->alignShift;
   227   tablesize = BTSize(bits);
   228 
   229   PoolSegFree(LOPool(lo), group->seg);
   230   /* Both bit table are freed together, see .group.init.tables */
   231   SpaceFree(space, (Addr)group->mark, tablesize*2);
   232   RingRemove(&group->loRing);
   233   SpaceFree(space, (Addr)group, (Size)sizeof(LOGroupStruct));
   234 }
   235 
   236 
   237 static void loGroupReclaim(LOGroup group, Trace trace)
   238 {
   239   Addr base;
   240   Bool marked;
   241   LO lo;
   242   Space space;
   243   Index i, limit;
   244 
   245   AVERT(LOGroup, group);
   246   AVERT(Trace, trace);
   247 
   248   lo = group->lo;
   249   space = PoolSpace(LOPool(lo));
   250   base = SegBase(space, group->seg);
   251   limit = SegSize(space, group->seg) >> lo->alignShift;
   252   marked = FALSE;
   253 
   254   /* i is the index of the current pointer,
   255    * p is the actual address that is being considered.
   256    * j and q act similarly for a pointer which is used to
   257    * point at the end of the current object.
   258    */
   259   i = 0;
   260   while(i < limit) {
   261     Addr p = AddrAdd(base, i << lo->alignShift);
   262     Buffer buffer = loGroupBuffer(group);
   263     Addr q;
   264     Word j;
   265 
   266     if(buffer != NULL) {
   267       if(p == BufferGetInit(buffer)) {
   268         /* skip over buffered area (from init to limit) */
   269         marked = TRUE;
   270         p = BufferLimit(buffer);
   271         i = AddrOffset(base, p) >> lo->alignShift;
   272         continue;
   273       }
   274       /* since we skip over the buffered area we are always */
   275       /* either before the buffer, or after it, never in it */
   276       AVER(p < BufferGetInit(buffer) || BufferLimit(buffer) <= p);
   277     }
   278     if(!BTGet(group->alloc, i)) {
   279       /* This grain is free */
   280       ++i;
   281       continue;
   282     }
   283     q = (*lo->format->skip)(p);
   284     j = AddrOffset(base, q) >> lo->alignShift;
   285     AVER(i < j);
   286     if(BTGet(group->mark, i)) {
   287       marked = TRUE;
   288     } else {
   289       /* This object is not marked, so free it */
   290       BTResRange(group->alloc, i, j);
   291     }
   292     i = j;
   293   }
   294 
   295   group->seg->white = TraceSetDel(group->seg->white, trace->ti);
   296 
   297   if(!marked) {
   298     loGroupDestroy(group);
   299   }
   300 }
   301 
   302 
   303 static Res LOInit(Pool pool, va_list arg)
   304 {
   305   Format format;
   306   LO lo;
   307   Space space;
   308   
   309   AVER(pool != NULL);
   310 
   311   space = PoolSpace(pool);
   312 
   313   format = va_arg(arg, Format);
   314   AVERT(Format, format);
   315   
   316   lo = PoolPoolLO(pool);
   317   
   318   RingInit(&lo->groupRing);
   319   lo->format = format;
   320   lo->poolStruct.alignment = format->alignment;
   321   lo->alignShift = SizeLog2((unsigned 
long)PoolAlignment(&lo->poolStruct));
   322 
   323   lo->sig = LOSig;
   324 
   325   AVERT(LO, lo);
   326 
   327   return ResOK;
   328 }
   329 
   330 static void LOFinish(Pool pool)
   331 {
   332   LO lo;
   333   Ring node;
   334   
   335   AVERT(Pool, pool);
   336   lo = PoolPoolLO(pool);
   337   AVERT(LO, lo);
   338 
   339   /* Can't use RING_FOR as the ring is being modified */
   340   /* as we are iterating over it */
   341   node = RingNext(&lo->groupRing);
   342   while(node != &lo->groupRing) {
   343     Ring next = RingNext(node);
   344     LOGroup group = RING_ELT(LOGroup, loRing, node);
   345 
   346     loGroupDestroy(group);
   347 
   348     node = next;
   349   }
   350 
   351   RingFinish(&lo->groupRing);
   352   lo->sig = SigInvalid;
   353 }
   354 
   355 
   356 /* BufferInit
   357  *
   358  * This wouldn't be needed if the client had a way to make an AP
   359  * of rankset RankSetEMPTY.  We let the client make APs of any rank
   360  * and coerce their rank here.  @@@@
   361  */
   362 static Res LOBufferInit(Pool pool, Buffer buffer)
   363 {
   364   buffer->rankSet = RankSetEMPTY;
   365   return ResOK;
   366 }
   367 
   368 
   369 static Res LOBufferFill(Seg *segReturn, Addr *baseReturn, Addr 
*limitReturn,
   370                         Pool pool, Buffer buffer, Size size)
   371 {
   372   Res res;
   373   Ring node;
   374   LO lo;
   375   LOGroup group;
   376   Space space;
   377   Addr init, limit;
   378 
   379   AVER(segReturn != NULL);
   380   AVER(baseReturn != NULL);
   381   AVER(limitReturn != NULL);
   382   AVERT(Pool, pool);
   383   AVER(pool->class == PoolClassLO());
   384   lo = PARENT(LOStruct, poolStruct, pool);
   385   AVERT(LO, lo);
   386   AVER(BufferIsReset(buffer));
   387   AVER(BufferRankSet(buffer) == RankSetEMPTY);
   388   AVER(size > 0);
   389 
   390   space = PoolSpace(pool);
   391 
   392   /* Try to find a group with enough space already. */
   393   size = SizeAlignUp(size, PoolAlignment(pool));
   394   RING_FOR(node, &lo->groupRing) {
   395     group = RING_ELT(LOGroup, loRing, node);
   396     if(loGroupAlloc(&init, &limit, group, size)) {
   397       goto found;
   398     }
   399   }
   400 
   401   /* No group had enough space, so make a new one. */
   402   res = loGroupCreate(&group, pool, size);
   403   if(res != ResOK) {
   404     goto failGroup;
   405   }
   406   init = SegBase(space, group->seg);
   407   limit = SegLimit(space, group->seg);
   408 
   409 found:
   410   *segReturn = group->seg;
   411   *baseReturn = init;
   412   *limitReturn = limit;
   413   return ResOK;
   414 
   415 failGroup:
   416   return res;
   417 }
   418 
   419 
   420 /* Synchronise the buffer with the alloc Bit Table in the group. */
   421 
   422 static void LOBufferEmpty(Pool pool, Buffer buffer)
   423 {
   424   LO lo;
   425   Addr base, alloc, segBase;
   426   LOGroup group;
   427   Seg seg;
   428   Size bi, ai;
   429   Space space;
   430 
   431   AVERT(Pool, pool);
   432   lo = PARENT(LOStruct, poolStruct, pool);
   433   AVERT(LO, lo);
   434   AVERT(Buffer, buffer);
   435   AVER(!BufferIsReset(buffer));
   436   AVER(BufferIsReady(buffer));
   437   
   438   seg = BufferSeg(buffer);
   439   group = (LOGroup)seg->p;
   440 
   441   AVERT(LOGroup, group);
   442   AVER(group->seg == seg);
   443   AVER(group->lo == lo);
   444 
   445   space = PoolSpace(pool);
   446   base = BufferBase(buffer);
   447   alloc = BufferAlloc(buffer);
   448   segBase = SegBase(space, seg);
   449 
   450   AVER(AddrIsAligned(base, PoolAlignment(pool)));
   451   AVER(segBase <= base && base < SegLimit(space, seg));
   452   AVER(segBase <= alloc && alloc <= SegLimit(space, seg));
   453 
   454   /* convert base and alloc to quantum positions */
   455   bi = AddrOffset(segBase, base) >> lo->alignShift;
   456   ai = AddrOffset(segBase, alloc) >> lo->alignShift;
   457 
   458   /* The ex-buffered area now becomes allocated */
   459   BTSetRange(group->alloc, bi, ai);
   460 }
   461 
   462 
   463 /* LOCondemn -- condemn a segment */
   464 
   465 static Res LOCondemn(Pool pool, Trace trace, Seg seg)
   466 {
   467   LO lo;
   468   LOGroup group;
   469   Space space;
   470   unsigned long bits;
   471 
   472   AVERT(Pool, pool);
   473   lo = PARENT(LOStruct, poolStruct, pool);
   474   AVERT(LO, lo);
   475 
   476   AVERT(Trace, trace);
   477   AVERT(Seg, seg);
   478   AVER(seg->white == TraceSetEMPTY);
   479 
   480   group = (LOGroup)seg->p;
   481   AVERT(LOGroup, group);
   482 
   483   space = PoolSpace(pool);
   484   bits = SegSize(space, group->seg) >> lo->alignShift;
   485   BTResRange(group->mark, 0, bits);
   486 
   487   seg->white = TraceSetAdd(seg->white, trace->ti);
   488 
   489   return ResOK;
   490 }
   491 
   492 
   493 static Res LOFix(Pool pool, ScanState ss, Seg seg, Ref *refIO)
   494 {
   495   LO lo;
   496   LOGroup group;
   497   Ref ref;
   498 
   499   AVERT(Pool, pool);
   500   AVERT(ScanState, ss);
   501   AVERT(Seg, seg);
   502   AVER(TraceSetInter(seg->white, ss->traces) != TraceSetEMPTY);
   503   AVER(refIO != NULL);
   504   ref = *refIO;
   505   lo = PARENT(LOStruct, poolStruct, pool);
   506   AVERT(LO, lo);
   507   group = (LOGroup)seg->p;
   508   AVERT(LOGroup, group);
   509   AVER(group->seg == seg);
   510 
   511   ss->wasMarked = TRUE;         /* design.mps.fix.protocol.was-marked */
   512 
   513   switch(ss->rank) {
   514   case RankAMBIG:
   515     if(!AddrIsAligned(ref, lo->format->alignment)) {
   516       return ResOK;
   517     }
   518   /* fall through */
   519 
   520   case RankEXACT: 
   521   case RankFINAL:
   522   case RankWEAK: {
   523     Space space = PoolSpace(pool);
   524     Size i = AddrOffset(SegBase(space, seg),
   525                         (Addr)ref) >> lo->alignShift;
   526 
   527     if(!BTGet(group->mark, i)) {
   528       ss->wasMarked = FALSE;  /* design.mps.fix.protocol.was-marked */
   529       if(ss->rank == RankWEAK) {
   530         *refIO = (Addr)0;
   531       } else {
   532         BTSet(group->mark, i);
   533       }
   534     }
   535   } break;
   536 
   537   default:
   538     NOTREACHED;
   539     break;
   540   }
   541 
   542   return ResOK;
   543 }
   544 
   545 
   546 static void LOReclaim(Pool pool, Trace trace, Seg seg)
   547 {
   548   LO lo;
   549   LOGroup group;
   550 
   551   AVERT(Pool, pool);
   552   lo = PoolPoolLO(pool);
   553   AVERT(LO, lo);
   554 
   555   AVERT(Trace, trace);
   556   AVERT(Seg, seg);
   557   AVER(TraceSetIsMember(seg->white, trace->ti));
   558 
   559   group = (LOGroup)seg->p;
   560   loGroupReclaim(group, trace);
   561 }
   562 
   563 
   564 static struct PoolClassStruct PoolClassLOStruct = {
   565   PoolClassSig,
   566   "LO",                                 /* name */
   567   sizeof(LOStruct),                     /* size */
   568   offsetof(LOStruct, poolStruct),       /* offset */
   569   AttrFMT | AttrBUF | AttrBUF_RESERVE | AttrGC,
   570   LOInit,
   571   LOFinish,
   572   PoolNoAlloc,
   573   PoolNoFree,
   574   LOBufferInit,
   575   LOBufferFill,
   576   LOBufferEmpty,
   577   PoolTrivBufferFinish,
   578   LOCondemn,
   579   PoolNoGrey,
   580   PoolNoScan,
   581   LOFix,
   582   LOReclaim,
   583   PoolTrivDescribe,
   584   PoolClassSig
   585 };
   586 
   587 
   588 PoolClass PoolClassLO(void)
   589 {
   590   return &PoolClassLOStruct;
   591 }
   592 
   593 
   594 mps_class_t mps_class_lo(void)
   595 {
   596   return (mps_class_t)PoolClassLO();
   597 }
   598 
   599 
   600 static Bool LOCheck(LO lo)
   601 {
   602   CHECKS(LO, lo);
   603   CHECKD(Pool, &lo->poolStruct);
   604   CHECKL(lo->poolStruct.class == &PoolClassLOStruct);
   605   CHECKL(RingCheck(&lo->groupRing));
   606   CHECKD(Format, lo->format);
   607   CHECKL(1uL << lo->alignShift == PoolAlignment(&lo->poolStruct));
   608   return TRUE;
   609 }

