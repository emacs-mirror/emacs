               VIRTUAL MEMORY BASED ARENA IMPLEMENTATION
                             impl.c.arenavm
                               draft impl
                             drj 1996-07-12

     1 /* impl.c.arenavm: VIRTUAL MEMORY BASED ARENA IMPLEMENTATION
     2  *
     3  * $HopeName: MMsrc!arenavm.c(trunk.18) $
     4  * Copyright (C) 1997 The Harlequin Group Limited.  All rights reserved.
     5  *
     6  * This is the implementation of the Segment abstraction from the VM
     7  * abstraction.  Use of this arena implies use of a VM.
     8  *
     9  * DESIGN
    10  * design.mps.arena.vm
    11  */
    12 
    13 
    14 #include "mpm.h"
    15 
    16 
    17 SRCID(arenavm, "$HopeName: MMsrc!arenavm.c(trunk.18) $");
    18 
    19 
    20 /* Space Arena Projection
    21  * 
    22  * Only the arena module needs to discuss the arena object, hence, this
    23  * method is private to this module.
    24  */
    25 
    26 #define SpaceArena(space)       (&(space)->arenaStruct)
    27 
    28 
    29 /* Page Index to Base address mapping
    30  *
    31  * See design.mps.arena.vm.table.linear
    32  */
    33 
    34 #define PageBase(arena, i) \
    35   AddrAdd((arena)->base, ((i) << arena->pageShift))
    36 
    37 
    38 /* PageStruct -- page structure
    39  *
    40  * The page table (defined as a PageStruct array) is central to the
    41  * design of the arena.  See design.mps.arena.vm.table.*
    42  */
    43 
    44 typedef struct PageStruct {     /* page structure */
    45   union {
    46     SegStruct head;             /* segment */
    47     struct {
    48       Pool pool;                /* .page: NULL, must be first field
    49                                  * see impl.h.mpmst.seg.pool */
    50       Seg seg;                  /* segment at base page of run */
    51       Addr limit;               /* limit of segment */
    52     } tail;                     /* tail page */
    53   } the;
    54 } PageStruct;
    55 
    56 
    57 /* ArenaCreate -- create the arena
    58  *
    59  * In fact, this creates the space structure and initializes the
    60  * arena part.
    61  *
    62  * In fact, the space structure is created by calling VMCreate.
    63  */
    64 
    65 Res ArenaCreate(Space *spaceReturn, Size size, Addr base)
    66 {
    67   Res res;
    68   Space space;
    69   Size f_words, f_size, p_size; /* see .init-tables */
    70   Arena arena;
    71   
    72   AVER(spaceReturn != NULL);
    73   AVER(size > 0);
    74   /* no restrictions on base, it's simply passed through to VMCreate */
    75 
    76   /* VMCreate requires aligned size */
    77   size = SizeAlignUp(size, VMAlign());
    78 
    79   /* .vm.create: Create the space structure, initialize the VM part */
    80   res = VMCreate(&space, size, base);
    81   if(res) return res;
    82 
    83   arena = SpaceArena(space);
    84   /* see design.mps.space.arena */
    85   arena->base = VMBase(space);
    86   arena->limit = VMLimit(space);
    87   AVER(AddrOffset(arena->base, arena->limit) == size);
    88   arena->pageSize = VMAlign();
    89   arena->pageShift = SizeLog2(arena->pageSize);
    90   arena->pages = size >> arena->pageShift;
    91 
    92   /* .init-tables: Allocate the page tables at the base of the arena.
    93    *
    94    * .improve.table.zone-zero: It would be better to make sure that the
    95    * page tables are in zone zero, since that zone is least useful for
    96    * GC. (but it would change how SegAllocWithRefSet avoids allocating
    97    * over the tables, see .alloc.skip)
    98    *
    99    * There are two tables, the free table which is a bool array, and the
   100    * page table which is a PageStruct array.  Both tables are allocated
   101    * contiguously in one chunk.
   102    *
   103    * f_words is the number of words required for the free table.
   104    * 
   105    * f_size is the page-aligned size of the free table.
   106    * 
   107    * p_size is the page-aligned size of the page table.
   108    */
   109   f_words = SizeAlignUp(arena->pages, MPS_WORD_WIDTH) >> MPS_WORD_SHIFT;
   110   f_size = SizeAlignUp(f_words * sizeof(Word), arena->pageSize);
   111   p_size = SizeAlignUp(arena->pages * sizeof(PageStruct), 
arena->pageSize);
   112   arena->tablesSize = f_size + p_size;
   113   res = VMMap(space, arena->base, AddrAdd(arena->base, 
arena->tablesSize));
   114   if(res) {
   115     VMDestroy(space);
   116     return res;
   117   }
   118   arena->freeTable = (BT)arena->base;
   119   arena->pageTable = (Page)AddrAdd(arena->base, f_size);
   120 
   121   /* .tablepages: pages whose page index is < tablePages are recorded as
   122    * free but never allocated as alloc starts searching after the tables
   123    * (see .alloc.skip).  SegOfAddr uses the fact that these pages are
   124    * marked as free in order to detect "references" to these pages as
   125    * being bogus see .addr.free.
   126    */
   127   arena->tablePages = arena->tablesSize >> arena->pageShift;
   128   BTSetRange(arena->freeTable, 0, arena->pages);
   129 
   130   /* Set the zone shift to divide the arena into the same number of
   131    * zones as will fit into a reference set (the number of bits in a
   132    * word).  Note that some zones are discontiguous in the arena if the
   133    * size is not a power of 2. See design.mps.space.arena.
   134    */
   135   space->zoneShift = SizeFloorLog2(size >> MPS_WORD_SHIFT);
   136 
   137   /* Sign the arena. */
   138   arena->sig = ArenaSig;
   139   
   140   AVERT(Arena, arena);
   141   
   142   EVENT2(ArenaCreate, arena, space);
   143 
   144   *spaceReturn = space;
   145   return ResOK;
   146 }
   147 
   148 Res ArenaExtend(Space space, Addr base, Size size)
   149 {
   150   return ResUNIMPL;
   151 }
   152 
   153 Res ArenaRetract(Space space, Addr base, Size size)
   154 {
   155   return ResUNIMPL;
   156 }
   157 
   158 /* ArenaDestroy -- finish the arena and destroy the space structure */
   159 
   160 void ArenaDestroy(Space space)
   161 {
   162   Arena arena;
   163 
   164   AVERT(Arena, SpaceArena(space));
   165   
   166   arena = SpaceArena(space);
   167   arena->sig = SigInvalid;
   168   VMUnmap(space, arena->base, AddrAdd(arena->base, arena->tablesSize));
   169   VMDestroy(space);     /* .vm.create */
   170 
   171   EVENT1(ArenaDestroy, arena);
   172 }
   173 
   174 
   175 /* ArenaReserved -- return the amount of reserved address space
   176  * ArenaCommitted -- return the amount of committed virtual memory
   177  *
   178  * Since this is a VM-based arena, this information is retrieved from
   179  * the VM.
   180  */
   181 
   182 Size ArenaReserved(Space space)
   183 {
   184   AVERT(Arena, SpaceArena(space));
   185   return VMReserved(space);
   186 }
   187 
   188 Size ArenaCommitted(Space space)
   189 {
   190   AVERT(Arena, SpaceArena(space));
   191   return VMMapped(space);
   192 }
   193 
   194 
   195 /* ArenaCheck -- check of the consistency of the arena structure */
   196 
   197 Bool ArenaCheck(Arena arena)
   198 {
   199   CHECKS(Arena, arena);
   200   CHECKD(VM, &arena->vmStruct);
   201   CHECKL(arena->base != (Addr)0);
   202   CHECKL(arena->base < arena->limit);
   203   CHECKL(arena->pageShift <= MPS_WORD_WIDTH);
   204   CHECKL(arena->pageSize == 1uL << arena->pageShift);
   205   CHECKL(VMAlign() == arena->pageSize);
   206   CHECKL(arena->pages == 
   207            AddrOffset(arena->base, arena->limit) >> arena->pageShift);
   208   CHECKL(arena->tablePages <= arena->pages);
   209   CHECKL(arena->tablesSize == arena->tablePages << arena->pageShift);
   210   CHECKL(arena->pageTable != NULL);
   211   CHECKL((Addr)arena->pageTable >= arena->base);
   212   CHECKL((Addr)&arena->pageTable[arena->pages] <=
   213            AddrAdd(arena->base, arena->tablesSize));
   214   CHECKL(arena->freeTable != NULL);
   215   CHECKL((Addr)arena->freeTable >= arena->base);
   216   CHECKL((Addr)&arena->freeTable[(arena->pages + 
MPS_WORD_WIDTH-1)>>MPS_WORD_SHIFT] <=
   217            arena->limit);
   218   /* .improve.check-table: Could check the consistency of the tables. */
   219   return TRUE;
   220 }
   221 
   222 
   223 Bool SegPrefCheck(SegPref pref)
   224 {
   225   CHECKS(SegPref, pref);
   226   CHECKL(BoolCheck(pref->high));
   227   /* nothing else to check */
   228   return TRUE;
   229 }
   230 
   231 static SegPrefStruct segPrefDefault = {
   232   SegPrefSig,                           /* sig */
   233   FALSE,                                /* high */
   234   RefSetUNIV,                           /* refSet */
   235 };
   236 
   237 SegPref SegPrefDefault(void)
   238 {
   239   return &segPrefDefault;
   240 }
   241 
   242 Res SegPrefExpress (SegPref sp, SegPrefKind kind, void *p)
   243 {
   244   AVERT(SegPref,sp);
   245   AVER(sp != &segPrefDefault);
   246 
   247   switch(kind) {
   248   case SegPrefHigh:
   249     AVER(p == NULL);
   250     sp->high = TRUE;
   251     return ResOK;
   252 
   253   case SegPrefLow:
   254     AVER(p == NULL);
   255     sp->high = FALSE;
   256     return ResOK;
   257 
   258   case SegPrefRefSet:
   259     AVER(p != NULL);
   260     sp->refSet = *(RefSet *)p;
   261     return ResOK;
   262 
   263   default:
   264     /* see design.mps.pref.default */
   265     return ResOK;
   266   }
   267 }
   268 
   269 
   270 /* IndexOfAddr -- return the page index of the page containing an 
address */
   271 
   272 static Index IndexOfAddr(Arena arena, Addr addr)
   273 {
   274   AVERT(Arena, arena);
   275   AVER(arena->base <= addr);
   276   AVER(addr <= arena->limit);
   277   return AddrOffset(arena->base, addr) >> arena->pageShift;
   278 }
   279 
   280 
   281 /* SegAllocInArea -- try to allocate a segment in an area
   282  *
   283  * Search for a free run of pages in the free table, but between
   284  * base and limit.
   285  *
   286  * .improve.bit-twiddle:  This code can probably be seriously
   287  * optimised by twiddling the bit table.
   288  */
   289 
   290 static Bool SegAllocInArea(Index *baseReturn,
   291       Space space, Size size, Addr base, Addr limit)
   292 {
   293   Arena arena;
   294   Word pages;    /* number of pages equiv. to size */
   295   Word count;    /* pages so far in free run */
   296   Index basePage, limitPage;  /* Index equiv. to base and limit */
   297   Index i;    /* iterator over page table */
   298   Index start = (Index)0;  /* base of free run, with warning suppressor 
*/
   299 
   300   AVER(baseReturn != NULL);
   301   AVERT(Space, space);  
   302   arena = SpaceArena(space);
   303   AVERT(Arena, arena);
   304   AVER(arena->base <= base);
   305   AVER(base < limit);
   306   AVER(limit <= arena->limit);
   307   AVER(size <= AddrOffset(base, limit));
   308   AVER(size > (Size)0);
   309   AVER(SizeIsAligned(size, arena->pageSize));
   310 
   311   basePage = IndexOfAddr(arena, base);
   312   limitPage = IndexOfAddr(arena, limit);
   313 
   314   pages = size >> arena->pageShift;
   315   count = 0;
   316   for(i = basePage; i < limitPage; ++i) {
   317     if(BTGet(arena->freeTable, i)) {
   318       if(count == 0)
   319         start = i;
   320       ++count;
   321       if(count == pages) {
   322         *baseReturn = start;
   323         return TRUE;
   324       }
   325     } else
   326       count = 0;
   327   }
   328   
   329   return FALSE;
   330 }
   331 
   332 
   333 /* SegAllocWithRefSet
   334  *   -- try to allocate a segment with a particular RefSet
   335  * 
   336  * This function finds the intersection of refSet and the set of free
   337  * pages and tries to allocate a segment in the resulting set of
   338  * areas.
   339  */
   340 
   341 static Bool SegAllocWithRefSet(Index *baseReturn,
   342           Space space, Size size, RefSet refSet)
   343 {
   344   Arena arena = SpaceArena(space);
   345   Addr arenaBase, base, limit;
   346   Size zoneSize = (Size)1 << space->zoneShift;
   347 
   348   /* .alloc.skip: The first address available for segments, */
   349   /* is just after the arena tables. */
   350   arenaBase = PageBase(arena, arena->tablePages);
   351 
   352   base = arenaBase;
   353   while(base < arena->limit) {
   354   
   355     if(RefSetIsMember(space, refSet, base)) {
   356       /* Search for a run of zone stripes which are in the RefSet and */
   357       /* the arena.  Adding the zoneSize might wrap round (to zero, */
   358       /* because limit is aligned to zoneSize, which is a power of two). 
*/
   359       limit = base;
   360       do {
   361         limit = AddrAlignDown(AddrAdd(limit, zoneSize), zoneSize);
   362 
   363         AVER(limit > base || limit == (Addr)0);
   364 
   365         if(limit >= arena->limit || limit < base) {
   366           limit = arena->limit;
   367           break;
   368         }
   369 
   370         AVER(base < limit && limit < arena->limit);
   371       } while(RefSetIsMember(space, refSet, limit));
   372 
   373       AVER(refSet != RefSetUNIV ||
   374            (base == arenaBase && limit == arena->limit));
   375 
   376       /* Try to allocate a segment in the area. */
   377       if(AddrOffset(base, limit) >= size &&
   378          SegAllocInArea(baseReturn, space, size, base, limit))
   379         return TRUE;
   380       
   381       base = limit;
   382     } else {
   383       /* Adding the zoneSize might wrap round (to zero, because base */
   384       /* is aligned to zoneSize, which is a power of two). */
   385       base = AddrAlignDown(AddrAdd(base, zoneSize), zoneSize);
   386       AVER(base > arenaBase || base == (Addr)0);
   387       if(base < arenaBase) {
   388         base = arena->limit;
   389         break;
   390       }
   391     }
   392   }
   393 
   394   AVER(base == arena->limit);
   395 
   396   return FALSE;
   397 }
   398 
   399 
   400 /* SegAlloc -- allocate a segment from the arena */
   401 
   402 Res SegAlloc(Seg *segReturn, SegPref pref, Space space, Size size, Pool 
pool)
   403 {
   404   Arena arena = SpaceArena(space);
   405   Index i, pages, base;
   406   Addr addr;
   407   Seg seg;
   408   Res res;
   409 
   410   AVER(segReturn != NULL);
   411   AVERT(SegPref, pref);
   412   AVERT(Arena, SpaceArena(space));
   413   AVER(size > 0);
   414   AVERT(Pool, pool);
   415   AVER(SizeIsAligned(size, arena->pageSize));
   416   
   417   /* NULL is used as a discriminator (see 
design.mps.arena.vm.table.disc) */
   418   /* therefore the real pool must be non-NULL. */
   419   AVER(pool != NULL);
   420 
   421   if(!SegAllocWithRefSet(&base, space, size, pref->refSet) &&
   422      (pref->refSet == RefSetUNIV ||
   423       !SegAllocWithRefSet(&base, space, size, RefSetUNIV))) {
   424     /* .improve.alloc-fail: This could be because the request was */
   425     /* too large, or perhaps the arena is fragmented.  We could return a 
*/
   426     /* more meaningful code. */
   427     return ResRESOURCE;
   428   }
   429   
   430   /* .alloc.early-map: Map in the segment memory before actually */
   431   /* allocating the pages, because the unwind (in case of failure) */
   432   /* is simpler. */
   433   addr = PageBase(arena, base);
   434   res = VMMap(space, addr, AddrAdd(addr, size));
   435   if(res) return res;
   436 
   437   /* Initialize the generic segment structure. */
   438   seg = &arena->pageTable[base].the.head;
   439   SegInit(seg, pool);
   440 
   441   /* Allocate the first page, and, if there is more than one page, */
   442   /* allocate the rest of the pages and store the multi-page information 
*/
   443   /* in the page table. */
   444   AVER(BTGet(arena->freeTable, base));
   445   BTRes(arena->freeTable, base);
   446   pages = size >> arena->pageShift;
   447   if(pages > 1) {
   448     Addr limit = PageBase(arena, base + pages);
   449     seg->single = FALSE;
   450     for(i = base + 1; i < base + pages; ++i) {
   451       AVER(BTGet(arena->freeTable, i));
   452       BTRes(arena->freeTable, i);
   453       arena->pageTable[i].the.tail.pool = NULL;
   454       arena->pageTable[i].the.tail.seg = seg;
   455       arena->pageTable[i].the.tail.limit = limit;
   456     }
   457   } else {
   458     seg->single = TRUE;
   459   }
   460   
   461   AVERT(Seg, seg);
   462   
   463   EVENT5(SegAlloc, arena, seg, addr, size, pool);
   464 
   465   *segReturn = seg;
   466   return ResOK;
   467 }
   468 
   469 
   470 /* SegFree - free a segment in the arena */
   471 
   472 void SegFree(Space space, Seg seg)
   473 {
   474   Arena arena;
   475   Page page;
   476   Index i, pl, pn;
   477   Addr base, limit; 
   478 
   479   AVERT(Arena, SpaceArena(space));
   480   AVERT(Seg, seg);
   481 
   482   arena = SpaceArena(space);
   483   page = PARENT(PageStruct, the.head, seg);
   484   limit = SegLimit(space, seg);
   485   i = page - arena->pageTable;
   486   AVER(i <= arena->pages);
   487 
   488   SegFinish(seg);
   489 
   490   /* Remember the base address of the segment so it can be */
   491   /* unmapped .free.unmap */
   492   base = PageBase(arena, i);
   493 
   494   /* Calculate the number of pages in the segment, and hence the
   495    * limit for .free.loop */
   496   pn = AddrOffset(base, limit) >> arena->pageShift;
   497   pl = i + pn;
   498   /* .free.loop: */
   499   while(i < pl) {
   500     AVER(!BTGet(arena->freeTable, i));
   501     BTSet(arena->freeTable, i);
   502     ++i;
   503   }
   504 
   505   /* .free.unmap: Unmap the segment memory. */
   506   VMUnmap(space, base, PageBase(arena, i));
   507 
   508   /* Double check that .free.loop takes us to the limit page of the
   509    * segment.
   510    */
   511   AVER(PageBase(arena, i) == limit);
   512 
   513   EVENT2(SegFree, arena, seg);
   514 }
   515 
   516 
   517 /* ArenaAlign -- return the alignment of segments */
   518 
   519 Align ArenaAlign(Space space)
   520 {
   521   Arena arena;
   522   AVERT(Arena, SpaceArena(space));
   523   arena = SpaceArena(space);
   524   return arena->pageSize;
   525 }
   526 
   527 
   528 /* SegBase -- return the base address of a segment
   529  *
   530  * The segment base is calculated by working out the index of the
   531  * segment structure in the page table and then multiplying that
   532  * by the page size and adding it to the arena base address.
   533  */
   534 
   535 Addr SegBase(Space space, Seg seg)
   536 {
   537   Arena arena;
   538   Page page;
   539   Index i;
   540   
   541   AVERT(Arena, SpaceArena(space));
   542   AVERT(Seg, seg);
   543 
   544   arena = SpaceArena(space);
   545   page = PARENT(PageStruct, the.head, seg);
   546   i = page - arena->pageTable;
   547 
   548   return PageBase(arena, i);
   549 }
   550 
   551 
   552 /* SegLimit -- return the limit address (end+1) of a segment
   553  *
   554  * If the segment is a single page, then the limit is just
   555  * the next page, otherwise it is stored on the next page
   556  * table entry.
   557  */
   558 
   559 Addr SegLimit(Space space, Seg seg)
   560 {
   561   Arena arena;
   562   Page page;
   563 
   564   AVERT(Arena, SpaceArena(space));
   565   AVERT(Seg, seg);
   566 
   567   arena = SpaceArena(space);
   568   if(seg->single)
   569     return AddrAdd(SegBase(space, seg), arena->pageSize);
   570   else {
   571     page = PARENT(PageStruct, the.head, seg);
   572     return page[1].the.tail.limit;
   573   }
   574 }
   575 
   576 
   577 /* SegSize -- return the size (limit - base) of a segment
   578  *
   579  * .improve.redundant-calc: There is scope for optimizing this,
   580  * because both base and limit calls do roughly the same thing twice.
   581  */
   582 
   583 Size SegSize(Space space, Seg seg)
   584 {
   585   AVERT(Arena, SpaceArena(space));
   586   AVERT(Seg, seg);
   587   return AddrOffset(SegBase(space, seg), SegLimit(space, seg));
   588 }
   589 
   590 
   591 /* SegOfAddr -- return the segment which encloses an address
   592  *
   593  * If the address is within the bounds of the arena, calculate the
   594  * page table index from the address and see if the page is allocated.
   595  * If it is a head page, return the segment, otherwise follow the
   596  * tail's pointer back to the segment in the head page.
   597  */
   598 
   599 Bool SegOfAddr(Seg *segReturn, Space space, Addr addr)
   600 {
   601   Arena arena;
   602   
   603   AVER(segReturn != NULL);
   604   AVERT(Arena, SpaceArena(space));
   605   
   606   arena = SpaceArena(space);
   607   if(arena->base <= addr && addr < arena->limit) {
   608     Index i = IndexOfAddr(arena, addr);
   609     /* .addr.free: If the page is recorded as being free then */
   610     /* either the page is free or it is */
   611     /* part of the arena tables (see .tablepages) */
   612     if(!BTGet(arena->freeTable, i)) {
   613       Page page = &arena->pageTable[i];
   614 
   615       if(page->the.head.pool != NULL)
   616         *segReturn = &page->the.head;
   617       else
   618         *segReturn = page->the.tail.seg;
   619       return TRUE;
   620     }
   621   }
   622   
   623   return FALSE;
   624 }
   625 
   626 
   627 /* SegSearch -- search for a segment
   628  *
   629  * Searches for a segment in the arena starting at page index i,
   630  * return NULL if there is none.  A segment is present if it is
   631  * not free, and its pool is not NULL.
   632  *
   633  * This function is private to this module and is used in the segment
   634  * iteration protocol (SegFirst and SegNext).
   635  */
   636 static Bool SegSearch(Seg *segReturn, Arena arena, Index i)
   637 {
   638   /* static function called with checked arguments, */
   639   /* so we don't bother checking them here as well */
   640 
   641   while(i < arena->pages &&
   642         (BTGet(arena->freeTable, i) ||
   643          arena->pageTable[i].the.head.pool == NULL)) {
   644     ++i;
   645   }
   646   
   647   if(i < arena->pages) {
   648     *segReturn = &arena->pageTable[i].the.head;
   649     return TRUE;
   650   }
   651   
   652   AVER(i == arena->pages);
   653   return FALSE;
   654 }
   655 
   656 
   657 /* SegFirst -- return the first segment in the arena
   658  *
   659  * This is used to start an iteration over all segments in the arena.
   660  */
   661 
   662 Bool SegFirst(Seg *segReturn, Space space)
   663 {
   664   Arena arena;
   665 
   666   AVER(segReturn != NULL);
   667   AVERT(Space, space);
   668   arena = SpaceArena(space);
   669   AVERT(Arena, arena);
   670 
   671   /* We start from tablePages, as the tables can't be a segment.
   672    * See .tablepages */
   673   return SegSearch(segReturn, arena, (Index)arena->tablePages);
   674 }
   675 
   676 
   677 /* SegNext -- return the next segment in the arena
   678  *
   679  * This is used as the iteration step when iterating over all
   680  * segments in the arena.
   681  */
   682 
   683 Bool SegNext(Seg *segReturn, Space space, Addr addr)
   684 {
   685   Arena arena;
   686   Index i;
   687 
   688   AVER(segReturn != NULL);
   689   AVERT(Space, space);
   690   /* There are further restrictions on addr, but they are much */
   691   /* harder to check */
   692   AVER(AddrIsAligned((addr), ArenaAlign(space)));
   693 
   694   arena = SpaceArena(space);
   695   AVERT(Arena, arena);
   696   i = IndexOfAddr(arena, addr);
   697   /* There are fewer pages than addresses, therefore the */
   698   /* page index can never wrap around */
   699   AVER(i+1 != 0);
   700   return SegSearch(segReturn, arena, i + 1);
   701 }
   702 
   703 

